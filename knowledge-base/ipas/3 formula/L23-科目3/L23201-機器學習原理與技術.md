# L23201 - 機器學習原理與技術

## 1. 核心定義 (20%, 400-1200字)

### 1.1 主題定義

機器學習原理是理解機器學習系統行為的理論基礎，涵蓋學習範式、泛化理論、模型選擇等核心概念。機器學習的本質是從資料中學習規律並推廣到未見資料，這個過程涉及三大核心問題：如何學習（學習範式）、如何避免過擬合（泛化理論）、如何選擇模型（模型複雜度權衡）。

機器學習原理提供了理解模型行為的數學框架：偏差-方差分解解釋了模型誤差的來源、VC 維理論量化了模型的學習能力、正則化技術平衡了擬合與泛化。從理論到實務，這些原理指導著特徵工程、模型選擇、超參數調校等關鍵決策。

### 1.2 核心概念

**機器學習原理的六大核心概念：**

1. **學習範式**：監督學習（有標籤）、非監督學習（無標籤）、強化學習（獎勵訊號）
2. **泛化能力**：模型在未見資料上的表現能力，是機器學習的終極目標
3. **偏差-方差權衡**：模型誤差分解為偏差（欠擬合）與方差（過擬合），需平衡兩者
4. **過擬合與欠擬合**：過度擬合訓練資料（過擬合）或無法捕捉資料規律（欠擬合）
5. **交叉驗證**：分割資料集評估模型泛化能力的標準方法
6. **正則化**：在損失函數中加入複雜度懲罰，防止過擬合

### 1.3 CFDS 分解

基於 Formula-Contract 方法論，將機器學習原理分解為四個基本單元：

```
MachineLearningPrinciples = f(C, F, D, S)
```

**C (Code - 可執行邏輯)**
```
C = LearningProcess ∘ GeneralizationControl ∘ ModelSelection ∘ ValidationStrategy
  = 學習過程 -> 泛化控制 -> 模型選擇 -> 驗證策略
```

**F (Files - 配置資源)**
```
F = {TrainConfig, ValidationSplit, RegularizationParams, CrossValidationFolds}
  = {訓練配置, 驗證集劃分, 正則化參數, 交叉驗證折數}
```

**D (Data - 資料結構)**
```
D = TrainingSet + ValidationSet + TestSet + LearningCurves
  = 訓練集 + 驗證集 + 測試集 + 學習曲線
```

**S (State - 運行狀態)**
```
S = Underfitting | Optimal | Overfitting | Generalizing
  = 欠擬合 | 最佳 | 過擬合 | 泛化中
```

### 1.4 技術定位

機器學習原理在技術棧中處於理論指導層，連接數學基礎（機率統計、優化理論）與實務應用（演算法設計、模型訓練）。理解原理能幫助判斷模型行為（為什麼訓練準確率 99% 但測試準確率 70%？）、指導調參決策（增加正則化還是增加資料？）、預測模型效能（資料量與準確率的關係）。

在企業應用中，機器學習原理指導著模型開發的全流程：資料劃分策略（訓練/驗證/測試）、模型選擇依據（簡單模型 vs 複雜模型）、泛化能力評估（交叉驗證）、過擬合診斷（學習曲線分析）。

---

## 2. 關鍵公式 (25%, 500-1500字)

### 2.1 學習範式主公式

**監督學習（Supervised Learning）**：
```
SupervisedLearning = f(X, Y) -> Model
Model: X -> Ŷ
Goal: minimize Loss(Y, Ŷ)
```
- **X**：輸入特徵（已知）
- **Y**：目標標籤（已知）
- **Ŷ**：模型預測（學習目標）
- **應用**：分類、迴歸

**非監督學習（Unsupervised Learning）**：
```
UnsupervisedLearning = f(X) -> Structure
Goal: discover patterns in X
```
- **X**：輸入特徵（已知）
- **Y**：無標籤（未知）
- **目標**：發現資料結構（聚類、降維、異常檢測）
- **應用**：K-means、PCA、Autoencoder

**強化學習（Reinforcement Learning）**：
```
ReinforcementLearning = Agent × Environment -> Policy
Policy: State -> Action
Goal: maximize Cumulative_Reward
```
- **Agent**：學習者
- **Environment**：環境
- **Reward**：獎勵訊號
- **應用**：遊戲 AI、機器人控制

### 2.2 泛化誤差分解公式

**期望誤差（Expected Error）**：
```
E[Error] = Bias² + Variance + Irreducible_Error
```

**偏差（Bias）**：
```
Bias = E[f̂(x)] - f(x)
```
- **f̂(x)**：模型預測
- **f(x)**：真實函數
- **意義**：模型的平均預測與真實值的偏離程度（欠擬合）

**方差（Variance）**：
```
Variance = E[(f̂(x) - E[f̂(x)])²]
```
- **意義**：模型在不同訓練集上預測的變異程度（過擬合）

**不可減少誤差（Irreducible Error）**：
```
Irreducible_Error = Noise_in_Data
```
- **意義**：資料本身的隨機噪音，任何模型無法消除

### 2.3 偏差-方差權衡

**權衡關係**：
```
Model_Complexity ↑ → Bias ↓, Variance ↑
Model_Complexity ↓ → Bias ↑, Variance ↓
```

**最佳模型複雜度**：
```
Optimal_Complexity = argmin(Bias² + Variance)
```

**典型曲線**：
```
訓練誤差: Train_Error ↓ (隨複雜度增加而下降)
測試誤差: Test_Error = U-shaped (先降後升)
最佳點: 測試誤差最低點
```

### 2.4 過擬合與欠擬合診斷公式

**過擬合（Overfitting）**：
```
(Train_Accuracy > 95%) ∧ (Test_Accuracy < 80%)
→ Overfitting_Detected
```
- **特徵**：訓練集表現優異、測試集表現差
- **原因**：模型過度複雜、訓練資料不足
- **解決**：正則化、Dropout、增加訓練資料

**欠擬合（Underfitting）**：
```
(Train_Accuracy < 80%) ∧ (Test_Accuracy < 80%)
→ Underfitting_Detected
```
- **特徵**：訓練集與測試集皆表現不佳
- **原因**：模型過於簡單、特徵不足
- **解決**：增加模型複雜度、特徵工程

**理想狀態（Well-fitted）**：
```
(Train_Accuracy ≈ Test_Accuracy) ∧ (Both > 85%)
→ Well_Generalized
```

### 2.5 交叉驗證公式

**K-Fold 交叉驗證**：
```
K-Fold_CV = (1/K) × Σ_{k=1}^{K} Evaluate(Model, Fold_k)
```
- **K**：折數（常見 5 或 10）
- **Fold_k**：第 k 個驗證集
- **流程**：
  1. 將資料分為 K 份
  2. 每次用 K-1 份訓練、1 份驗證
  3. 重複 K 次，每份都當過驗證集
  4. 平均 K 次結果

**留一交叉驗證（Leave-One-Out CV）**：
```
LOO_CV = (1/N) × Σ_{i=1}^{N} Evaluate(Model_{-i}, x_i)
```
- **N**：資料總數
- **Model_{-i}**：去除第 i 筆資料訓練的模型
- **優點**：充分利用資料
- **缺點**：計算成本高（需訓練 N 次）

### 2.6 正則化公式

**Ridge 正則化（L2）**：
```
Loss_Ridge = DataLoss + λ × Σθ_i²
```
- **效果**：平滑縮小參數、防止過擬合
- **應用**：線性迴歸、神經網路權重衰減

**Lasso 正則化（L1）**：
```
Loss_Lasso = DataLoss + λ × Σ|θ_i|
```
- **效果**：產生稀疏性（參數歸零）、特徵選擇
- **應用**：特徵選擇、壓縮感知

**Elastic Net（L1+L2）**：
```
Loss_ElasticNet = DataLoss + λ_1×Σ|θ_i| + λ_2×Σθ_i²
```
- **效果**：結合 L1 稀疏性與 L2 穩定性

---

## 3. 對比矩陣 (15%, 300-900字)

### 3.1 技術對比表

| 學習範式 | 資料要求 | 學習目標 | 典型演算法 | 應用場景 | 難度 |
|---------|---------|---------|-----------|---------|------|
| **監督學習** | 標籤資料 | 預測準確性 | 迴歸、分類、SVM | 影像辨識、語音識別 | 中 |
| **非監督學習** | 無標籤資料 | 發現結構 | K-means、PCA、Autoencoder | 客戶分群、異常檢測 | 高 |
| **強化學習** | 獎勵訊號 | 最大化回報 | Q-Learning、DQN、PPO | 遊戲 AI、機器人 | 最高 |
| **半監督學習** | 少量標籤 | 利用無標籤資料 | Self-training、Co-training | 醫療影像（標註昂貴） | 高 |

### 3.2 優缺點分析

**監督學習**
- **優點**：準確度高、可解釋性強、訓練穩定
- **缺點**：需要大量標籤資料（標註成本高）、無法處理未見類別
- **適用**：標籤資料充足、明確的預測目標

**非監督學習**
- **優點**：無需標籤（成本低）、發現隱藏結構、探索性分析
- **缺點**：缺乏明確評估指標、結果難解釋、不保證有用
- **適用**：探索資料結構、標籤不可得

**強化學習**
- **優點**：適應動態環境、可處理序列決策、無需完整標籤
- **缺點**：訓練不穩定、需大量試錯、獎勵設計困難
- **適用**：遊戲、機器人、自動駕駛

### 3.3 過擬合 vs 欠擬合對比

| 狀態 | 訓練誤差 | 測試誤差 | 原因 | 解決方法 |
|------|---------|---------|------|---------|
| **過擬合** | 極低 | 高 | 模型過複雜、資料不足 | 正則化、Dropout、增加資料 |
| **欠擬合** | 高 | 高 | 模型過簡單、特徵不足 | 增加複雜度、特徵工程 |
| **理想** | 低 | 低 | 平衡 | 維持現狀 |

### 3.4 交叉驗證方法對比

| 方法 | 資料利用率 | 計算成本 | 方差 | 適用場景 |
|------|-----------|---------|------|---------|
| **Hold-out** | 低（70-80%） | 最低 | 高 | 大資料集、快速驗證 |
| **K-Fold** | 高（100%） | 中 | 中 | 中小資料集、標準選擇 |
| **LOO** | 最高（100%） | 最高 | 低 | 小資料集（< 1000） |
| **Stratified K-Fold** | 高（100%） | 中 | 低 | 類別不平衡資料 |

---

## 4. 實務應用 (20%, 400-1200字)

### 4.1 應用場景一：診斷過擬合問題

**場景描述**：影像分類模型訓練準確率 99%、測試準確率 65%，懷疑過擬合。

**技術應用**：學習曲線分析 + 正則化技術。

**實現要點**：
```
OverfittingDiagnosis = PlotLearningCurves -> AnalyzeGap -> ApplyRegularization

LearningCurve_Analysis:
  X軸: Training_Epochs
  Y軸: Train_Accuracy, Test_Accuracy
  觀察: Gap between Train & Test

診斷標準:
  Gap < 5%: Well-fitted
  5% < Gap < 15%: Mild Overfitting
  Gap > 15%: Severe Overfitting (如 99% vs 65%)

解決方案:
  1. L2 正則化: Loss = DataLoss + 0.001×Σθ²
  2. Dropout(0.5): 訓練時隨機丟棄 50% 神經元
  3. Data Augmentation: 影像旋轉、翻轉、裁剪
  4. Early Stopping: 驗證損失 10 epoch 未改善則停止
```

**效果**：
- 測試準確率提升至 85%（+20%）
- 訓練準確率降至 90%（-9%）
- 泛化差距縮小至 5%

### 4.2 應用場景二：K-Fold 交叉驗證選模型

**場景描述**：比較邏輯迴歸、隨機森林、XGBoost 三種模型，選擇最佳方案。

**技術應用**：5-Fold 交叉驗證 + 性能評估。

**實現要點**：
```
ModelSelection = K-Fold_CV(Models) -> CompareMetrics -> SelectBest

K=5 Cross-Validation:
  For each model in [LogisticRegression, RandomForest, XGBoost]:
      scores = []
      For k in range(5):
          train_data = folds[0:k] + folds[k+1:5]
          val_data = folds[k]
          model.fit(train_data)
          score = model.evaluate(val_data)
          scores.append(score)
      avg_score = mean(scores)
      std_score = std(scores)

評估指標:
  - Accuracy (平均準確率)
  - Std (標準差，反映穩定性)
  - Training Time
```

**實驗結果**：
| 模型 | 平均準確率 | 標準差 | 訓練時間 | 選擇 |
|------|-----------|--------|---------|------|
| Logistic Regression | 82% | 2% | 1s | - |
| Random Forest | 89% | 3% | 10s | - |
| XGBoost | 91% | 2% | 8s | ✓ 選定 |

**結論**：XGBoost 達到最高準確率且穩定性良好，選為最終模型。

### 4.3 應用場景三：偏差-方差權衡調整

**場景描述**：決策樹深度選擇（max_depth = 3, 10, 50）。

**技術應用**：偏差-方差分解分析。

**實現要點**：
```
BiasVarianceAnalysis = TrainModels(Depths) -> DecomposeError -> FindOptimal

實驗設定:
  Depths = [3, 10, 50]
  每個深度訓練 20 次（不同資料子集）
  記錄每次的 Train_Error, Test_Error

誤差分解:
  Bias² = (E[Prediction] - TrueValue)²
  Variance = E[(Prediction - E[Prediction])²]
  Total_Error = Bias² + Variance + Noise
```

**結果分析**：
| max_depth | Bias² | Variance | Total Error | 狀態 |
|-----------|-------|----------|-------------|------|
| 3 | 0.15 | 0.02 | 0.18 | 欠擬合（高偏差） |
| 10 | 0.05 | 0.06 | 0.12 | ✓ 最佳平衡 |
| 50 | 0.02 | 0.25 | 0.28 | 過擬合（高方差） |

**結論**：max_depth=10 達到偏差-方差最佳平衡。

### 4.4 實作步驟

**機器學習專案標準流程**：

1. **資料劃分**：訓練集 60%、驗證集 20%、測試集 20%
2. **基準模型**：訓練簡單模型（如邏輯迴歸）建立基準
3. **模型選擇**：使用 K-Fold CV 比較多種模型
4. **超參數調校**：網格搜尋或貝氏優化
5. **診斷分析**：繪製學習曲線、分析偏差-方差
6. **泛化控制**：應用正則化、Dropout、Early Stopping
7. **最終評估**：在測試集上評估（僅一次）

### 4.5 常見陷阱

**陷阱 1：測試集洩漏**
- **問題**：在模型選擇時多次使用測試集，導致過擬合測試集
- **解決**：測試集僅在最終評估時使用一次，模型選擇用驗證集

**陷阱 2：資料洩漏**
- **問題**：特徵工程時使用全部資料（含測試集）的統計量
- **解決**：標準化等操作僅在訓練集上擬合，測試集使用同一轉換

**陷阱 3：忽略類別不平衡**
- **問題**：100 筆資料中 95 正例 5 負例，模型預測全部為正也有 95% 準確率
- **解決**：使用 Stratified K-Fold、調整類別權重、F1-Score 評估

**陷阱 4：過度依賴單一指標**
- **問題**：僅看 Accuracy 忽略 Precision/Recall
- **解決**：綜合評估多項指標（Accuracy、Precision、Recall、F1、AUC）

**陷阱 5：盲目增加模型複雜度**
- **問題**：欠擬合時直接使用深度神經網路，忽略特徵工程
- **解決**：先嘗試特徵工程、再考慮增加模型複雜度

---

## 5. 記憶口訣 (10%, 200-600字)

### 5.1 核心口訣

**「監督非監強化三範式，偏差方差需權衡」**
- **監督**：有標籤學預測（分類、迴歸）
- **非監**：無標籤探結構（聚類、降維）
- **強化**：獎勵訊號學策略（遊戲、機器人）
- **偏差方差**：欠擬合與過擬合的數學本質

**「訓練驗證測試三分離，交叉驗證保泛化」**
- **訓練集**：學習參數
- **驗證集**：調整超參數
- **測試集**：最終評估（僅用一次）
- **交叉驗證**：K-Fold 充分利用資料

### 5.2 記憶技巧

**偏差-方差口訣**：「簡單高偏差，複雜高方差」
- **簡單模型**（如線性迴歸）：偏差高（Bias↑）、方差低（Variance↓）→ 欠擬合
- **複雜模型**（如深度神經網路）：偏差低（Bias↓）、方差高（Variance↑）→ 過擬合
- **目標**：找到偏差與方差平衡點

**過擬合診斷口訣**：「訓練高測試低，過擬合警報響」
```
Train_Acc = 99%, Test_Acc = 65% → Overfitting
Train_Acc = 70%, Test_Acc = 68% → Underfitting
Train_Acc = 88%, Test_Acc = 85% → Well-fitted
```

**正則化選擇**：「L1 稀疏化，L2 平滑化」
- **L1**（Lasso）：Σ|θ| → 參數歸零（稀疏）
- **L2**（Ridge）：Σθ² → 參數縮小（平滑）

**K-Fold 記憶**：「切 K 份輪流驗，平均結果最可靠」
```
K=5: 80% 訓練 + 20% 驗證，重複 5 次
結果: 平均 5 次準確率
```

### 5.3 快速回憶

**學習範式速配**：
- **有標籤** → 監督學習（分類/迴歸）
- **無標籤** → 非監督學習（聚類/降維）
- **獎勵訊號** → 強化學習（策略學習）

**誤差分解公式**：
```
Total_Error = Bias² + Variance + Noise
欠擬合 → Bias↑
過擬合 → Variance↑
```

**資料劃分比例**：
- **標準**：60% 訓練 + 20% 驗證 + 20% 測試
- **大資料**：98% 訓練 + 1% 驗證 + 1% 測試
- **小資料**：K-Fold CV（無 hold-out）

### 5.4 易混淆辨析

**訓練集 vs 驗證集 vs 測試集**：
- **訓練集**：學習模型參數（權重、偏差）
- **驗證集**：調整超參數（學習率、正則化強度）、模型選擇
- **測試集**：最終評估泛化能力（僅使用一次）

**過擬合 vs 欠擬合**：
- **過擬合**：訓練好測試差（記住訓練資料）
- **欠擬合**：訓練差測試差（未學到規律）

**偏差 vs 方差**：
- **偏差**：模型預測偏離真實值（系統性誤差）
- **方差**：模型在不同訓練集上預測的變異（隨機誤差）

**K-Fold vs Hold-out**：
- **K-Fold**：資料利用率 100%、結果穩定、計算成本高
- **Hold-out**：資料利用率低、計算快速、結果方差大

---

## 6. 自我驗證 (10%, 200-600字)

### 6.1 選擇題

**Q1：以下哪種學習範式需要標籤資料？**
A. 監督學習
B. 非監督學習
C. 強化學習
D. 遷移學習

**Q2：模型在訓練集上準確率 99%、測試集上準確率 65%，這是什麼問題？**
A. 欠擬合
B. 過擬合
C. 資料不足
D. 正常現象

**Q3：偏差-方差分解中，增加模型複雜度會導致？**
A. 偏差增加、方差減少
B. 偏差減少、方差增加
C. 偏差與方差皆增加
D. 偏差與方差皆減少

**Q4：5-Fold 交叉驗證需要訓練模型幾次？**
A. 1 次
B. 5 次
C. 10 次
D. 取決於資料量

**Q5：以下哪個正則化方法會產生稀疏性（參數歸零）？**
A. L2 正則化（Ridge）
B. L1 正則化（Lasso）
C. Dropout
D. Batch Normalization

### 6.2 簡答題

**Q1：解釋偏差-方差權衡（Bias-Variance Tradeoff），並說明如何透過調整模型複雜度平衡兩者。**

**Q2：為什麼測試集只能使用一次？如果多次使用測試集調整模型會有什麼問題？**

### 6.3 答案解析

**選擇題答案**：

**A1：A（監督學習）**
- **解析**：監督學習需要標籤資料（X, Y），學習從輸入 X 預測標籤 Y 的映射函數。非監督學習無標籤（僅 X），強化學習使用獎勵訊號（非直接標籤）。

**A2：B（過擬合）**
- **解析**：訓練集準確率極高（99%）但測試集準確率低（65%），表示模型過度擬合訓練資料，未能泛化到新資料。典型的過擬合特徵是訓練-測試差距大（> 15%）。

**A3：B（偏差減少、方差增加）**
- **解析**：增加模型複雜度（如增加神經網路層數）使模型擬合能力增強，降低偏差（Bias↓），但同時增加對訓練資料的敏感度，提高方差（Variance↑）。這是偏差-方差權衡的核心。

**A4：B（5 次）**
- **解析**：K-Fold 交叉驗證將資料分為 K 份，每次用 K-1 份訓練、1 份驗證，共訓練 K 次模型。5-Fold 即訓練 5 次，每份資料都當過一次驗證集。

**A5：B（L1 正則化 Lasso）**
- **解析**：L1 正則化對參數絕對值進行懲罰（Σ|θ_i|），導致許多參數收斂至 0，產生稀疏解。L2 正則化（Σθ_i²）僅平滑縮小參數但不歸零。

**簡答題答案**：

**A1：偏差-方差權衡**

**定義**：
- **偏差（Bias）**：模型預測的期望值與真實值的偏差，反映模型的假設限制
- **方差（Variance）**：模型在不同訓練集上預測的變異程度，反映模型對訓練資料的敏感度
- **誤差分解**：Total Error = Bias² + Variance + Noise

**權衡關係**：
- **簡單模型**（如線性迴歸）：
  - 偏差高（Bias↑）：無法捕捉複雜規律（欠擬合）
  - 方差低（Variance↓）：不同訓練集預測穩定

- **複雜模型**（如深度神經網路）：
  - 偏差低（Bias↓）：可擬合複雜規律
  - 方差高（Variance↑）：對訓練資料過度敏感（過擬合）

**平衡方法**：
1. **調整模型複雜度**：
   - 欠擬合 → 增加複雜度（增加特徵、深度、寬度）
   - 過擬合 → 降低複雜度或加正則化

2. **正則化技術**：
   - L1/L2 正則化：懲罰過大參數
   - Dropout：隨機丟棄神經元
   - Early Stopping：驗證損失不再下降時停止

3. **增加訓練資料**：
   - 更多資料降低方差，改善過擬合

**最佳點**：
```
Optimal = argmin(Bias² + Variance)
```
在偏差與方差之間找到最小化總誤差的平衡點。

**A2：測試集使用限制**

**為什麼測試集只能使用一次？**

測試集的目的是評估模型在「完全未見資料」上的泛化能力，模擬真實應用場景。如果多次使用測試集進行模型調整，會導致：

**1. 過擬合測試集**：
- 模型調整過程會逐漸「記住」測試集的特性
- 測試集不再代表「未見資料」，失去評估泛化能力的意義
- 測試準確率虛高，實際部署後效能下降

**2. 資訊洩漏**：
- 測試集的資訊間接影響模型設計（如選擇在測試集表現好的模型）
- 違反「訓練與測試資料獨立」的基本原則

**3. 評估偏差**：
- 最終報告的測試準確率不再可信
- 無法預測模型在真實新資料上的表現

**正確做法**：
```
資料劃分：
  Training Set (60%): 訓練模型參數
  Validation Set (20%): 調整超參數、模型選擇（可多次使用）
  Test Set (20%): 最終評估（僅使用一次）

流程：
  1. 在訓練集上訓練多種模型
  2. 在驗證集上比較模型、調整超參數（可反覆試驗）
  3. 選定最佳模型後，在測試集上評估一次
  4. 報告測試集結果作為最終泛化能力
```

**類比**：
測試集就像「期末考試」，你可以用「練習題」（驗證集）反覆練習，但「考試題目」（測試集）只能考一次，否則無法真實評估你的能力。

### 6.4 易錯點提醒

**易錯點 1：混淆訓練集與驗證集用途**
- **錯誤**：在訓練集上調整超參數
- **提醒**：超參數調整必須在驗證集上進行

**易錯點 2：多次使用測試集**
- **錯誤**：模型 A 測試準確率 80%、模型 B 85%，選 B 後再測試
- **提醒**：測試集僅最終評估一次

**易錯點 3：資料洩漏**
- **錯誤**：用全部資料計算均值標準差再劃分訓練/測試
- **提醒**：標準化僅在訓練集上擬合

**易錯點 4：忽略偏差-方差診斷**
- **錯誤**：過擬合時盲目增加資料
- **提醒**：先診斷是高偏差還是高方差，對症下藥

**易錯點 5：交叉驗證用於超參數調校後未重新訓練**
- **錯誤**：K-Fold 選出最佳超參數後直接使用其中一折的模型
- **提醒**：應用選定的超參數在全部訓練資料上重新訓練
