# L23401 - 數據隱私安全合規

## 1. 核心定義 (20%)

數據隱私安全合規是機器學習應用中不可忽視的法律與倫理議題,涵蓋數據隱私保護法規（GDPR、個資法）、差分隱私（Differential Privacy）、聯邦學習（Federated Learning）、數據匿名化技術、模型加密與安全部署、隱私洩漏風險等。核心挑戰是在保護個人隱私與充分利用數據之間取得平衡,確保AI系統符合法規要求並維護用戶信任。

### CFDS分解
```
PrivacySecurity = f(C, F, D, S)
C = DataAnonymization ∘ DifferentialPrivacy ∘ FederatedLearning ∘ EncryptedComputation
F = {PrivacyBudget, EncryptionKeys, AuditLogs, ComplianceConfig}
D = RawData + AnonymizedData + EncryptedData + AggregatedStatistics
S = Collecting | Anonymizing | Training | Auditing | Compliant
```

---

## 2. 關鍵公式 (25%)

### 2.1 差分隱私（Differential Privacy）

**ε-差分隱私定義**:
```
機制M滿足ε-差分隱私,若對任意相鄰資料集D和D'（僅差一筆記錄）:

Pr[M(D) ∈ S] ≤ e^ε × Pr[M(D') ∈ S]

其中:
- ε: 隱私預算（越小隱私保護越強）
  ε < 0.1: 極強隱私
  ε ≈ 1: 強隱私
  ε > 10: 弱隱私
- S: 任意輸出集合

直觀解釋:
  加入或移除單筆記錄,輸出分佈變化有限（e^ε倍）
  攻擊者難以判斷某筆記錄是否在資料集中
```

**拉普拉斯機制（Laplace Mechanism）**:
```
查詢函數f: D -> R（如：平均值、計數）

加噪輸出:
M(D) = f(D) + Lap(Δf/ε)

其中:
- Δf: 全域敏感度（單筆記錄改變對f的最大影響）
  Δf = max_{D,D'} |f(D) - f(D')|

- Lap(b): 拉普拉斯噪音,參數b
  PDF: p(x) = (1/2b) exp(-|x|/b)

範例（計數查詢）:
  f(D) = count(D中滿足條件的記錄)
  Δf = 1（加減一筆記錄,計數變化1）
  M(D) = count + Lap(1/ε)

  若ε=1, 噪音標準差 = √2
```

**高斯機制（Gaussian Mechanism）**:
```
M(D) = f(D) + N(0, σ²)

其中σ² = 2ln(1.25/δ) × (Δf)² / ε²

滿足(ε, δ)-差分隱私（較弱,允許δ機率失效）

適用: 深度學習梯度噪音
```

**組合性（Composition）**:
```
順序組合:
  M₁滿足ε₁-DP, M₂滿足ε₂-DP
  則M₁和M₂順序執行滿足(ε₁+ε₂)-DP

隱私預算消耗:
  總預算ε_total固定（如ε=1）
  每次查詢消耗ε/K（K次查詢）

實務:
  隱私預算用完後,拒絕進一步查詢
```

### 2.2 聯邦學習（Federated Learning）

**聯邦平均（FedAvg）**:
```
中央伺服器協調,客戶端本地訓練

流程:
1. 伺服器廣播全局模型w_t
2. 每個客戶端k本地訓練:
   w_t^k <- w_t - η∇L_k(w_t; D_k)  # 本地資料D_k
3. 伺服器聚合:
   w_{t+1} = Σ_k (n_k/n) w_t^k  # n_k為客戶端k資料量

優勢:
- 資料不離開本地（隱私保護）
- 分散式計算（擴展性）

挑戰:
- 通訊成本（需多輪通訊）
- 異質資料（各客戶端分佈不同）
```

**安全聚合（Secure Aggregation）**:
```
目標: 伺服器僅看到聚合結果,看不到單個客戶端更新

方法:
1. 每個客戶端加密其更新
2. 伺服器聚合加密更新
3. 解密僅得聚合結果

數學:
w_{t+1} = Decrypt(Σ_k Encrypt(w_t^k))

實現: 同態加密、秘密共享
```

### 2.3 數據匿名化

**K-匿名性（K-Anonymity）**:
```
定義: 資料集中,每筆記錄至少與K-1筆其他記錄在準識別符上不可區分

準識別符（Quasi-Identifiers）:
  年齡、郵遞區號、性別等可能識別個人的屬性組合

範例（K=3）:
  原始資料:
  | Age | ZIP   | Gender | Disease |
  |-----|-------|--------|---------|
  | 25  | 10001 | M      | 流感    |
  | 26  | 10001 | M      | 糖尿病  |
  | 25  | 10002 | M      | 心臟病  |

  泛化後（K=3匿名）:
  | Age   | ZIP   | Gender | Disease |
  |-------|-------|--------|---------|
  | 20-30 | 1000* | M      | 流感    |
  | 20-30 | 1000* | M      | 糖尿病  |
  | 20-30 | 1000* | M      | 心臟病  |

  每筆記錄與至少2筆其他記錄不可區分
```

**L-多樣性（L-Diversity）**:
```
解決K-匿名不足:
  即使K-匿名,敏感屬性缺乏多樣性仍可推斷

定義: 每個等價類中,敏感屬性至少有L個不同值

範例（L=3）:
  | 等價類 | Disease  |
  |--------|----------|
  | 組1    | 流感     |
  | 組1    | 糖尿病   |
  | 組1    | 心臟病   | ✓ L=3多樣性

  vs 缺乏多樣性:
  | 組2    | 流感     |
  | 組2    | 流感     |
  | 組2    | 感冒     | ✗ 僅2種疾病
```

---

## 3. 對比矩陣 (15%)

### 隱私保護技術對比

| 技術 | 隱私強度 | 效用損失 | 適用場景 | 計算成本 |
|------|---------|---------|---------|---------|
| 差分隱私 | 數學保證 | 中（噪音） | 統計查詢 | 低 |
| 聯邦學習 | 高（資料不共享） | 低 | 分散式訓練 | 高（通訊） |
| 同態加密 | 極高 | 中 | 加密計算 | 極高 |
| K-匿名 | 中 | 高（泛化） | 資料發布 | 低 |

### 法規對比

| 法規 | 地區 | 核心要求 | 罰則 | 適用範圍 |
|------|------|---------|------|---------|
| GDPR | 歐盟 | 同意、可攜、被遺忘權 | 營收4%或2000萬歐元 | 處理歐盟居民資料 |
| 個資法 | 台灣 | 告知同意、安全維護 | 刑事+民事 | 台灣境內 |
| CCPA | 美國加州 | 知情權、刪除權 | $7500/違規 | 加州居民 |

---

## 4. 實務應用 (20%)

### 4.1 差分隱私實現

```python
import numpy as np

def laplace_mechanism(true_value, sensitivity, epsilon):
    """拉普拉斯機制"""
    scale = sensitivity / epsilon
    noise = np.random.laplace(0, scale)
    return true_value + noise

# 範例: 計算平均年齡（ε=1）
ages = [25, 30, 35, 40, 45]
true_mean = np.mean(ages)  # 35
sensitivity = (max(ages) - min(ages)) / len(ages)  # 4

private_mean = laplace_mechanism(true_mean, sensitivity, epsilon=1)
print(f"真實均值: {true_mean}, 差分隱私均值: {private_mean:.2f}")
# 真實均值: 35, 差分隱私均值: 36.21（噪音影響）

# 多次查詢消耗預算
epsilon_total = 1.0
num_queries = 10
epsilon_per_query = epsilon_total / num_queries  # 0.1

for i in range(num_queries):
    private_value = laplace_mechanism(true_mean, sensitivity, epsilon_per_query)
    print(f"查詢{i+1}: {private_value:.2f}")
```

### 4.2 聯邦學習模擬

```python
import torch
import torch.nn as nn

def federated_averaging(global_model, client_models, client_data_sizes):
    """聯邦平均聚合"""
    total_size = sum(client_data_sizes)

    # 加權平均
    global_state = global_model.state_dict()
    for key in global_state.keys():
        global_state[key] = torch.zeros_like(global_state[key])
        for client_model, data_size in zip(client_models, client_data_sizes):
            weight = data_size / total_size
            global_state[key] += weight * client_model.state_dict()[key]

    global_model.load_state_dict(global_state)
    return global_model

# 模擬聯邦學習
global_model = SimpleNN()
client_models = [SimpleNN() for _ in range(5)]
client_data_sizes = [1000, 800, 1200, 900, 1100]

for round in range(10):
    # 1. 廣播全局模型
    for client_model in client_models:
        client_model.load_state_dict(global_model.state_dict())

    # 2. 客戶端本地訓練
    for i, client_model in enumerate(client_models):
        train_local(client_model, client_data[i])  # 本地資料

    # 3. 聚合
    global_model = federated_averaging(global_model, client_models, client_data_sizes)

    print(f"Round {round+1} complete")
```

### 4.3 數據匿名化

```python
import pandas as pd

def k_anonymize(df, quasi_identifiers, k=3):
    """簡單K-匿名化（泛化）"""
    df_anon = df.copy()

    # 年齡泛化（10歲區間）
    if 'Age' in quasi_identifiers:
        df_anon['Age'] = (df_anon['Age'] // 10) * 10
        df_anon['Age'] = df_anon['Age'].astype(str) + '-' + (df_anon['Age'] + 9).astype(str)

    # 郵遞區號泛化（前3碼）
    if 'ZIP' in quasi_identifiers:
        df_anon['ZIP'] = df_anon['ZIP'].astype(str).str[:3] + '**'

    # 檢查K-匿名性
    group_sizes = df_anon.groupby(quasi_identifiers).size()
    if (group_sizes < k).any():
        print(f"警告: 部分組別小於K={k}")

    return df_anon

# 範例
df = pd.DataFrame({
    'Age': [25, 26, 27, 35, 36, 37],
    'ZIP': ['10001', '10002', '10003', '20001', '20002', '20003'],
    'Disease': ['流感', '糖尿病', '心臟病', '高血壓', '流感', '糖尿病']
})

df_anon = k_anonymize(df, ['Age', 'ZIP'], k=3)
print(df_anon)
"""
    Age     ZIP   Disease
0  20-29   100**  流感
1  20-29   100**  糖尿病
2  20-29   100**  心臟病
3  30-39   200**  高血壓
4  30-39   200**  流感
5  30-39   200**  糖尿病
"""
```

---

## 5. 記憶口訣 (10%)

**「差分加噪隱私強,聯邦學習資料留家鄉」**
- 差分隱私: 加拉普拉斯噪音,ε控制隱私強度
- 聯邦學習: 資料不離開客戶端,僅共享模型更新

**「GDPR歐盟嚴,個資法台灣管,同意告知是關鍵」**
- GDPR: 歐盟,營收4%罰款
- 個資法: 台灣,刑事+民事責任
- 核心: 告知同意、安全維護、被遺忘權

**「K-匿名泛化資料,L-多樣保護敏感」**
- K-匿名: 每筆記錄至少K-1筆不可區分
- L-多樣性: 敏感屬性至少L種不同值

---

## 6. 自我驗證 (10%)

**Q1: 差分隱私的隱私預算ε越小,表示?**
A. 隱私保護越強
B. 隱私保護越弱
C. 噪音越小
D. 效用越高

**答案: A（隱私保護越強）**
解析: ε越小,加入的噪音越大,攻擊者越難推斷個人資訊,但效用損失也越大。

**Q2: 聯邦學習的主要優勢是?**
A. 訓練速度快
B. 資料不需離開本地
C. 模型準確率高
D. 無需標籤資料

**答案: B（資料不需離開本地）**
解析: 聯邦學習資料留在客戶端,僅共享模型更新,保護資料隱私。

**Q3: GDPR的最高罰款額度是?**
A. 營收2%或1000萬歐元
B. 營收4%或2000萬歐元
C. 營收10%或5000萬歐元
D. 固定100萬歐元

**答案: B（營收4%或2000萬歐元）**
解析: GDPR嚴重違規最高罰款為年營收4%或2000萬歐元,取較高者。

**簡答: 解釋差分隱私的ε-δ參數意義,並說明如何選擇合適的ε值。**

**答案:**

**ε-差分隱私參數:**

**ε（epsilon,隱私預算）:**
- 定義: 控制隱私保護強度的參數
- 數學意義: Pr[M(D)∈S] ≤ e^ε × Pr[M(D')∈S]
- ε越小 -> 隱私保護越強（更難區分D和D'）
- ε越大 -> 效用越高（噪音越小）

**典型ε值:**
- ε < 0.1: 極強隱私（學術標準）
- ε ≈ 1: 強隱私（實務推薦）
- ε = 5-10: 中等隱私
- ε > 10: 弱隱私（接近無保護）

**δ（delta,失效機率）:**
- 定義: 差分隱私保證失效的機率
- (ε, δ)-DP: 以1-δ機率滿足ε-DP
- 通常δ < 1/N²（N為資料筆數）

**選擇合適ε值:**

1. **考慮敏感度**:
   - 醫療、金融資料: ε < 1
   - 一般個人資料: ε = 1-5
   - 非敏感資料: ε > 5

2. **平衡隱私與效用**:
   - 效用要求高: 增大ε
   - 隱私要求高: 減小ε

3. **預算分配**:
   - 總預算ε_total固定（如1.0）
   - K次查詢: 每次ε/K

4. **法規要求**:
   - GDPR等法規可能要求特定ε範圍
   - 參考行業最佳實踐

**易錯點提醒:**
1. 混淆ε大小與隱私強度（ε小=隱私強）
2. 忽略隱私預算消耗（多次查詢累積）
3. K-匿名假設攻擊者無背景知識（不足夠安全）
4. 聯邦學習未加密更新（模型更新可能洩漏資訊）
5. GDPR適用範圍（處理歐盟居民資料,非僅歐盟公司）
