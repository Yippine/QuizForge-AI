# L21203 - AI風險管理

## 1. 核心定義 (20%, 400-1200字)

### 1.1 主題定義

AI風險管理是在AI系統導入與運營全生命週期中,針對技術、資料、法規、倫理、組織等多重層面的潛在風險,進行系統化識別、評估、緩解與持續監控的治理過程。其核心目標是確保AI系統在技術穩定性、法規合規性、倫理正當性與社會可信賴性等面向均能達標,避免因風險管控不當導致專案失敗、法律責任、聲譽損害或社會負面影響。

不同於傳統IT專案,AI風險具有更高的複雜性與不確定性。資料品質直接影響模型可靠性,演算法黑箱特性導致透明度不足,模型在動態環境中可能漂移失效,個資處理涉及嚴格法規,而決策偏誤更可能引發社會公平性爭議。因此,AI風險管理需從規劃階段便前瞻性納入,並貫穿開發、測試、部署、營運的全生命週期,形成持續治理體系。

### 1.2 核心概念

**AI風險管理的五大核心概念:**

1. **風險識別(Risk Identification)**:辨識技術、資料、法規、倫理、組織等層面潛在風險來源與類型
2. **法規合規(Compliance Assessment)**:確保AI系統符合GDPR、個資法、產業法規等法律要求
3. **模型偏誤管理(Bias Management)**:檢測與緩解資料、標註、演算法層面的偏見與歧視性結果
4. **透明度與可解釋性(Transparency & Explainability)**:提升AI決策過程的可理解性與可追溯性
5. **持續監控與治理(Continuous Monitoring & Governance)**:建立AI治理委員會、監控機制與回饋優化流程

### 1.3 CFDS 分解

基於 Formula-Contract 方法論,將AI風險管理過程分解為四個基本單元:

```
AI_RiskManagement = f(C, F, D, S)
```

**C (Code - 可執行邏輯)**
```
C = RiskIdentification ∘ ComplianceAssessment ∘ BiasDetection ∘ MitigationPlanning ∘ ContinuousMonitoring
  = 風險識別 -> 合規評估 -> 偏誤檢測 -> 緩解規劃 -> 持續監控
```

**F (Files - 配置資源)**
```
F = {風險登記簿, 合規檢核表, 偏誤評估工具, 倫理準則, 監控儀表板, 治理政策}
```

**D (Data - 資料結構)**
```
D = RiskRegistry + ComplianceStatus + BiasMetrics + AuditLogs + IncidentReports
  = 風險清單 + 合規狀態 + 偏誤指標 + 稽核日誌 + 事件報告
```

**S (State - 運行狀態)**
```
S = RiskAssessment | Mitigation | Monitoring | Incident | Review
  = 風險評估中 | 緩解執行中 | 持續監控 | 事件處理 | 定期審查
```

### 1.4 技術定位

AI風險管理在AI專案生命週期中處於「全程治理」的角色,是從規劃、開發、部署到營運各階段的橫向支撐機制。風險管理品質直接影響專案成敗、法規合規與社會信任,是AI治理(AI Governance)的核心環節。

在企業AI轉型中,風險管理扮演安全閘門與信任建立的角色,協助組織在創新與風險間取得平衡,確保AI系統在技術、法律、倫理三重框架下穩健運行,並維持長期競爭力與社會責任。

---

## 2. 關鍵公式 (25%, 500-1500字)

### 2.1 AI風險管理核心流程公式

```
AI_RiskManagement = RiskIdentification -> ComplianceCheck -> BiasEvaluation -> MitigationExecution -> ContinuousGovernance

詳細展開:
  RiskIdentification = TechnicalRisk + OrganizationalRisk + RegulatoryRisk + EthicalRisk
  ComplianceCheck = LegalRequirements × IndustryStandards × InternalPolicies
  BiasEvaluation = DataBias + LabelingBias + AlgorithmicBias -> FairnessMetrics
  MitigationExecution = RiskPrioritization -> ControlImplementation -> ValidationTest
  ContinuousGovernance = Monitoring + AuditTrail + IncidentResponse + PeriodicReview
```

### 2.2 風險評分公式

**風險優先級矩陣:**
```
Risk_Score = Probability(發生機率) × Impact(影響程度) × Detectability(可偵測性倒數)

機率分級(1-5):
  1 = 極低(< 10%)
  2 = 低(10-30%)
  3 = 中(30-50%)
  4 = 高(50-70%)
  5 = 極高(> 70%)

影響分級(1-5):
  1 = 微小(可忽略)
  2 = 輕微(輕微延誤/成本)
  3 = 中度(顯著影響)
  4 = 嚴重(專案受阻)
  5 = 災難(專案失敗/法律責任)

可偵測性(1-5,分數越低越易偵測):
  1 = 易於偵測(自動監控)
  2 = 可偵測(定期檢查)
  3 = 中等偵測難度
  4 = 難以偵測(需專業稽核)
  5 = 極難偵測(隱藏風險)

風險分類:
  Score 1-25: 低風險(綠燈) -> 常規監控
  Score 26-50: 中風險(黃燈) -> 強化監控與緩解
  Score 51-75: 高風險(橙燈) -> 立即緩解措施
  Score 76-125: 極高風險(紅燈) -> 專案暫停/重新設計
```

### 2.3 資料品質風險評估公式

**資料就緒度與風險評分:**
```
Data_Risk = (1 - Data_Quality) × Data_Criticality

Data_Quality = Completeness × Accuracy × Consistency × Timeliness
  Completeness = 完整資料筆數 / 總資料筆數
  Accuracy = 正確資料筆數 / 總資料筆數
  Consistency = 一致性檢查通過筆數 / 總資料筆數
  Timeliness = 即時資料筆數 / 總需求筆數

Data_Criticality = BusinessImpact × ModelDependency
  BusinessImpact(1-10): 資料對業務決策的影響程度
  ModelDependency(1-10): 模型對該資料的依賴程度

風險閾值:
  Data_Risk < 20 -> 低風險,可接受
  Data_Risk 20-50 -> 中風險,需改善資料品質
  Data_Risk 50-80 -> 高風險,需重新收集或清理資料
  Data_Risk > 80 -> 極高風險,不建議使用該資料集
```

### 2.4 模型偏誤檢測公式

**公平性指標(Fairness Metrics):**
```
1. 統計平等性(Demographic Parity):
   DP = |P(Ŷ=1|A=0) - P(Ŷ=1|A=1)|
   其中 A 為敏感屬性(如性別、種族), Ŷ 為預測結果
   DP < 0.1 -> 模型在不同群體間預測率差異可接受

2. 機會均等(Equalized Odds):
   EO = |P(Ŷ=1|Y=1,A=0) - P(Ŷ=1|Y=1,A=1)|
   衡量真陽性率在不同群體間的差異
   EO < 0.1 -> 模型對不同群體的敏感度公平

3. 預測價值均等(Predictive Parity):
   PP = |P(Y=1|Ŷ=1,A=0) - P(Y=1|Ŷ=1,A=1)|
   衡量預測為正的準確率在不同群體間的差異
   PP < 0.1 -> 模型預測結果對不同群體同等可靠

偏誤綜合評分:
  Bias_Score = (DP + EO + PP) / 3
  Bias_Score < 0.05 -> 低偏誤
  Bias_Score 0.05-0.15 -> 中偏誤,需監控
  Bias_Score > 0.15 -> 高偏誤,需重新訓練或調整
```

### 2.5 法規合規評估公式

**合規覆蓋率計算:**
```
Compliance_Coverage = Implemented_Controls / Required_Controls × 100%

Required_Controls = GDPR_Requirements + Industry_Regulations + Internal_Policies

GDPR 核心要求(範例):
  - 資料主體同意機制
  - 資料最小化原則
  - 刪除權/遺忘權實作
  - 資料可攜權支援
  - 自動化決策反對權
  - 資料保護影響評估(DPIA)
  - 資料外洩通報機制

合規成熟度分級:
  Coverage < 60% -> 不合規(高風險)
  Coverage 60-80% -> 部分合規(需改善)
  Coverage 80-95% -> 基本合規(持續監控)
  Coverage > 95% -> 高度合規(最佳實務)
```

### 2.6 風險緩解成本效益公式

**風險緩解投資決策:**
```
Mitigation_ROI = (Risk_Reduction_Value - Mitigation_Cost) / Mitigation_Cost × 100%

Risk_Reduction_Value = Risk_Before - Risk_After
  Risk_Before = Probability_Before × Impact_Before
  Risk_After = Probability_After × Impact_After

決策準則:
  Mitigation_ROI > 100% -> 高價值緩解措施,立即執行
  Mitigation_ROI 50-100% -> 中價值,優先排序執行
  Mitigation_ROI 0-50% -> 低價值,評估替代方案
  Mitigation_ROI < 0 -> 成本高於效益,需重新評估

範例:
  風險前: P=0.6 × I=100萬 = 60萬
  風險後: P=0.1 × I=100萬 = 10萬
  緩解成本: 20萬
  ROI = (50萬 - 20萬) / 20萬 = 150% -> 建議執行
```

---

## 3. 對比矩陣 (15%, 300-900字)

### 3.1 AI風險類型對比表

| 風險類型 | 主要來源 | 常見問題 | 影響範圍 | 偵測難度 | 緩解策略 |
|---------|---------|---------|---------|---------|---------|
| **技術風險** | 資料品質、模型穩定性 | 資料漂移、過擬合、模型失效 | 系統準確度、可靠性 | 中 | 資料稽核、模型監控、A/B測試 |
| **法規風險** | 個資法、GDPR、產業法規 | 未取得同意、資料外洩、合規不足 | 法律責任、罰款、營運中斷 | 低 | 法規檢核、DPIA、合規稽核 |
| **倫理風險** | 資料偏誤、演算法歧視 | 性別/種族歧視、不公平決策 | 社會信任、品牌聲譽 | 高 | 公平性評估、多元資料、倫理審查 |
| **組織風險** | 跨部門協作、技能缺口 | 溝通不良、變革抵制、人才流失 | 專案延誤、成效不彰 | 中 | 溝通機制、培訓計畫、變革管理 |
| **安全風險** | 資料外洩、模型攻擊 | 對抗性攻擊、資料竊取、隱私侵犯 | 資安事件、信任危機 | 高 | 加密、存取控制、對抗性測試 |

### 3.2 法規合規對比

| 法規/標準 | 適用範圍 | 核心要求 | 罰則 | AI特殊考量 |
|---------|---------|---------|------|----------|
| **GDPR** | 歐盟居民個資 | 同意、刪除權、可攜權、DPIA | 最高€2000萬或營收4% | 自動化決策反對權、可解釋性 |
| **台灣個資法** | 台灣境內個資 | 告知義務、當事人權利、安全維護 | 最高200萬、刑事責任 | 個資蒐集目的限制 |
| **HIPAA** | 美國醫療資訊 | 技術、實體、行政保護措施 | 最高$150萬/年 | 健康資料加密、存取日誌 |
| **PCI-DSS** | 支付卡資訊 | 加密、存取控管、滲透測試 | 停止處理資格、罰款 | 支付預測需符合安全標準 |

### 3.3 偏誤來源與緩解對比

| 偏誤來源 | 產生原因 | 典型案例 | 檢測方法 | 緩解策略 |
|---------|---------|---------|---------|---------|
| **資料偏誤** | 樣本不均、代表性不足 | 招聘系統偏好男性履歷 | 群體分布分析、DP指標 | 資料平衡、多元收集 |
| **歷史偏誤** | 歷史資料反映既有歧視 | 信用評分歧視少數族裔 | 歷史資料稽核、公平性測試 | 去偏誤演算法、公平性約束 |
| **標註偏誤** | 標註者主觀判斷 | 情感分析對特定群體誤判 | 標註一致性檢查、多人標註 | 標註準則、品質控制 |
| **演算法偏誤** | 演算法優化全體犧牲少數 | 推薦系統忽略小眾需求 | 子群體效能評估 | 公平性正則化、多目標優化 |

### 3.4 風險緩解策略對比

| 緩解策略 | 實施時機 | 成本 | 效果 | 適用風險 |
|---------|---------|------|------|---------|
| **預防性控制** | 設計階段 | 低 | 高 | 技術、資料、法規風險 |
| **偵測性控制** | 營運階段 | 中 | 中 | 模型漂移、異常偵測 |
| **矯正性控制** | 事件發生後 | 高 | 低 | 資料外洩、合規違規 |
| **補償性控制** | 主要控制失效時 | 中 | 中 | 備援機制、人工審查 |

### 3.5 AI治理成熟度對比

| 成熟度級別 | 風險管理狀態 | 治理特徵 | 典型組織 |
|-----------|-------------|---------|---------|
| **Level 1: 初始** | 被動反應、無系統化管理 | 風險發生後才處理 | AI導入初期組織 |
| **Level 2: 可重複** | 專案層級管理、部分文件化 | 基本風險登記簿 | 多個AI專案經驗 |
| **Level 3: 已定義** | 標準化流程、全組織政策 | AI治理委員會、倫理準則 | 系統化AI應用企業 |
| **Level 4: 量化管理** | 指標化監控、資料驅動決策 | 自動化監控、KPI追蹤 | AI成熟度高的組織 |
| **Level 5: 持續優化** | 前瞻性治理、持續改進 | 業界最佳實務、創新治理 | AI領先企業 |

---

## 4. 實務應用 (20%, 400-1200字)

### 4.1 應用場景一:金融業信用評分AI風險管理

**場景描述**:銀行導入AI信用評分系統,需確保符合法規、避免歧視性決策。

**風險管理流程:**
```
Step1: 風險識別
  技術風險: 資料品質(缺失值15%,需處理)、模型漂移(經濟環境變化)
  法規風險: 個資法、金管會規範、公平信貸法
  倫理風險: 性別/年齡歧視、少數族裔不公平待遇

Step2: 法規合規評估
  GDPR/個資法: 需取得同意、提供決策解釋
  金融法規: 符合Basel III風險管理框架
  實施措施:
    - 資料匿名化處理
    - DPIA評估完成
    - 自動化決策反對權機制建立

Step3: 模型偏誤檢測
  公平性測試:
    DP(性別) = |P(核准|男) - P(核准|女)| = 0.18 > 0.1 -> 偏誤警示
    EO(族裔) = 0.22 > 0.1 -> 高偏誤
  偏誤來源分析: 歷史資料反映既有歧視(男性核准率較高)

Step4: 緩解措施執行
  資料層:
    - 重新平衡訓練資料(男女比例1:1)
    - 移除敏感特徵(性別、種族)的直接使用
  模型層:
    - 引入公平性約束(Fairness Constraints)
    - 使用Adversarial Debiasing技術
  流程層:
    - 人工審查機制(高風險案件)
    - 客戶申訴管道

Step5: 持續監控與治理
  每月監控:
    - 公平性指標(DP, EO, PP)
    - 模型準確率(AUC, F1-Score)
    - 客訴案件分析
  季度審查:
    - 風險登記簿更新
    - 法規變動檢查
    - 倫理委員會審查

執行成果:
  - DP降至0.08, EO降至0.09 -> 偏誤顯著降低
  - 法規合規覆蓋率95%
  - 客訴率下降40%
  - 模型AUC維持0.82(未因公平性調整而顯著下降)
```

### 4.2 應用場景二:醫療AI診斷系統風險管理

**場景描述**:醫院導入AI影像診斷系統,需確保安全性、準確性與法規合規。

**風險管理流程:**
```
Step1: 風險識別
  技術風險:
    - 模型誤診(假陰性風險高,錯過病症)
    - 資料品質(影像標註錯誤率3%)
    - 模型泛化性(不同醫院設備差異)
  法規風險:
    - HIPAA合規(美國)、醫療器材管理法(台灣)
    - 醫療個資保護
  倫理風險:
    - 過度依賴AI導致醫師技能退化
    - 弱勢群體(罕見疾病)診斷準確度不足

Step2: 法規合規措施
  HIPAA要求:
    - 資料加密(傳輸與儲存)
    - 存取控制(僅授權醫護人員)
    - 稽核日誌(所有存取紀錄)
  醫療器材法:
    - 臨床試驗驗證
    - TFDA上市許可申請
    - 不良事件通報機制

Step3: 技術風險緩解
  誤診風險:
    - 設定保守閾值(降低假陰性,寧願多轉人工)
    - 雙重確認機制(AI+醫師覆核)
    - 高風險病症強制人工審查
  資料品質:
    - 邀請資深醫師重新標註
    - 多專家標註一致性檢查
    - 標註準確率提升至98%
  泛化性:
    - 多中心資料收集(10家醫院)
    - 資料增強技術(旋轉、翻轉、對比調整)
    - 遷移學習適應新設備

Step4: 倫理風險管理
  醫師培訓:
    - AI輔助使用教育訓練
    - 維持醫師最終決策權
    - 鼓勵批判性使用AI建議
  弱勢保障:
    - 罕見疾病資料擴充
    - 子群體效能監控
    - 不足群體警示機制

Step5: 持續監控
  技術指標:
    - 敏感度(Sensitivity) > 95%
    - 特異度(Specificity) > 90%
    - 假陰性率 < 5%
  業務指標:
    - 診斷時間縮短50%
    - 漏診率下降30%
  風險指標:
    - 醫療糾紛案件
    - AI誤診通報
    - 法規稽核結果

執行成果:
  - 敏感度96%, 特異度92%
  - 假陰性率降至4%
  - 通過TFDA醫療器材認證
  - 醫師滿意度85%
  - 診斷效率提升60%
```

### 4.3 應用場景三:人臉辨識監控系統風險管理

**場景描述**:企業導入人臉辨識門禁系統,需處理隱私、偏誤與安全風險。

**風險管理流程:**
```
Step1: 風險識別
  隱私風險:
    - 未經同意收集生物特徵
    - 人臉資料外洩風險
    - 過度監控員工隱私
  偏誤風險:
    - 深色皮膚辨識率較低
    - 特定族裔誤認率高
  安全風險:
    - 對抗性攻擊(adversarial attack)
    - 照片/影片欺騙(spoofing)

Step2: 隱私保護措施
  法規合規:
    - 員工知情同意書簽署(100%覆蓋)
    - 隱私政策公開透明
    - 提供員工退出機制
  技術措施:
    - 人臉特徵加密儲存
    - 資料最小化(僅儲存特徵向量,不保留原始影像)
    - 定期刪除機制(離職後立即刪除)
  組織措施:
    - 存取權限嚴格控管(僅HR與安全部門)
    - 稽核日誌完整記錄
    - 隱私官(Privacy Officer)指定

Step3: 偏誤緩解
  資料層:
    - 多元種族資料收集(各族裔比例均衡)
    - 不同光線條件資料擴充
  模型層:
    - 公平性測試:各族裔辨識率差異 < 5%
    - 調整決策閾值(降低少數族裔誤判)
  驗證:
    - 實際環境測試(不同族裔員工)
    - 辨識率: 白種人98%, 亞洲人97%, 非裔96% -> 差異可接受

Step4: 安全防護
  活體檢測(Liveness Detection):
    - 3D深度感測
    - 微動作偵測(眨眼、頭部轉動)
    - 多幀影像序列分析
  對抗性防禦:
    - 對抗性訓練(Adversarial Training)
    - 輸入影像預處理(去除雜訊攻擊)
  異常偵測:
    - 多次失敗嘗試警報
    - 非正常時段存取警示

Step5: 持續監控與治理
  每週監控:
    - 辨識準確率
    - 誤拒率/誤識率
    - 各族裔效能差異
  每月審查:
    - 隱私稽核(是否違規存取)
    - 安全事件分析
    - 員工投訴處理
  年度評估:
    - 法規變動檢查
    - 技術升級評估
    - 倫理委員會審查

執行成果:
  - 員工同意率100%
  - 整體辨識準確率97.5%
  - 族裔間辨識率差異 < 2%
  - 零隱私投訴事件
  - 活體檢測攔截攻擊100次
```

### 4.4 風險管理實施步驟(通用流程)

**AI風險管理八步驟:**
```
Step1: 成立風險管理團隊
  成員: 技術專家+法務+倫理專家+業務代表

Step2: 風險識別工作坊
  技術、法規、倫理、組織、安全五大面向全面盤點

Step3: 風險評估與優先排序
  使用風險矩陣評分、排定處理優先序

Step4: 法規合規檢核
  GDPR、個資法、產業法規逐項檢查

Step5: 偏誤與公平性評估
  資料、模型、結果三層偏誤檢測

Step6: 緩解措施規劃與執行
  預防、偵測、矯正、補償四類措施

Step7: 監控機制建立
  自動化監控+人工審查+定期審計

Step8: 治理政策與流程建立
  AI治理委員會、倫理準則、事件回應流程
```

### 4.5 常見陷阱與解決方案

**陷阱1:法規合規後置**
- 問題:專案開發完成才進行合規檢查,導致大幅返工
- 解決:Privacy by Design,從規劃階段納入合規要求

**陷阱2:偏誤檢測形式化**
- 問題:僅進行表面公平性測試,未深入分析偏誤來源
- 解決:多維度偏誤檢測+根因分析+持續監控

**陷阱3:風險登記簿不更新**
- 問題:風險清單建立後未持續維護,新風險未納入
- 解決:每月/季度定期審查+事件觸發式更新

**陷阱4:過度依賴技術手段**
- 問題:僅靠技術緩解風險,忽略組織流程與文化
- 解決:技術+流程+培訓三管齊下

**陷阱5:缺乏跨部門協作**
- 問題:風險管理僅由技術團隊負責,法務、倫理、業務未參與
- 解決:建立跨職能風險管理委員會

---

## 5. 記憶口訣 (10%, 200-600字)

### 5.1 核心口訣

**AI風險管理五步口訣:**
```
識評緩監治,風險全掌握
識別風險要全面
評估優先排順序
緩解措施要到位
監控機制不鬆懈
治理政策保長效
```

**風險類型記憶口訣:**
```
技法倫組安,五大風險面
技術風險看資料
法規風險查合規
倫理風險防歧視
組織風險促協作
安全風險守防線
```

### 5.2 記憶技巧

**風險矩陣記憶法(交通號誌):**
```
想像風險評分如開車遇紅綠燈:
綠燈(低風險): 安全通過,常規監控
黃燈(中風險): 減速注意,強化監控
橙燈(高風險): 準備停車,立即緩解
紅燈(極高風險): 停止前進,專案暫停

公式: 風險分數 = 機率 × 影響 × (1/可偵測性)
```

**法規合規記憶法(GDPR權利):**
```
資料主體六大權(記憶:刪修攜反查限):
刪除權: Right to Erasure
修正權: Right to Rectification
可攜權: Data Portability
反對權: Object to Automated Decision
查閱權: Right of Access
限制權: Restriction of Processing
```

### 5.3 快速回憶提示

**考試快速回想關鍵字:**
- 風險類型 = 技術+法規+倫理+組織+安全
- 風險評分 = 機率 × 影響 × (1/可偵測性)
- 公平性指標 = DP + EO + PP
- 法規核心 = GDPR + 個資法 + 產業法規
- 緩解策略 = 預防+偵測+矯正+補償

### 5.4 易混淆辨析

**資料漂移 vs 模型漂移:**
- **資料漂移(Data Drift)**:輸入資料的統計分佈改變(如客戶年齡分布變化)
- **模型漂移(Model Drift)**:模型預測準確度隨時間下降(環境變化導致)
- 記憶:資料漂移是「原料變質」,模型漂移是「成品失效」

**統計平等 vs 機會均等:**
- **統計平等(DP)**:不同群體預測為正的比例相同
- **機會均等(EO)**:不同群體真陽性率(正確預測為正)相同
- 記憶:DP看「機會」(被預測為正),EO看「結果」(正確性)

**GDPR vs 個資法:**
- **GDPR**:歐盟法規,罰則最高€2000萬或營收4%,強調自動化決策反對權
- **個資法**:台灣法規,罰則最高200萬+刑責,強調告知義務
- 記憶:GDPR「國際重罰」,個資法「本土合規」

---

## 6. 自我驗證 (10%, 200-600字)

### 6.1 選擇題

**題目1**:風險評分公式「Risk_Score = Probability × Impact × (1/Detectability)」中,若某風險P=4, I=5, D=2,其風險分數為何?
A. 10
B. 40
C. 20
D. 100

**答案**:D
**解析**:Risk_Score = 4 × 5 × (1/2) = 20 × 0.5 = 10...錯誤! 正確計算: 公式應理解為P×I×倒數權重,若D=2(可偵測性中等),實際風險放大。正確理解:D越小越易偵測,分數應越低。題目設計若D為「可偵測性」評分,則公式為P×I/D = 4×5/2=10(A)。但題幹說明D為「倒數」,則直接相乘:4×5×2=40(B)。**正確答案應為B**(假設D已為倒數形式)或**A**(若D為可偵測性原值)。題目需明確定義。標準答案:**B**(40),假設公式中D已處理為風險加權因子。

讓我重新設計:

**題目1修正**:風險評分公式「Risk_Score = Probability × Impact」,若某風險機率=4(高),影響=5(災難),其風險分數與分類為何?
A. 20, 低風險
B. 20, 中風險
C. 20, 高風險
D. 20, 極高風險

**答案**:C
**解析**:Risk_Score = 4 × 5 = 20。根據分類:1-5低風險,6-12中風險,13-20高風險,21-25極高風險。分數20落在高風險區間,需立即緩解措施。

---

**題目2**:下列何者是GDPR賦予資料主體的權利?
A. 資料刪除權
B. 資料修正權
C. 資料可攜權
D. 以上皆是

**答案**:D
**解析**:GDPR賦予資料主體多項權利,包括:(1)刪除權/遺忘權(Right to Erasure),(2)修正權(Right to Rectification),(3)資料可攜權(Data Portability),(4)反對自動化決策權等。選項A、B、C皆為GDPR核心權利,故答案為D。

---

**題目3**:模型公平性指標中,「Demographic Parity (DP)」衡量的是?
A. 不同群體預測為正的比例是否相同
B. 不同群體真陽性率是否相同
C. 不同群體預測準確率是否相同
D. 不同群體資料量是否相同

**答案**:A
**解析**:Demographic Parity(統計平等性)定義為 DP = |P(Ŷ=1|A=0) - P(Ŷ=1|A=1)|,衡量不同群體(如性別、種族)被預測為正類的比例是否相同。選項B為Equalized Odds,C為Predictive Parity,D為資料平衡問題。

---

**題目4**:AI系統導入時,下列何者不是「資料品質風險」的常見問題?
A. 資料缺失值過多
B. 資料標註錯誤
C. 資料分布不均(偏誤)
D. 模型過度擬合

**答案**:D
**解析**:資料品質風險包括:缺失值(Missing Data)、標註錯誤(Labeling Errors)、資料偏誤(Data Bias)、資料漂移(Data Drift)等。模型過度擬合(Overfitting)屬於「模型穩定性風險」,與資料品質無直接關係,而是模型訓練過程的問題。

---

**題目5**:下列何者是AI風險管理的「預防性控制」措施?
A. 模型漂移監控
B. Privacy by Design
C. 資料外洩事件回應
D. 錯誤樣本人工覆核

**答案**:B
**解析**:預防性控制在設計階段預先避免風險發生,Privacy by Design(隱私設計)即從規劃階段納入隱私保護,屬於預防措施。選項A為偵測性控制(營運階段),C為矯正性控制(事件發生後),D為補償性控制(人工審查作為補償機制)。

### 6.2 簡答題

**題目6**:請說明AI模型偏誤的三種主要來源,並提出對應的緩解策略。

**答案解析**:
- **三種偏誤來源與緩解策略**:

1. **資料偏誤(Data Bias)**:
   - 來源:訓練資料中某些群體樣本不足或分布不均,導致模型對該群體預測效果差。
   - 緩解策略:
     - 資料平衡:透過Over-sampling少數群體或Under-sampling多數群體
     - 多元資料收集:確保不同性別、種族、年齡群體資料充足
     - 資料增強:使用SMOTE等技術合成少數群體樣本

2. **標註偏誤(Labeling Bias)**:
   - 來源:標註者的主觀判斷、文化背景或刻板印象影響標註結果。
   - 緩解策略:
     - 標註準則標準化:建立明確、客觀的標註指引
     - 多人標註與一致性檢查:同一樣本由多人標註,計算一致性
     - 盲測與交叉驗證:標註者不知道樣本所屬群體
     - 專家審查:資深專家覆核標註品質

3. **演算法偏誤(Algorithmic Bias)**:
   - 來源:演算法優化整體效能,可能犧牲特定群體公平性。
   - 緩解策略:
     - 公平性約束:在模型訓練中加入公平性正則化項
     - Adversarial Debiasing:使用對抗性訓練移除敏感屬性影響
     - 公平性指標監控:持續追蹤DP、EO、PP等指標
     - 閾值調整:針對不同群體設定不同決策閾值

---

**題目7**:企業導入AI系統時,如何進行有效的法規合規評估?請說明評估流程與重點。

**答案解析**:
- **法規合規評估流程**:

**Step1: 法規範疇識別**
- 確認適用法規:GDPR(歐盟)、個資法(台灣)、HIPAA(美國醫療)、PCI-DSS(支付)等
- 產業特定法規:金融、醫療、電信等專業監管要求
- 內部政策:企業自訂的資料治理與倫理準則

**Step2: 要求清單建立**
- GDPR核心要求:
  - 資料主體同意機制
  - 資料最小化原則
  - 刪除權/遺忘權實作
  - 資料可攜權支援
  - 自動化決策反對權
  - 資料保護影響評估(DPIA)
- 個資法要求:
  - 告知義務(蒐集目的、使用方式)
  - 當事人權利(查閱、更正、刪除、停止處理)
  - 安全維護措施

**Step3: 現況差異分析**
- 逐項檢查已實施控制措施
- 計算合規覆蓋率:Implemented / Required × 100%
- 識別合規缺口(Gap Analysis)

**Step4: 風險評估**
- 不合規項目的法律風險:罰款金額、刑事責任、營運中斷
- 優先排序:高風險項目優先處理

**Step5: 改善措施規劃**
- 技術措施:加密、存取控制、稽核日誌、匿名化
- 流程措施:同意書簽署、DPIA執行、資料外洩通報
- 組織措施:隱私官指定、員工培訓、政策文件化

**Step6: 驗證與稽核**
- 內部稽核:定期檢查合規狀態
- 外部稽核:第三方驗證(如ISO 27001)
- 持續監控:法規變動追蹤與及時更新

**評估重點**:
1. **資料生命週期合規**:從收集、處理、儲存到刪除全程符合法規
2. **技術與組織措施並重**:不僅技術防護,還需流程與文化支撐
3. **可追溯性**:完整稽核日誌,證明合規落實
4. **動態更新**:法規持續演進,評估需定期重新執行

### 6.3 易錯點提醒

**易錯點1**:認為AI風險管理僅是技術問題
- **正確理解**:AI風險涵蓋技術、法規、倫理、組織、安全五大面向,需跨職能協作
- **記憶提示**:風險管理是「組織行為」,非「技術專案」

**易錯點2**:公平性指標選擇錯誤
- **正確理解**:DP、EO、PP等指標無法同時滿足,需根據應用情境選擇
- **記憶提示**:招聘/信貸看EO(結果公平),推薦系統看DP(機會公平)

**易錯點3**:合規評估一次性完成
- **正確理解**:法規持續演進(如EU AI Act),需定期重新評估與更新
- **記憶提示**:合規是「持續過程」,非「一次交付」

**易錯點4**:偏誤緩解僅靠技術手段
- **正確理解**:資料、模型、流程三層緩解,人工審查機制不可少
- **記憶提示**:技術+流程+人工審查=完整偏誤管理
