# L21301 - 數據準備與模型選擇

## 1. 核心定義 (20%, 400-1200字)

### 1.1 主題定義

數據準備與模型選擇是AI專案從構想邁向實現的關鍵技術階段,涵蓋資料收集、清理、特徵工程,以及根據業務問題與資料特性選擇最適合的機器學習模型。其核心目標是將原始資料轉化為高品質訓練資料,並選擇能夠有效學習資料模式、產生準確預測且符合業務需求的模型架構,最終實現AI系統的業務價值。

業界常引用「垃圾進,垃圾出(Garbage In, Garbage Out, GIGO)」,強調資料品質直接決定模型效能。即使擁有最先進的演算法,若資料缺失、錯誤、偏誤嚴重,模型也無法產生可靠預測。因此,數據準備需系統化處理資料品質問題,特徵工程需將原始資料轉化為模型可學習的形式,模型選擇則需在準確度、可解釋性、運算效率間取得平衡。

### 1.2 核心概念

**數據準備與模型選擇的五大核心概念:**

1. **資料收集與清理(Data Collection & Cleaning)**:從內外部來源收集資料,處理缺失值、重複值、異常值
2. **特徵工程(Feature Engineering)**:轉換原始資料為模型可學習的特徵,包括數值轉換、類別編碼、降維
3. **資料品質評估(Data Quality Assessment)**:評估資料完整性、準確性、一致性、及時性
4. **模型選擇策略(Model Selection Strategy)**:根據問題類型(分類/迴歸)、資料特性、業務需求選擇演算法
5. **模型評估與調優(Model Evaluation & Tuning)**:使用驗證集評估模型效能,調整超參數優化表現

### 1.3 CFDS 分解

基於 Formula-Contract 方法論,將數據準備與模型選擇過程分解為四個基本單元:

```
DataPrep_ModelSelection = f(C, F, D, S)
```

**C (Code - 可執行邏輯)**
```
C = DataCollection ∘ DataCleaning ∘ FeatureEngineering ∘ ModelSelection ∘ ModelTraining ∘ Evaluation
  = 資料收集 -> 資料清理 -> 特徵工程 -> 模型選擇 -> 模型訓練 -> 效能評估
```

**F (Files - 配置資源)**
```
F = {原始資料集, 清理腳本, 特徵轉換Pipeline, 模型配置檔, 訓練參數, 評估報告}
```

**D (Data - 資料結構)**
```
D = RawData + CleanedData + FeatureSet + TrainingSet + ValidationSet + TestSet
  = 原始資料 + 清理資料 + 特徵集 + 訓練集 + 驗證集 + 測試集
```

**S (State - 運行狀態)**
```
S = DataCollecting | Cleaning | FeatureEngineering | ModelTraining | Evaluating | Deployed
  = 資料收集中 | 清理中 | 特徵工程 | 模型訓練 | 評估中 | 已部署
```

### 1.4 技術定位

數據準備與模型選擇在AI專案生命週期中處於「開發核心階段」,是連接「業務需求」與「系統部署」的技術實現環節。資料品質與模型選擇直接影響AI系統的準確度、穩定性、可解釋性,是專案成敗的決定性因素。

在企業AI應用中,數據準備佔據專案60-80%時間,是最耗時但最關鍵的環節。模型選擇則需在準確度(Accuracy)、可解釋性(Interpretability)、運算效率(Efficiency)、可維護性(Maintainability)間權衡,確保技術方案與業務目標一致。

---

## 2. 關鍵公式 (25%, 500-1500字)

### 2.1 數據準備核心流程公式

```
DataPreparation = Collection -> Cleaning -> Transformation -> Validation

詳細展開:
  Collection = InternalSources + ExternalSources + RealTimeStreams
  Cleaning = MissingValueHandling + DuplicateRemoval + OutlierDetection + NoiseReduction
  Transformation = Normalization + Encoding + FeatureExtraction + Dimensionality Reduction
  Validation = QualityMetrics × CompletenessCheck × ConsistencyTest
```

### 2.2 資料品質評估公式

**資料品質綜合評分:**
```
Data_Quality_Score = (Completeness + Accuracy + Consistency + Timeliness) / 4

Completeness(完整性) = 完整記錄數 / 總記錄數 × 100%
  範例: 10000筆資料中9500筆完整 -> 95%

Accuracy(準確性) = 正確資料筆數 / 總資料筆數 × 100%
  需透過抽樣驗證或與可信來源比對

Consistency(一致性) = 一致性規則通過筆數 / 總檢查筆數 × 100%
  範例: 年齡與出生日期邏輯一致性檢查

Timeliness(及時性) = 符合時效資料筆數 / 總資料筆數 × 100%
  範例: 股價預測需即時資料,超過1天視為過時

品質分級:
  Score >= 90% -> 優質資料
  Score 70-90% -> 可接受(需改善)
  Score 50-70% -> 品質不足(需大量清理)
  Score < 50% -> 不建議使用
```

### 2.3 缺失值處理策略公式

**缺失值比例決策樹:**
```
Missing_Strategy = f(Missing_Rate, Data_Type, Missing_Pattern)

決策流程:
  if Missing_Rate < 5%:
    策略 = 刪除該筆記錄(Listwise Deletion)
  elif Missing_Rate 5-20%:
    if Data_Type == Numerical:
      策略 = 平均數/中位數填補(Mean/Median Imputation)
    elif Data_Type == Categorical:
      策略 = 眾數填補(Mode Imputation)
  elif Missing_Rate 20-50%:
    if Missing_Pattern == MCAR (Missing Completely At Random):
      策略 = 多重插補(Multiple Imputation)
    elif Missing_Pattern == MAR (Missing At Random):
      策略 = 模型預測填補(Model-based Imputation, KNN, MICE)
  else (Missing_Rate > 50%):
    策略 = 刪除該特徵欄位

時間序列特殊處理:
  Forward Fill: 使用前一筆資料填補
  Backward Fill: 使用後一筆資料填補
  Interpolation: 線性/多項式插值法
```

### 2.4 特徵工程轉換公式

**數值特徵標準化:**
```
1. Min-Max Normalization(最小最大正規化):
   X_norm = (X - X_min) / (X_max - X_min)
   將資料縮放至[0, 1]區間
   適用: 資料分布均勻、無極端異常值

2. Z-Score Standardization(標準化):
   X_std = (X - μ) / σ
   其中 μ為平均數, σ為標準差
   將資料轉為平均數0、標準差1的分布
   適用: 資料呈常態分布、需梯度下降演算法(線性迴歸、神經網路)

3. Robust Scaling(穩健縮放):
   X_robust = (X - Median) / IQR
   使用中位數與四分位距,對異常值不敏感
   適用: 資料含異常值、分布偏態
```

**類別特徵編碼:**
```
1. One-Hot Encoding(獨熱編碼):
   類別變數轉為二元向量
   範例: 顏色{紅,綠,藍} -> 紅[1,0,0], 綠[0,1,0], 藍[0,0,1]
   適用: 無序類別、類別數量少(< 10)

2. Label Encoding(標籤編碼):
   類別轉為整數編碼
   範例: 學歷{高中,學士,碩士,博士} -> {1,2,3,4}
   適用: 有序類別、樹狀模型(決策樹、隨機森林)

3. Target Encoding(目標編碼):
   用該類別對應的目標值平均數替換
   範例: 城市{台北,高雄} -> {平均房價800萬, 400萬}
   適用: 高基數類別(類別數量多)、分類/迴歸問題
```

### 2.5 特徵選擇與降維公式

**特徵重要性評分:**
```
1. 資訊增益(Information Gain):
   IG(T, a) = H(T) - H(T|a)
   其中 H(T)為目標變數熵, H(T|a)為給定特徵a後的條件熵
   IG越大,特徵越重要

2. 皮爾森相關係數(Pearson Correlation):
   r = Cov(X, Y) / (σ_X × σ_Y)
   |r| > 0.7 -> 強相關(考慮保留)
   |r| 0.3-0.7 -> 中度相關
   |r| < 0.3 -> 弱相關(考慮移除)

3. 卡方檢定(Chi-Square Test):
   χ² = Σ (Observed - Expected)² / Expected
   用於類別特徵與目標變數的相關性檢定
   p-value < 0.05 -> 顯著相關,保留特徵
```

**主成分分析(PCA)降維:**
```
PCA = Variance_Explained_Ratio

選擇主成分數量:
  累積解釋變異量 >= 85% -> 保留該數量主成分

範例:
  原始100個特徵
  PCA分析: 前20個主成分累積解釋變異量90%
  降維結果: 100維 -> 20維,資訊損失10%
  優點: 減少運算量、避免過擬合、視覺化
```

### 2.6 模型選擇決策公式

**問題類型決策樹:**
```
ModelSelection = ProblemType × DataCharacteristics × BusinessRequirements

ProblemType決策:
  if 預測目標 == 連續數值:
    TaskType = Regression(迴歸)
    CandidateModels = {Linear Regression, Decision Tree Regression, Random Forest, Gradient Boosting, SVR}
  elif 預測目標 == 離散類別:
    TaskType = Classification(分類)
    if 類別數 == 2:
      SubType = Binary Classification
      CandidateModels = {Logistic Regression, SVM, Random Forest, XGBoost, Neural Network}
    else:
      SubType = Multi-class Classification
      CandidateModels = {Softmax Regression, Random Forest, XGBoost, Neural Network}
  elif 無標註資料:
    TaskType = Unsupervised Learning
    if 目標 == 分群:
      CandidateModels = {K-means, DBSCAN, Hierarchical Clustering}
    elif 目標 == 降維:
      CandidateModels = {PCA, t-SNE, UMAP}
```

**資料特性匹配:**
```
DataCharacteristics影響:
  if 資料量 < 1000:
    避免深度學習(易過擬合),選擇簡單模型(Logistic, KNN, Naive Bayes)
  elif 資料量 1000-10000:
    傳統機器學習優先(Random Forest, XGBoost)
  elif 資料量 > 100000:
    深度學習可行(Neural Network, CNN, RNN)

  if 特徵維度 > 資料筆數:
    需降維或正則化(L1/L2 Regularization, PCA)

  if 資料呈線性關係:
    Linear Regression / Logistic Regression
  elif 資料呈非線性關係:
    Tree-based models / Neural Network
```

### 2.7 模型評估指標公式

**分類模型評估:**
```
1. 準確率(Accuracy):
   Accuracy = (TP + TN) / (TP + TN + FP + FN)
   適用: 類別平衡資料

2. 精確率(Precision):
   Precision = TP / (TP + FP)
   關注: 預測為正的準確性
   適用: 誤判成本高(如垃圾郵件偵測)

3. 召回率(Recall / Sensitivity):
   Recall = TP / (TP + FN)
   關注: 正類被找出的比例
   適用: 漏判成本高(如疾病診斷)

4. F1-Score(F1分數):
   F1 = 2 × (Precision × Recall) / (Precision + Recall)
   Precision與Recall的調和平均數
   適用: 類別不平衡、需平衡精確率與召回率

5. AUC-ROC(曲線下面積):
   AUC範圍[0, 1], 越接近1越好
   AUC > 0.9 -> 優秀
   AUC 0.8-0.9 -> 良好
   AUC 0.7-0.8 -> 可接受
   AUC < 0.7 -> 較差
```

**迴歸模型評估:**
```
1. 平均絕對誤差(MAE):
   MAE = (1/n) × Σ|y_i - ŷ_i|
   對異常值不敏感,易於解釋

2. 均方誤差(MSE):
   MSE = (1/n) × Σ(y_i - ŷ_i)²
   對異常值敏感,放大大誤差

3. 均方根誤差(RMSE):
   RMSE = √MSE
   與目標變數同單位,易於解釋

4. 決定係數(R²):
   R² = 1 - (SS_res / SS_tot)
   R² = 1 -> 完美預測
   R² = 0 -> 與平均值預測相同
   R² < 0 -> 比平均值更差
   R² > 0.7 -> 模型解釋力強
```

---

## 3. 對比矩陣 (15%, 300-900字)

### 3.1 資料來源對比表

| 資料來源 | 可控性 | 資料品質 | 取得成本 | 法規限制 | 典型應用 |
|---------|--------|---------|---------|---------|---------|
| **內部ERP/CRM** | 高 | 高 | 低 | 低 | 銷售預測、客戶分析 |
| **機台/IoT資料** | 高 | 中 | 中 | 低 | 預測保養、製程優化 |
| **開放資料平台** | 低 | 中 | 低 | 低 | 政策分析、市場研究 |
| **Web Scraping** | 低 | 低 | 中 | 高(版權) | 輿情監測、價格分析 |
| **商業資料庫** | 中 | 高 | 高 | 中 | 金融分析、產業趨勢 |

### 3.2 缺失值處理方法對比

| 處理方法 | 適用情境 | 優點 | 缺點 | 資料損失 |
|---------|---------|------|------|---------|
| **刪除記錄** | 缺失率< 5% | 簡單快速 | 損失資訊 | 高 |
| **平均數填補** | 數值型、缺失率低 | 保持樣本數 | 低估變異性 | 低 |
| **眾數填補** | 類別型、缺失率低 | 保持樣本數 | 可能引入偏誤 | 低 |
| **KNN填補** | 缺失率中等 | 考慮鄰近樣本 | 運算量大 | 無 |
| **模型預測填補** | 缺失率高、MAR | 準確度高 | 複雜度高 | 無 |

### 3.3 特徵縮放方法對比

| 縮放方法 | 輸出範圍 | 對異常值敏感度 | 適用演算法 | 適用資料分布 |
|---------|---------|---------------|----------|-------------|
| **Min-Max** | [0, 1] | 高 | Neural Network, KNN | 均勻分布 |
| **Z-Score** | 無固定範圍 | 中 | Linear Regression, SVM | 常態分布 |
| **Robust Scaling** | 無固定範圍 | 低 | 所有演算法 | 偏態分布、含異常值 |

### 3.4 監督式學習演算法對比

| 演算法 | 問題類型 | 優點 | 缺點 | 可解釋性 | 訓練速度 |
|--------|---------|------|------|---------|---------|
| **Linear Regression** | 迴歸 | 簡單、快速、可解釋 | 僅適用線性關係 | 高 | 快 |
| **Logistic Regression** | 分類 | 簡單、機率輸出 | 僅適用線性可分 | 高 | 快 |
| **Decision Tree** | 分類/迴歸 | 易解釋、處理非線性 | 易過擬合 | 高 | 中 |
| **Random Forest** | 分類/迴歸 | 準確度高、抗過擬合 | 黑箱、慢 | 中 | 慢 |
| **XGBoost** | 分類/迴歸 | 準確度極高、效率佳 | 參數多、需調優 | 低 | 中 |
| **SVM** | 分類/迴歸 | 高維資料表現佳 | 大資料慢、參數敏感 | 低 | 慢 |
| **KNN** | 分類/迴歸 | 簡單、無訓練階段 | 預測慢、對維度敏感 | 高 | 快(訓練)/慢(預測) |
| **Neural Network** | 分類/迴歸 | 強大表達力、適應複雜模式 | 需大量資料、黑箱 | 低 | 慢 |

### 3.5 非監督式學習演算法對比

| 演算法 | 任務類型 | 優點 | 缺點 | 參數需求 | 適用資料規模 |
|--------|---------|------|------|---------|-------------|
| **K-means** | 分群 | 快速、簡單 | 需預設K值、對初始點敏感 | 需指定K | 大 |
| **DBSCAN** | 分群 | 發現任意形狀群、自動偵測雜訊 | 對密度參數敏感 | ε, MinPts | 中 |
| **Hierarchical** | 分群 | 層級結構、無需預設K | 運算量大 | 連結方式 | 小 |
| **PCA** | 降維 | 快速、有效降維 | 線性假設、特徵不易解釋 | 主成分數 | 大 |
| **t-SNE** | 降維視覺化 | 保留局部結構、視覺效果佳 | 運算慢、不適合高維->低維 | perplexity | 中 |

### 3.6 模型評估指標對比(分類)

| 指標 | 關注重點 | 適用情境 | 優點 | 缺點 |
|-----|---------|---------|------|------|
| **Accuracy** | 整體正確率 | 類別平衡 | 直觀易懂 | 類別不平衡時誤導 |
| **Precision** | 預測為正的準確性 | 誤判成本高 | 關注FP | 忽略FN |
| **Recall** | 正類被找出比例 | 漏判成本高 | 關注FN | 忽略FP |
| **F1-Score** | Precision與Recall平衡 | 類別不平衡 | 綜合考量 | 對極端情況不敏感 |
| **AUC-ROC** | 分類能力整體評估 | 二元分類 | 不受閾值影響 | 多分類需擴展 |

---

## 4. 實務應用 (20%, 400-1200字)

### 4.1 應用場景一:電商銷售預測(迴歸任務)

**場景描述**:電商平台希望預測未來一個月各商品銷售量,進行庫存管理與行銷規劃。

**數據準備流程:**
```
Step1: 資料收集
  內部資料:
    - 歷史銷售記錄(3年, 500萬筆交易)
    - 商品資訊(價格、類別、庫存)
    - 促銷活動紀錄
    - 會員資料(購買歷程、偏好)
  外部資料:
    - 節慶日曆(過年、聖誕節等)
    - 經濟指標(消費者信心指數)
    - 競爭對手價格(Web Scraping)

Step2: 資料清理
  缺失值處理:
    - 價格缺失(1%): 使用同類別平均價填補
    - 會員年齡缺失(5%): 使用中位數填補
    - 競品價格缺失(20%): 刪除該特徵(缺失率過高)
  異常值檢測:
    - 使用IQR方法偵測異常銷售量(促銷活動導致)
    - 保留異常值但標記為促銷期間
  重複值處理:
    - 依據訂單編號去重,移除1000筆重複記錄

Step3: 特徵工程
  時間特徵:
    - 提取年、月、日、星期幾、是否週末
    - 計算距離節慶天數(如距離過年30天)
    - 建立週期性特徵(sin/cos轉換捕捉週期性)
  商品特徵:
    - 價格標準化(Z-Score)
    - 類別One-Hot編碼(10個類別 -> 10維二元向量)
    - 計算價格排名(該商品在同類別中的價格百分位)
  互動特徵:
    - 價格 × 促銷力度(折扣幅度)
    - 類別 × 節慶(特定類別在特定節慶銷量高)

Step4: 資料品質評估
  Completeness = 99% (缺失處理後)
  Accuracy = 95% (抽樣驗證與實際庫存比對)
  Consistency = 98% (價格與銷量邏輯一致性檢查)
  Data_Quality_Score = (99 + 95 + 98) / 3 = 97.3% -> 優質資料
```

**模型選擇與訓練:**
```
Step1: 問題定義
  任務類型: Regression(預測連續數值銷售量)
  目標: 預測未來30天每日銷售量

Step2: 候選模型
  簡單基線: Linear Regression
  樹狀模型: Random Forest Regression, XGBoost
  深度學習: LSTM(考慮時間序列特性)

Step3: 資料分割
  訓練集: 80% (2.5年資料)
  驗證集: 10% (3個月資料)
  測試集: 10% (最近3個月資料,模擬真實預測)

Step4: 模型訓練與評估
  Linear Regression:
    RMSE = 150件, MAE = 120件, R² = 0.65
    優點: 快速、可解釋
    缺點: 無法捕捉非線性關係

  Random Forest:
    RMSE = 100件, MAE = 80件, R² = 0.82
    優點: 準確度高、自動特徵重要性
    缺點: 訓練慢、黑箱

  XGBoost:
    RMSE = 85件, MAE = 65件, R² = 0.87
    優點: 準確度最高、訓練效率佳
    缺點: 參數調優複雜

  LSTM(時間序列):
    RMSE = 95件, MAE = 75件, R² = 0.84
    優點: 捕捉時間依賴性
    缺點: 需大量資料、訓練慢

Step5: 模型選擇決策
  選擇XGBoost:
    - 準確度最高(R²=0.87, RMSE=85)
    - 訓練效率可接受
    - 特徵重要性可解釋(業務關注重點)

  特徵重要性分析:
    Top 5: 歷史銷量(40%), 價格(25%), 促銷力度(15%), 節慶(10%), 類別(10%)

Step6: 超參數調優
  使用Grid Search:
    n_estimators: [100, 200, 300]
    max_depth: [3, 5, 7]
    learning_rate: [0.01, 0.1, 0.3]
  最佳參數: n_estimators=200, max_depth=5, learning_rate=0.1
  調優後RMSE降至80件
```

**執行成果:**
- 預測準確度RMSE=80件,相對誤差10%
- 庫存管理效率提升30%(減少缺貨與積壓)
- 促銷規劃精準度提升,ROI增加25%

### 4.2 應用場景二:客戶流失預測(分類任務)

**場景描述**:電信公司希望預測客戶是否在未來3個月內流失,提前挽留高價值客戶。

**數據準備流程:**
```
Step1: 資料收集
  客戶基本資料: 年齡、性別、地區、合約類型
  使用行為: 月均通話分鐘數、數據用量、客服聯繫次數
  財務資料: 月費、欠費紀錄、付款方式
  標籤: 是否流失(1=流失, 0=留存)
  資料筆數: 100,000筆客戶(流失率15%)

Step2: 資料清理
  缺失值:
    - 年齡缺失(2%): 使用KNN填補(基於消費行為預測)
    - 客服聯繫次數缺失(0.5%): 填補為0(代表未聯繫)
  類別不平衡處理:
    - 流失客戶15,000筆 vs 留存85,000筆(1:5.67不平衡)
    - 策略: SMOTE(Synthetic Minority Over-sampling)合成少數類
    - 平衡後: 流失40,000筆, 留存40,000筆(1:1)

Step3: 特徵工程
  數值特徵:
    - 月費、通話分鐘數標準化(Z-Score)
    - 建立衍生特徵: 月費/通話分鐘(單位成本)、數據用量增長率
  類別特徵:
    - 合約類型(月約、年約、兩年約) -> One-Hot編碼
    - 地區(20個城市) -> Target Encoding(用該地區流失率編碼)
  互動特徵:
    - 高月費 × 高客訴 -> 高流失風險群
    - 年約 × 低使用量 -> 潛在流失

Step4: 特徵選擇
  使用隨機森林計算特徵重要性:
    Top 10特徵保留,移除低重要性特徵
    選出: 合約類型、月費、客服聯繫次數、使用年限、數據用量等
```

**模型選擇與訓練:**
```
Step1: 候選模型
  Logistic Regression(基線)
  Random Forest Classifier
  XGBoost Classifier
  Neural Network(MLP)

Step2: 資料分割
  訓練集: 70% (56,000筆)
  驗證集: 15% (12,000筆)
  測試集: 15% (12,000筆)

Step3: 模型訓練與評估
  Logistic Regression:
    Accuracy = 0.75, Precision = 0.70, Recall = 0.65, F1 = 0.67, AUC = 0.78
    優點: 可解釋、係數代表特徵影響
    缺點: 線性假設限制

  Random Forest:
    Accuracy = 0.85, Precision = 0.82, Recall = 0.80, F1 = 0.81, AUC = 0.90
    優點: 準確度高、特徵重要性
    缺點: 黑箱

  XGBoost:
    Accuracy = 0.87, Precision = 0.85, Recall = 0.83, F1 = 0.84, AUC = 0.92
    優點: 準確度最高
    缺點: 參數多

  Neural Network:
    Accuracy = 0.86, Precision = 0.83, Recall = 0.82, F1 = 0.825, AUC = 0.91
    優點: 捕捉複雜關係
    缺點: 需大量資料、黑箱

Step4: 業務導向模型選擇
  關注Recall(召回率):
    - 流失預測中,漏判成本高(錯過挽留高價值客戶)
    - Precision降低可接受(多發放挽留優惠,成本可控)

  調整決策閾值:
    - 預設閾值0.5: Recall=0.83
    - 降低閾值至0.3: Recall提升至0.90, Precision降至0.75
    - 業務可接受(寧可多挽留,避免漏失)

  最終選擇: XGBoost + 閾值0.3
    Recall = 0.90 (90%流失客戶被識別)
    Precision = 0.75 (75%預測流失確實流失)

Step5: 模型解釋
  SHAP(SHapley Additive exPlanations)分析:
    最影響流失因素: 合約類型(月約高風險)、客服聯繫次數(高頻=不滿)、月費(高費用未對應高使用=不划算)
```

**執行成果:**
- 識別90%潛在流失客戶
- 挽留率從30%提升至50%(精準投放優惠)
- 年節省客戶流失損失3000萬

### 4.3 應用場景三:客戶分群(非監督式學習)

**場景描述**:零售業希望依據購買行為將客戶分群,制定差異化行銷策略。

**數據準備與分群流程:**
```
Step1: 資料收集
  RFM特徵(經典客戶分群指標):
    - Recency(最近購買天數): 距離上次購買多久
    - Frequency(購買頻率): 過去一年購買次數
    - Monetary(消費金額): 過去一年總消費金額
  額外特徵:
    - 平均客單價、購買類別多樣性、優惠券使用率
  資料筆數: 50,000筆客戶

Step2: 資料清理與標準化
  異常值處理:
    - 使用IQR移除極端異常(如單筆消費100萬,可能是B2B非零售客戶)
  標準化:
    - RFM三指標量級差異大(Recency:天數, Frequency:次數, Monetary:金額)
    - 使用Z-Score標準化,確保各特徵等權重

Step3: 降維視覺化
  使用PCA降至2維:
    - 保留85%變異量
    - 視覺化觀察客戶分布,初步判斷可能分群數

Step4: K-means分群
  決定K值(群數):
    - 手肘法(Elbow Method): 繪製K vs SSE(誤差平方和)曲線
    - 輪廓係數(Silhouette Score): K=4時最大(0.65)
    - 業務判斷: 4個群符合行銷策略需求

  分群結果:
    群1(VIP客戶, 10%): Recency低、Frequency高、Monetary高
    群2(潛力客戶, 25%): Recency中、Frequency中、Monetary中
    群3(新客戶, 40%): Recency低、Frequency低、Monetary低
    群4(流失風險, 25%): Recency高、Frequency低、Monetary低

Step5: 分群解釋與驗證
  各群特徵分析:
    群1: 3個月內購買5次以上,年消費10萬+
    群2: 3個月內購買2-4次,年消費3-10萬
    群3: 首次購買<1個月,消費<5千
    群4: 6個月未購買

  業務驗證:
    - 與行銷團隊討論,分群符合業務認知
    - 歷史資料驗證: 群4客戶70%一年後確實流失

Step6: 差異化策略
  群1(VIP): 專屬優惠、優先體驗新品、個人化服務
  群2(潛力): 升級方案、消費滿額送、會員活動邀請
  群3(新客): 歡迎優惠、新手教學、回購鼓勵
  群4(流失風險): 喚回優惠、問卷調查(了解原因)、停損評估
```

**執行成果:**
- 精準行銷ROI提升40%
- 新客轉換率提升25%
- VIP客戶續約率提升15%

### 4.4 數據準備最佳實務

**通用流程八步驟:**
```
Step1: 業務理解與目標定義
  明確預測目標、評估指標、業務限制

Step2: 資料收集規劃
  識別所需資料來源、評估取得可行性與成本

Step3: 資料品質評估
  初步檢查完整性、準確性、一致性

Step4: 資料清理
  處理缺失值、重複值、異常值、格式不一致

Step5: 特徵工程
  數值轉換、類別編碼、衍生特徵、互動特徵

Step6: 特徵選擇
  移除低重要性/高相關性特徵,降低維度

Step7: 資料分割
  訓練集/驗證集/測試集,確保時間順序(時間序列)

Step8: 資料版本管理
  記錄資料來源、清理步驟、特徵定義,確保可重現性
```

### 4.5 常見陷阱與解決方案

**陷阱1:資料洩漏(Data Leakage)**
- 問題:測試集資訊洩漏至訓練集,導致高估模型效能
- 範例:用全部資料計算平均數進行標準化,再分割訓練/測試集
- 解決:先分割資料,再對訓練集計算統計量,套用至測試集

**陷阱2:過度特徵工程**
- 問題:建立過多特徵,導致過擬合與運算負擔
- 解決:特徵選擇、交叉驗證評估特徵價值

**陷阱3:忽略時間序列特性**
- 問題:隨機分割資料,導致用未來預測過去
- 解決:按時間順序分割,訓練集在前、測試集在後

**陷阱4:類別不平衡未處理**
- 問題:少數類樣本少,模型偏向多數類
- 解決:SMOTE、調整類別權重、調整決策閾值

**陷阱5:盲目追求複雜模型**
- 問題:使用深度學習處理小資料,導致過擬合
- 解決:從簡單模型開始,根據資料量與複雜度選擇

---

## 5. 記憶口訣 (10%, 200-600字)

### 5.1 核心口訣

**數據準備四步口訣:**
```
收清轉驗,數據就緒
收集資料選對源
清理品質要把關
轉換特徵工程巧
驗證品質再出發
```

**模型選擇決策口訣:**
```
問資業三維,選模有依據
問題類型先確定(分類/迴歸)
資料特性要考量(量/維度/線性)
業務需求定方向(準確度/速度/解釋性)
```

### 5.2 記憶技巧

**資料品質四維度(CACT):**
```
想像資料如食材,CACT是品質檢驗:
C = Completeness(完整性): 食材齊全不缺
A = Accuracy(準確性): 食材新鮮正確
C = Consistency(一致性): 食材規格一致
T = Timeliness(及時性): 食材未過期
```

**特徵工程記憶法(轉編降):**
```
轉: 數值特徵轉換(標準化/正規化)
編: 類別特徵編碼(One-Hot/Label/Target)
降: 降維技術(PCA/特徵選擇)
```

**模型評估指標記憶(分類ABC):**
```
A = Accuracy(準確率): 整體對錯
P-R = Precision-Recall(精確率-召回率): 正類表現
F = F1-Score: PR調和平均
AUC = AUC-ROC: 分類能力總評
```

### 5.3 快速回憶提示

**考試快速回想關鍵字:**
- 資料品質 = CACT(完整/準確/一致/及時)
- 缺失值 = 刪除/填補/預測
- 特徵工程 = 轉換+編碼+降維
- 監督學習 = 分類(Logistic/RF/XGBoost) + 迴歸(Linear/RF/XGBoost)
- 非監督學習 = 分群(K-means/DBSCAN) + 降維(PCA/t-SNE)
- 評估指標 = 分類(Accuracy/Precision/Recall/F1/AUC) + 迴歸(MAE/RMSE/R²)

### 5.4 易混淆辨析

**Precision vs Recall:**
- **Precision(精確率)**:預測為正的樣本中,實際為正的比例(關注誤判)
- **Recall(召回率)**:實際為正的樣本中,被預測為正的比例(關注漏判)
- 記憶:Precision問「猜對幾個」,Recall問「找到幾個」

**Normalization vs Standardization:**
- **Normalization(正規化)**:縮放至[0,1],保持原始分布形狀
- **Standardization(標準化)**:轉為均值0標準差1,適合常態分布
- 記憶:Normalization「壓縮範圍」,Standardization「調整分布」

**One-Hot vs Label Encoding:**
- **One-Hot**:類別轉二元向量,無序類別(如顏色)
- **Label**:類別轉整數,有序類別(如學歷)
- 記憶:One-Hot「展開獨立」,Label「排序編號」

---

## 6. 自我驗證 (10%, 200-600字)

### 6.1 選擇題

**題目1**:資料品質評估中,「Completeness」指的是?
A. 資料的正確性
B. 資料的完整性(無缺失)
C. 資料的一致性
D. 資料的及時性

**答案**:B
**解析**:Completeness(完整性)衡量資料是否完整無缺失,計算公式為「完整記錄數/總記錄數×100%」。選項A為Accuracy(準確性),C為Consistency(一致性),D為Timeliness(及時性)。

---

**題目2**:處理缺失值時,若缺失率超過50%,最合適的策略是?
A. 使用平均數填補
B. 使用KNN預測填補
C. 刪除該特徵欄位
D. 使用眾數填補

**答案**:C
**解析**:當缺失率超過50%時,該特徵已失去大部分資訊價值,填補方法可能引入過多不確定性與偏誤。最佳策略是刪除該特徵,避免影響模型品質。若該特徵極為關鍵,需重新收集資料。

---

**題目3**:下列何者適用「One-Hot Encoding」?
A. 年齡(連續數值)
B. 學歷(高中<學士<碩士,有序)
C. 顏色(紅/綠/藍,無序)
D. 收入(連續數值)

**答案**:C
**解析**:One-Hot Encoding適用於無序類別變數,將每個類別轉為獨立的二元向量。顏色(紅/綠/藍)為無序類別,適用One-Hot。選項A、D為連續數值需標準化,選項B為有序類別適用Label Encoding。

---

**題目4**:在分類任務中,若業務關注「漏判成本高」(如疾病診斷),應優先優化哪個指標?
A. Accuracy
B. Precision
C. Recall
D. F1-Score

**答案**:C
**解析**:Recall(召回率)衡量實際為正的樣本中被找出的比例,關注「漏判」問題。疾病診斷中,漏診(FN,假陰性)成本極高,可能危及生命,因此應優先提升Recall,確保盡可能找出所有病患。

---

**題目5**:下列何者是「迴歸任務」的評估指標?
A. Accuracy
B. Precision
C. RMSE
D. AUC-ROC

**答案**:C
**解析**:RMSE(Root Mean Squared Error,均方根誤差)是迴歸任務的評估指標,衡量預測值與真實值的平均誤差。選項A、B、D皆為分類任務指標。

### 6.2 簡答題

**題目6**:請說明「資料洩漏(Data Leakage)」的定義、常見案例與避免方法。

**答案解析**:
- **定義**:
  資料洩漏是指訓練過程中,測試集或未來資訊不當洩漏至訓練集,導致模型在訓練時「看到答案」,虛高估計模型效能,但實際部署後表現不佳。

- **常見案例**:
  1. **時間洩漏**:
     - 問題:預測未來股價,但特徵包含「未來7天平均價」
     - 後果:訓練時準確度99%,實際預測完全失效(未來資訊不可得)

  2. **標準化洩漏**:
     - 問題:先對全部資料進行Min-Max正規化,再分割訓練/測試集
     - 後果:測試集的最大/最小值影響訓練集標準化,洩漏資訊

  3. **目標洩漏**:
     - 問題:信用評分預測,特徵包含「還款記錄」(還款記錄是結果不是原因)
     - 後果:模型學到「已還款=不違約」,但預測時還款記錄未知

  4. **ID洩漏**:
     - 問題:客戶ID與目標變數有隱含關係(如ID順序代表註冊時間,與流失相關)
     - 後果:模型學到ID模式,但新客戶ID無此模式

- **避免方法**:
  1. **嚴格時間切分**:
     - 訓練集使用過去資料,測試集使用未來資料
     - 禁止使用未來資訊作為特徵

  2. **分割後再處理**:
     - 先分割訓練/測試集
     - 僅對訓練集計算統計量(平均數、最大/最小值)
     - 將訓練集統計量套用至測試集

  3. **特徵檢查**:
     - 檢查特徵是否在預測時可取得
     - 移除「結果特徵」(如還款記錄)

  4. **交叉驗證**:
     - 使用時間序列交叉驗證(Time Series Cross-Validation)
     - 確保驗證集永遠在訓練集「之後」

---

**題目7**:請說明如何選擇適合的機器學習演算法?並以分類任務為例說明決策流程。

**答案解析**:
- **演算法選擇決策流程**:

**Step1: 問題類型確認**
- 分類任務:預測離散類別(如客戶流失是/否)
- 迴歸任務:預測連續數值(如房價)
- 分群任務:無標註資料分組
- 降維任務:高維資料視覺化

**Step2: 資料特性分析**
- **資料量大小**:
  - < 1,000筆: 簡單模型(Logistic Regression, KNN, Naive Bayes)
  - 1,000-100,000筆: 傳統ML(Random Forest, XGBoost, SVM)
  - > 100,000筆: 深度學習可行(Neural Network)

- **特徵維度**:
  - 低維度(< 10): 任何演算法
  - 中維度(10-100): 傳統ML優先
  - 高維度(> 100): 需降維(PCA)或L1正則化(Lasso)

- **線性vs非線性**:
  - 線性可分: Logistic Regression, Linear SVM
  - 非線性: Tree-based models, Kernel SVM, Neural Network

**Step3: 業務需求考量**
- **可解釋性需求高**:
  - 優先: Logistic Regression, Decision Tree
  - 次選: Random Forest(特徵重要性) + SHAP解釋
  - 避免: Deep Neural Network(黑箱)

- **預測速度需求**:
  - 即時預測: Logistic Regression, Decision Tree(快速)
  - 批次預測: XGBoost, Neural Network(可接受)

- **準確度vs複雜度權衡**:
  - 準確度優先: XGBoost, Neural Network
  - 簡單優先: Logistic Regression, Naive Bayes

**Step4: 分類任務決策範例**
情境:客戶流失預測,10萬筆資料,20個特徵,業務關注Recall

決策流程:
1. 資料量10萬 -> 傳統ML與深度學習皆可行
2. 特徵維度20 -> 適中,無需降維
3. 業務關注Recall(漏判成本高) -> 需調整閾值
4. 可解釋性需求中等 -> XGBoost + SHAP可接受

候選模型與測試:
- Logistic Regression(基線): AUC=0.78, 訓練快但準確度不足
- Random Forest: AUC=0.88, 準確度佳但訓練慢
- XGBoost: AUC=0.90, 準確度最高且效率可接受

最終選擇:XGBoost
- 調整閾值0.5 -> 0.3,提升Recall至0.90
- 使用SHAP解釋,滿足業務理解需求
- 特徵重要性指導業務策略

### 6.3 易錯點提醒

**易錯點1**:混淆資料分割順序
- **錯誤做法**:先標準化全部資料,再分割訓練/測試集
- **正確做法**:先分割,再對訓練集標準化,套用至測試集
- **記憶提示**:「分割是第一步,避免資訊洩漏」

**易錯點2**:類別不平衡未處理就評估
- **錯誤**:類別不平衡(1:99)時,僅看Accuracy(99%)誤以為模型優秀
- **正確**:使用F1-Score、AUC-ROC,並進行SMOTE或調整閾值
- **記憶提示**:「不平衡看F1,不看Accuracy」

**易錯點3**:過度依賴特徵工程
- **錯誤**:建立數百個衍生特徵,導致過擬合
- **正確**:特徵選擇移除低重要性特徵,交叉驗證評估
- **記憶提示**:「特徵多不如精,選擇勝於堆疊」

**易錯點4**:時間序列隨機分割
- **錯誤**:時間序列資料隨機分割,導致用未來預測過去
- **正確**:按時間順序分割,訓練集在前、測試集在後
- **記憶提示**:「時間序列不打亂,順序分割保真實」
