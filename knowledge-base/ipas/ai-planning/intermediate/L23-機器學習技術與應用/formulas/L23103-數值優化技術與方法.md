# L23103 - 數值優化技術與方法

## 1. 核心定義 (20%, 400-1200字)

### 1.1 主題定義

數值優化是機器學習訓練的核心引擎，負責尋找使損失函數最小化的模型參數。機器學習本質上是一個優化問題：在參數空間中搜尋最佳解，使模型預測與真實資料的誤差最小。從線性迴歸的最小平方法到深度神經網路的反向傳播，所有訓練過程都仰賴數值優化演算法的驅動。

數值優化技術決定了模型訓練的三大關鍵指標：收斂速度（多快找到最佳解）、穩定性（是否會發散或震盪）、泛化能力（是否陷入局部最優）。從最基礎的梯度下降法（GD）到現代深度學習的自適應優化器（Adam、RMSprop），優化演算法的演進顯著提升了機器學習的訓練效率與模型效能。

### 1.2 核心概念

**數值優化在機器學習中的六大核心概念：**

1. **損失函數（Loss Function）**：量化模型預測與真實值的差距，是優化的目標
2. **梯度（Gradient）**：損失函數對參數的偏導數，指向最陡峭上升方向（反方向為下降）
3. **梯度下降法（Gradient Descent）**：沿梯度反方向更新參數，逐步降低損失
4. **學習率（Learning Rate）**：控制每次更新的步長，影響收斂速度與穩定性
5. **優化器（Optimizer）**：改進的梯度下降變體（SGD、Momentum、Adam等），提升訓練效率
6. **正則化（Regularization）**：在損失函數中加入懲罰項（L1/L2），防止過擬合

### 1.3 CFDS 分解

基於 Formula-Contract 方法論，將數值優化在機器學習中的應用分解為四個基本單元：

```
NumericalOptimization_ML = f(C, F, D, S)
```

**C (Code - 可執行邏輯)**
```
C = LossComputation ∘ GradientCalculation ∘ ParameterUpdate ∘ ConvergenceCheck
  = 損失計算 -> 梯度計算 -> 參數更新 -> 收斂檢查
```

**F (Files - 配置資源)**
```
F = {OptimizerConfigs, LearningRateSchedules, RegularizationParameters, Checkpoints}
  = {優化器配置, 學習率調度, 正則化參數, 模型檢查點}
```

**D (Data - 資料結構)**
```
D = Parameters + Gradients + LossHistory + MomentumBuffers
  = 模型參數 + 梯度向量 + 損失歷史 + 動量緩衝
```

**S (State - 運行狀態)**
```
S = Training | Converged | Diverged | EarlyStopped
  = 訓練中 | 已收斂 | 已發散 | 提前停止
```

### 1.4 技術定位

數值優化在機器學習技術棧中處於訓練核心層，連接數學基礎（機率統計、線性代數）與模型實現（演算法、架構）。優化演算法的選擇直接影響模型訓練的成敗：學習率過大導致發散、過小導致收斂緩慢、不當優化器導致困在局部最優。

在企業應用中，數值優化技術決定了深度學習模型的可訓練性（能否收斂）、訓練成本（時間與計算資源）、模型品質（泛化能力）。Adam 優化器的發明使得複雜模型（如 Transformer）的訓練成為可能，學習率調度策略（如 Warmup）成為大模型訓練的標準配置。

---

## 2. 關鍵公式 (25%, 500-1500字)

### 2.1 損失函數主公式

**迴歸任務 - 均方誤差（MSE）**：
```
MSE = (1/n) × Σ(y_i - ŷ_i)²
```
- **y_i**：真實值
- **ŷ_i**：預測值
- **n**：樣本數量

**分類任務 - 交叉熵損失（Cross-Entropy）**：
```
CrossEntropy = -Σ(y_i × log(ŷ_i))
```
- **y_i**：真實標籤（one-hot 編碼）
- **ŷ_i**：預測機率（Softmax 輸出）

**正則化損失**：
```
TotalLoss = DataLoss + λ × RegularizationLoss
         = L(y, ŷ) + λ × R(θ)
```
- **L(y, ŷ)**：資料損失（MSE 或 CrossEntropy）
- **R(θ)**：正則化項（L1 或 L2）
- **λ**：正則化強度（超參數）

### 2.2 梯度下降法主公式

**基礎梯度下降（Gradient Descent, GD）**：
```
θ_{t+1} = θ_t - η × ∇L(θ_t)
```
- **θ_t**：當前參數
- **η**：學習率（learning rate）
- **∇L(θ_t)**：損失函數對參數的梯度

**梯度計算**：
```
∇L(θ) = ∂L/∂θ = [∂L/∂θ_1, ∂L/∂θ_2, ..., ∂L/∂θ_n]
```

**批次梯度下降**：
```
∇L(θ) = (1/N) × Σ_{i=1}^{N} ∇L_i(θ)
```
- **N**：訓練集大小
- **L_i**：第 i 筆資料的損失

### 2.3 梯度下降變體公式

**隨機梯度下降（Stochastic Gradient Descent, SGD）**：
```
θ_{t+1} = θ_t - η × ∇L_i(θ_t)
```
- 每次僅使用單筆資料（i）計算梯度
- **優點**：快速、記憶體低
- **缺點**：震盪大、不穩定

**小批次梯度下降（Mini-batch GD）**：
```
θ_{t+1} = θ_t - η × (1/B) × Σ_{i∈Batch} ∇L_i(θ_t)
```
- **B**：批次大小（batch size，常見 32、64、128）
- 平衡 GD 的穩定性與 SGD 的效率

### 2.4 進階優化器公式

**動量法（Momentum）**：
```
v_t = β × v_{t-1} + ∇L(θ_t)
θ_{t+1} = θ_t - η × v_t
```
- **v_t**：動量（velocity），累積歷史梯度
- **β**：動量係數（常見 0.9）
- **效果**：加速收斂、減少震盪

**RMSprop（Root Mean Square Propagation）**：
```
s_t = β × s_{t-1} + (1-β) × (∇L(θ_t))²
θ_{t+1} = θ_t - η × ∇L(θ_t) / √(s_t + ε)
```
- **s_t**：梯度平方的指數移動平均
- **β**：衰減率（常見 0.9）
- **ε**：數值穩定項（常見 10^(-8)）
- **效果**：自適應學習率、穩定訓練

**Adam（Adaptive Moment Estimation）**：
```
m_t = β_1 × m_{t-1} + (1-β_1) × ∇L(θ_t)          # 一階動量（梯度均值）
v_t = β_2 × v_{t-1} + (1-β_2) × (∇L(θ_t))²      # 二階動量（梯度方差）

m̂_t = m_t / (1 - β_1^t)                         # 偏差修正
v̂_t = v_t / (1 - β_2^t)

θ_{t+1} = θ_t - η × m̂_t / (√v̂_t + ε)
```
- **m_t**：一階動量（類似 Momentum）
- **v_t**：二階動量（類似 RMSprop）
- **β_1**：一階動量衰減率（常見 0.9）
- **β_2**：二階動量衰減率（常見 0.999）
- **η**：學習率（常見 0.001）
- **效果**：結合 Momentum 與 RMSprop 優點，深度學習首選

### 2.5 正則化公式

**L1 正則化（Lasso）**：
```
R_L1(θ) = Σ|θ_i|
TotalLoss = DataLoss + λ × Σ|θ_i|
```
- **效果**：產生稀疏性（多數參數為 0）
- **應用**：特徵選擇、模型簡化

**L2 正則化（Ridge）**：
```
R_L2(θ) = Σθ_i²
TotalLoss = DataLoss + λ × Σθ_i²
```
- **效果**：參數平滑、防止過擬合
- **應用**：神經網路權重衰減（Weight Decay）

**L1 與 L2 對比**：
- **L1**：絕對值懲罰，產生稀疏解（部分參數歸零）
- **L2**：平方懲罰，平滑縮小參數（所有參數縮小但不歸零）

### 2.6 學習率調度公式

**步驟衰減（Step Decay）**：
```
η_t = η_0 × γ^(⌊t/T⌋)
```
- **η_0**：初始學習率
- **γ**：衰減因子（常見 0.1）
- **T**：衰減週期（每 T 個 epoch 衰減一次）

**指數衰減（Exponential Decay）**：
```
η_t = η_0 × e^(-λt)
```

**餘弦退火（Cosine Annealing）**：
```
η_t = η_min + (η_max - η_min) × (1 + cos(πt/T)) / 2
```
- **效果**：平滑降低學習率、幫助模型精細調整

---

## 3. 對比矩陣 (15%, 300-900字)

### 3.1 技術對比表

| 優化器 | 更新規則 | 記憶體需求 | 收斂速度 | 穩定性 | 超參數敏感度 | 適用場景 |
|--------|---------|-----------|---------|-------|-------------|---------|
| **GD** | θ - η∇L | 低 | 慢 | 高 | 低 | 小資料集 |
| **SGD** | θ - η∇L_i | 極低 | 快但震盪 | 低 | 高 | 大資料集、線上學習 |
| **Mini-batch GD** | θ - η×(1/B)Σ∇L_i | 低 | 中 | 中 | 中 | 深度學習標配 |
| **Momentum** | θ - η×v_t | 中 | 快 | 中高 | 中 | 加速收斂 |
| **RMSprop** | θ - η∇L/√s_t | 中 | 快 | 高 | 中 | RNN、非穩定梯度 |
| **Adam** | θ - η×m̂_t/√v̂_t | 中 | 最快 | 最高 | 低 | 深度學習首選 |

### 3.2 優缺點分析

**批次梯度下降（GD）**
- **優點**：梯度準確、收斂穩定、可平行化
- **缺點**：計算成本高（每次迭代需遍歷全部資料）、無法線上學習
- **適用**：凸優化問題、小資料集（< 10,000 筆）

**隨機梯度下降（SGD）**
- **優點**：速度快、記憶體低、可線上學習、能逃離局部最優
- **缺點**：梯度噪音大、震盪嚴重、收斂不穩
- **適用**：大資料集、即時訓練

**動量法（Momentum）**
- **優點**：加速收斂、減少震盪、突破局部最優
- **缺點**：引入額外超參數（β）、可能衝過最優點
- **適用**：深層網路、高曲率損失面

**Adam**
- **優點**：自適應學習率、收斂快速、穩定性高、超參數不敏感
- **缺點**：記憶體需求較高（需存儲 m_t 和 v_t）、某些情境泛化能力不如 SGD
- **適用**：深度學習標配（CNN、RNN、Transformer）

### 3.3 適用場景

**何時使用 GD？**
- 資料集小（< 10,000 筆）
- 需要精確梯度（科學計算）
- 可平行化的計算環境

**何時使用 SGD/Mini-batch GD？**
- 大資料集（> 100萬筆）
- 線上學習（資料流式到達）
- GPU 訓練（Mini-batch 適合 GPU 平行化）

**何時使用 Adam？**
- 深度學習模型（CNN、RNN、Transformer）
- 不確定如何調整學習率
- 需要快速原型驗證
- 非凸優化問題

**何時使用 Momentum/RMSprop？**
- Momentum：需加速收斂、損失面高曲率
- RMSprop：RNN 訓練（梯度消失/爆炸）、非穩定梯度

### 3.4 性能比較

**收斂速度（相同準確率所需迭代次數）**：
Adam > Momentum > RMSprop > Mini-batch GD > SGD > GD

**訓練穩定性（震盪程度）**：
GD > Adam > RMSprop > Momentum > Mini-batch GD > SGD

**記憶體需求**：
SGD = GD < Mini-batch GD < Momentum = RMSprop = Adam

**泛化能力（測試集表現）**：
SGD（適當調校）≥ Adam ≥ Momentum ≥ GD

**實務選擇**：
- **快速原型**：Adam（預設選擇）
- **追求極致效能**：SGD + 精細調參 + 學習率調度
- **大型模型**：Adam + Warmup + 餘弦退火

---

## 4. 實務應用 (20%, 400-1200字)

### 4.1 應用場景一：深度神經網路訓練

**場景描述**：訓練 ResNet-50 影像分類模型，1000 類別、100 萬張訓練影像。

**技術應用**：使用 Adam 優化器 + 學習率 Warmup + 餘弦退火。

**實現要點**：
```
DeepLearningTraining = DataLoading -> ForwardPass -> LossComputation ->
                        BackwardPass(Gradients) -> AdamUpdate -> LearningRateSchedule

AdamOptimizer:
  初始學習率: η_0 = 0.001
  β_1 = 0.9 (一階動量)
  β_2 = 0.999 (二階動量)
  ε = 1e-8

LearningRateSchedule:
  Warmup(5 epochs): η_t = η_0 × (t/5)  # 線性增長
  CosineAnnealing(95 epochs): η_t = η_min + (η_0-η_min)×(1+cos(πt/95))/2
```

**效果**：
- 100 epoch 達到 76% Top-1 準確率
- 訓練穩定、無發散
- Adam 自動調整各層學習率

### 4.2 應用場景二：線上學習系統

**場景描述**：廣告點擊率預測（CTR），資料持續流入，需即時更新模型。

**技術應用**：使用 SGD + 固定小學習率 + L2 正則化。

**實現要點**：
```
OnlineLearning = StreamData -> FeatureExtraction -> PredictCTR ->
                  ObserveClick -> ComputeLoss -> SGD_Update

SGD_Configuration:
  學習率: η = 0.01 (固定)
  L2 正則化: λ = 0.0001
  更新頻率: 每筆資料即時更新

更新公式:
  θ_new = θ_old - η × (∇L_i(θ) + λ × θ_old)
```

**效果**：
- 模型即時適應最新點擊行為
- 記憶體需求極低（無需存儲歷史梯度）
- 每秒處理 10,000+ 次更新

### 4.3 應用場景三：超參數調校實驗

**場景描述**：調整學習率與優化器，找出最佳訓練配置。

**技術應用**：網格搜尋（Grid Search）+ 學習曲線分析。

**實現要點**：
```
HyperparameterTuning = GridSearch(Optimizers × LearningRates) ->
                        TrainModels -> EvaluateValidation -> SelectBest

搜尋空間:
  Optimizers: [SGD, Momentum, Adam]
  LearningRates: [0.1, 0.01, 0.001, 0.0001]
  總共: 3 × 4 = 12 組實驗

評估指標:
  - 驗證集準確率
  - 收斂速度（達到 90% 準確率所需 epoch）
  - 訓練穩定性（損失曲線平滑度）
```

**實驗結果示例**：
| 優化器 | 學習率 | 驗證準確率 | 收斂 epoch | 穩定性 |
|--------|--------|-----------|-----------|--------|
| SGD | 0.1 | 發散 | - | 極差 |
| SGD | 0.01 | 88% | 50 | 中 |
| Adam | 0.001 | 92% | 30 | 優 |
| Adam | 0.01 | 90% | 25 | 良 |

**結論**：Adam (η=0.001) 為最佳配置。

### 4.4 實作步驟

**通用訓練流程**：

1. **初始化參數**：隨機初始化模型權重 θ_0
2. **設定優化器**：選擇 Adam/SGD，設定學習率 η
3. **迭代訓練**：
   ```
   For epoch in range(num_epochs):
       For batch in dataloader:
           # Forward Pass
           predictions = model(batch.data)
           loss = loss_function(predictions, batch.labels)

           # Backward Pass
           gradients = compute_gradients(loss, θ)

           # Optimizer Update
           θ = optimizer.update(θ, gradients)

           # Learning Rate Schedule
           η = lr_scheduler.step(epoch)
   ```
4. **監控指標**：追蹤訓練損失、驗證準確率、梯度範數
5. **提前停止**：驗證損失 N 個 epoch 未改善則停止
6. **儲存模型**：保存驗證集表現最佳的檢查點

### 4.5 常見陷阱

**陷阱 1：學習率過大導致發散**
- **現象**：訓練損失突然上升、模型輸出 NaN
- **解決**：降低學習率（除以 10）、使用梯度裁剪（Gradient Clipping）

**陷阱 2：學習率過小導致收斂緩慢**
- **現象**：損失下降極慢、訓練時間過長
- **解決**：增大學習率、使用 Adam 自適應學習率

**陷阱 3：過擬合訓練集**
- **現象**：訓練準確率 99%、驗證準確率 70%
- **解決**：加入 L2 正則化、Dropout、Early Stopping

**陷阱 4：批次大小設定不當**
- **太小**（如 batch=1）：震盪大、難收斂
- **太大**（如 batch=10000）：泛化能力差、記憶體不足
- **建議**：32-128（小模型）、128-512（大模型）

**陷阱 5：梯度消失/爆炸**
- **梯度消失**：深層網路梯度趨近 0，無法更新
- **梯度爆炸**：梯度過大，參數發散
- **解決**：梯度裁剪、Batch Normalization、殘差連接（ResNet）

---

## 5. 記憶口訣 (10%, 200-600字)

### 5.1 核心口訣

**「損失梯度學習率，參數更新靠優化」**
- **損失**：目標函數（MSE、CrossEntropy）
- **梯度**：損失對參數的導數
- **學習率**：控制更新步長
- **優化**：演算法（GD、Adam）

**「Adam 口訣：一階二階皆自適應，深度學習首選器」**
- **一階動量**：m_t（梯度均值，類似 Momentum）
- **二階動量**：v_t（梯度方差，類似 RMSprop）
- **自適應**：每個參數獨立學習率
- **深度學習**：CNN、RNN、Transformer 標配

### 5.2 記憶技巧

**優化器選擇順口溜**：「小資料 GD，大資料 SGD，深度學習 Adam 穩」
- **小資料**（< 1萬）：批次梯度下降（GD）
- **大資料**（> 100萬）：隨機/小批次梯度下降（SGD/Mini-batch GD）
- **深度學習**：Adam（不確定就用它）

**梯度下降三要素**：「參數、學習率、梯度」
```
θ_{t+1} = θ_t - η × ∇L(θ_t)
參數      參數  學習率  梯度
```

**Adam 更新記憶**：「先算動量，再算自適應，最後更新參數」
```
Step 1: m_t (一階動量) = β_1 × m_{t-1} + (1-β_1) × ∇L
Step 2: v_t (二階動量) = β_2 × v_{t-1} + (1-β_2) × (∇L)²
Step 3: θ_{t+1} = θ_t - η × m̂_t / √v̂_t
```

**正則化 L1 vs L2**：「L1 稀疏化，L2 平滑化」
- **L1**（絕對值）：產生稀疏解（參數歸零）
- **L2**（平方）：平滑縮小參數（不歸零）

### 5.3 快速回憶

**優化器核心公式速查**：
- **GD**：θ - η∇L（全部資料）
- **SGD**：θ - η∇L_i（單筆資料）
- **Momentum**：θ - η×v_t（累積動量）
- **Adam**：θ - η×m̂_t/√v̂_t（自適應）

**學習率調度策略**：
- **固定**：η = const（簡單但效果差）
- **步驟衰減**：每 T epoch 乘以 γ
- **指數衰減**：η × e^(-λt)
- **餘弦退火**：η 按餘弦曲線下降

**正則化強度選擇**：
- **λ = 0**：無正則化（可能過擬合）
- **λ = 0.0001-0.001**：輕度正則化（常見值）
- **λ > 0.01**：強正則化（可能欠擬合）

### 5.4 易混淆辨析

**GD vs SGD vs Mini-batch GD**：
- **GD**：每次迭代使用全部資料（慢但穩）
- **SGD**：每次迭代使用單筆資料（快但震盪）
- **Mini-batch GD**：每次使用小批次（平衡折衷）

**Momentum vs Adam**：
- **Momentum**：僅一階動量（梯度均值）
- **Adam**：一階+二階動量（梯度均值+方差）

**L1 vs L2 正則化**：
- **L1**：Σ|θ_i|，產生稀疏性（特徵選擇）
- **L2**：Σθ_i²，參數平滑（防止過擬合）

**學習率過大 vs 過小**：
- **過大**：發散、震盪、NaN
- **過小**：收斂慢、陷入局部最優

---

## 6. 自我驗證 (10%, 200-600字)

### 6.1 選擇題

**Q1：以下哪個優化器結合了 Momentum 與 RMSprop 的優點？**
A. 批次梯度下降（GD）
B. 隨機梯度下降（SGD）
C. Adam
D. Adagrad

**Q2：在深度學習訓練中，如果訓練損失突然上升並出現 NaN，最可能的原因是？**
A. 學習率過小
B. 學習率過大
C. 批次大小過小
D. 正則化過強

**Q3：L1 正則化相比 L2 正則化的主要特性是？**
A. 計算更快
B. 產生稀疏性（部分參數歸零）
C. 防止過擬合能力更強
D. 適用於所有模型

**Q4：Mini-batch 梯度下降的批次大小（batch size）通常設為多少？**
A. 1
B. 整個訓練集大小
C. 32-128
D. 10,000+

**Q5：Adam 優化器中，β_1 和 β_2 參數的常見預設值為？**
A. β_1=0.5, β_2=0.5
B. β_1=0.9, β_2=0.999
C. β_1=0.99, β_2=0.9
D. β_1=0.1, β_2=0.1

### 6.2 簡答題

**Q1：解釋為什麼深度學習訓練通常選擇 Adam 優化器而非 SGD？**

**Q2：說明學習率調度（Learning Rate Schedule）的作用，並舉例說明 Warmup 策略的原理。**

### 6.3 答案解析

**選擇題答案**：

**A1：C（Adam）**
- **解析**：Adam 全稱 Adaptive Moment Estimation，結合 Momentum（一階動量 m_t）與 RMSprop（二階動量 v_t），具備加速收斂與自適應學習率的雙重優點，是深度學習訓練的首選優化器。

**A2：B（學習率過大）**
- **解析**：學習率過大導致參數更新幅度過大，跳過最優點甚至發散。當損失突然上升並出現 NaN（Not a Number），應立即降低學習率（除以 10）或使用梯度裁剪（Gradient Clipping）。

**A3：B（產生稀疏性）**
- **解析**：L1 正則化（Lasso）對參數絕對值進行懲罰（Σ|θ_i|），導致許多參數收斂至 0，產生稀疏解。這使得 L1 適用於特徵選擇場景。L2 正則化（Ridge）則平滑縮小所有參數但不歸零。

**A4：C（32-128）**
- **解析**：Mini-batch 梯度下降的批次大小通常設為 32-128（小模型）或 128-512（大模型如 Transformer）。太小（如 1）導致震盪、太大（如全部資料）失去 SGD 的隨機性優勢且記憶體不足。

**A5：B（β_1=0.9, β_2=0.999）**
- **解析**：Adam 論文建議的預設值為 β_1=0.9（一階動量衰減率）、β_2=0.999（二階動量衰減率）、ε=1e-8（數值穩定項）、η=0.001（學習率）。這組參數在大多數深度學習任務中表現良好。

**簡答題答案**：

**A1：Adam vs SGD 的選擇**

深度學習訓練通常優先選擇 Adam 的原因：

**1. 自適應學習率**：
- **Adam**：每個參數獨立調整學習率（基於歷史梯度的一階與二階動量），自動適應不同參數的更新需求
- **SGD**：所有參數使用固定學習率，需手動精細調整

**2. 收斂速度**：
- **Adam**：結合 Momentum 加速與 RMSprop 自適應，收斂速度通常比 SGD 快 2-5 倍
- **SGD**：需搭配學習率調度與大量調參才能達到類似效果

**3. 超參數敏感度**：
- **Adam**：對學習率不敏感，預設值（η=0.001, β_1=0.9, β_2=0.999）即可良好運作
- **SGD**：對學習率極度敏感，需仔細網格搜尋

**4. 訓練穩定性**：
- **Adam**：二階動量機制穩定梯度更新，減少震盪
- **SGD**：梯度噪音大，容易震盪

**例外情境**：某些研究顯示，精心調校的 SGD + Momentum 在泛化能力上可能略優於 Adam（如 ImageNet 訓練），但需要專家級調參。

**A2：學習率調度與 Warmup 策略**

**學習率調度的作用**：

學習率調度（Learning Rate Schedule）動態調整學習率，在訓練不同階段使用不同步長：

1. **初期**：大學習率快速下降損失（探索階段）
2. **中期**：中等學習率穩定收斂（優化階段）
3. **後期**：小學習率精細調整（微調階段）

**常見策略**：
- **步驟衰減**：每 N epoch 學習率乘以 γ（如 0.1）
- **指數衰減**：η_t = η_0 × e^(-λt)
- **餘弦退火**：學習率按餘弦曲線平滑下降

**Warmup 策略原理**：

Warmup 是指訓練初期（通常前 5-10 epoch）線性增長學習率，而非直接使用目標學習率：

```
η_t = η_target × (t / T_warmup)  # t ∈ [0, T_warmup]
```

**原因**：
1. **初始參數不穩定**：隨機初始化的參數梯度可能極大，大學習率會導致發散
2. **Adam 偏差問題**：訓練初期 m_t 和 v_t 偏差較大，小學習率可減輕影響
3. **大批次訓練**：大 batch size（如 8192）需要 Warmup 穩定訓練

**實例**：Transformer 訓練常用 Warmup + 餘弦退火
```
前 5 epoch: η_t = 0.001 × (t/5)  # Warmup
後 95 epoch: η_t = 0.001 × cos(πt/95)  # 餘弦退火
```

### 6.4 易錯點提醒

**易錯點 1：混淆梯度方向與更新方向**
- **梯度方向**：損失函數上升方向（∇L）
- **更新方向**：參數下降方向（-η∇L）
- **提醒**：梯度下降沿梯度反方向更新

**易錯點 2：學習率調度未同步優化器**
- **錯誤**：手動修改學習率但優化器內部狀態未更新
- **提醒**：使用框架提供的 lr_scheduler（如 PyTorch 的 StepLR）

**易錯點 3：正則化強度設定極端**
- **λ=0**：無正則化，可能過擬合
- **λ=10**：過強正則化，模型欠擬合
- **建議**：從 λ=0.0001 開始，根據驗證集調整

**易錯點 4：批次大小與學習率不匹配**
- **錯誤**：增大 batch size 但學習率不變，收斂變慢
- **建議**：batch size 增大 k 倍，學習率也增大 k 倍（線性縮放規則）

**易錯點 5：過早停止訓練**
- **現象**：驗證損失短暫上升即停止，未達收斂
- **建議**：設定 Early Stopping 的耐心值（如 10 epoch 未改善才停止）
