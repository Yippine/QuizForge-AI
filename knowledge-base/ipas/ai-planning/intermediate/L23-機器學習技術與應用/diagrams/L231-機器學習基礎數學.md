# L231 - 機器學習基礎數學

## 架構說明

本章節建立機器學習所需的數學基礎，涵蓋三大核心數學領域：
- **機率統計**：處理數據不確定性，支撐模型推論
- **線性代數**：支援數據表示和模型運算
- **數值優化**：實現參數學習和模型訓練

## Mermaid 架構圖

```mermaid
graph TD
    L231[L231 機器學習基礎數學]

    subgraph Prob_Group[機率統計之機器學習基礎應用]
        L23101[L23101 機率統計之ML基礎應用]

        ProbDist(機率分佈)
        CondProb(條件機率)
        HypoTest(假設檢定)
        StatInfer(統計推論)

        Normal(常態分佈)
        Bernoulli(伯努利分佈)
        Bayes(貝氏定理)
        MLE(最大概似估計)
    end

    subgraph LinAlg_Group[線性代數之機器學習基礎應用]
        L23102[L23102 線性代數之ML基礎應用]

        Vector(向量運算)
        Matrix(矩陣運算)
        EigenDecomp(特徵分解)
        LinTrans(線性轉換)

        DotProd(內積與外積)
        MatMul(矩陣乘法)
        Eigenvalue(特徵值與特徵向量)
        SVD(奇異值分解)
    end

    subgraph Optim_Group[數值優化技術與方法]
        L23103[L23103 數值優化技術與方法]

        GradDesc(梯度下降)
        Newton(牛頓法)
        OptAlgo(優化演算法)

        SGD(隨機梯度下降)
        Adam(Adam優化器)
        ConvexOpt(凸優化)
    end

    subgraph Applications[機器學習應用]
        App1{分類問題}
        App2{回歸問題}
        App3{降維技術}
        App4{模型訓練}
    end

    %% 章節層級
    L231 --> L23101
    L231 --> L23102
    L231 --> L23103

    %% 機率統計架構
    L23101 --> ProbDist
    L23101 --> CondProb
    L23101 --> HypoTest
    L23101 --> StatInfer

    ProbDist --> Normal
    ProbDist --> Bernoulli
    CondProb --> Bayes
    StatInfer --> MLE

    %% 線性代數架構
    L23102 --> Vector
    L23102 --> Matrix
    L23102 --> EigenDecomp
    L23102 --> LinTrans

    Vector --> DotProd
    Matrix --> MatMul
    EigenDecomp --> Eigenvalue
    EigenDecomp --> SVD

    %% 數值優化架構
    L23103 --> GradDesc
    L23103 --> Newton
    L23103 --> OptAlgo

    GradDesc --> SGD
    OptAlgo --> Adam
    OptAlgo --> ConvexOpt

    %% 應用關聯
    Bayes ==> App1
    MLE ==> App2
    SVD ==> App3
    SGD ==> App4
    Adam ==> App4

    %% 跨主題依賴
    ProbDist -.-> MLE
    Vector -.-> GradDesc
    Matrix -.-> EigenDecomp
    MLE -.-> OptAlgo

    %% 樣式定義
    classDef coreStyle fill:#e1f5ff,stroke:#0066cc,stroke-width:3px
    classDef supportStyle fill:#fff4e6,stroke:#ff9800,stroke-width:2px
    classDef appStyle fill:#e8f5e9,stroke:#4caf50,stroke-width:2px

    class L231,L23101,L23102,L23103 coreStyle
    class ProbDist,CondProb,HypoTest,StatInfer,Normal,Bernoulli,Bayes,MLE,Vector,Matrix,EigenDecomp,LinTrans,DotProd,MatMul,Eigenvalue,SVD,GradDesc,Newton,OptAlgo,SGD,Adam,ConvexOpt supportStyle
    class App1,App2,App3,App4 appStyle
```

## 說明

### 核心概念

- **機率統計**：
  - 機率分佈（常態分佈、伯努利分佈）描述數據的不確定性
  - 條件機率和貝氏定理支撐貝氏學習
  - 假設檢定和統計推論（如 MLE）用於參數估計

- **線性代數**：
  - 向量和矩陣運算是數據表示的基礎
  - 特徵分解（特徵值、特徵向量、SVD）用於降維和數據分析
  - 線性轉換描述數據變換

- **數值優化**：
  - 梯度下降及其變體（SGD）是最常用的優化方法
  - Adam 等優化器提升訓練效率
  - 凸優化理論保證收斂性

### 關聯說明

- **層級關係（-->）**：章節 -> 主題 -> 數學概念的展開
- **依賴關係（-.->）**：
  - 機率分佈 -> 最大概似估計
  - 向量運算 -> 梯度下降
  - 矩陣運算 -> 特徵分解
  - 最大概似估計 -> 優化演算法
- **應用關係（==>）**：
  - 貝氏定理 -> 分類問題
  - 最大概似估計 -> 回歸問題
  - 奇異值分解 -> 降維技術
  - 梯度下降/Adam -> 模型訓練

### 學習路徑建議

1. **機率統計基礎**：理解機率分佈、條件機率和貝氏定理
2. **線性代數基礎**：掌握向量、矩陣運算和特徵分解
3. **優化方法**：學習梯度下降及其變體
4. **整合應用**：將三者結合應用於實際機器學習問題
