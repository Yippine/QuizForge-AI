{
  "exam_info": {
    "exam_name": "iPAS AI工程師能力鑑定 - 科目1模擬考試",
    "subject": "L21 - 人工智慧技術應用規劃",
    "total_questions": 120,
    "difficulty_distribution": {
      "simple": 36,
      "medium": 60,
      "hard": 24
    },
    "question_types": {
      "technical_selection": 48,
      "technical_principles": 48,
      "system_integration": 24
    },
    "created_date": "2025-11-04",
    "version": "1.0"
  },
  "questions": [
    {
      "question_id": "L21101_001",
      "sequence": 1,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在自然語言處理(NLP)的發展歷程中,以下哪一個階段最早出現?",
      "options": {
        "A": "基於深度學習的方法",
        "B": "基於規則的方法",
        "C": "基於統計的方法",
        "D": "基於預訓練模型的方法"
      },
      "answer": "B",
      "explanation": "根據NLP技術演進路徑,發展順序為:規則→統計→深度學習→預訓練模型。基於規則的方法(1950s-1980s)是最早期的NLP技術,使用專家定義的語法規則和詞典進行文本處理。之後才依序發展出統計方法(1990s-2000s)、深度學習方法(2010s)和預訓練模型(2018年後)。",
      "keywords": ["NLP演進", "規則基礎", "技術發展史"],
      "reference": "L21101-自然語言處理技術與應用.md - NLP技術演進"
    },
    {
      "question_id": "L21101_002",
      "sequence": 2,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "關於Tokenization(分詞)與Lemmatization(詞形還原)的差異,下列敘述何者正確?",
      "options": {
        "A": "Tokenization是將文本還原為詞根形式,Lemmatization是將文本切分為token",
        "B": "Tokenization是將文本切分為token,Lemmatization是將詞彙還原為字典原型",
        "C": "兩者功能完全相同,只是術語不同",
        "D": "Tokenization需要詞性標註,Lemmatization不需要"
      },
      "answer": "B",
      "explanation": "Tokenization(分詞)是將連續文本切分為有意義的最小單位(token),例如將'I am learning NLP'切分為['I', 'am', 'learning', 'NLP']。Lemmatization(詞形還原)則是將詞彙還原為字典中的原型(lemma),例如'running'→'run', 'better'→'good'。Lemmatization需要考慮詞性,而Tokenization主要是切分任務。",
      "keywords": ["Tokenization", "Lemmatization", "文本預處理", "詞形還原"],
      "reference": "L21101-自然語言處理技術與應用.md - 文本預處理技術"
    },
    {
      "question_id": "L21101_003",
      "sequence": 3,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在Word2Vec模型中,CBOW與Skip-gram的主要差異為何?",
      "options": {
        "A": "CBOW用上下文預測中心詞,Skip-gram用中心詞預測上下文",
        "B": "CBOW用中心詞預測上下文,Skip-gram用上下文預測中心詞",
        "C": "CBOW適用於大語料庫,Skip-gram適用於小語料庫",
        "D": "CBOW是監督式學習,Skip-gram是非監督式學習"
      },
      "answer": "A",
      "explanation": "Word2Vec有兩種訓練架構:CBOW(Continuous Bag of Words)使用上下文詞彙預測中心詞,訓練速度較快,適合大語料庫;Skip-gram使用中心詞預測周圍上下文,對低頻詞表現較好,適合小語料庫。兩者都是非監督式學習方法,透過詞彙的分布式表示學習語義相似性。",
      "keywords": ["Word2Vec", "CBOW", "Skip-gram", "詞向量"],
      "reference": "L21101-自然語言處理技術與應用.md - Word2Vec原理"
    },
    {
      "question_id": "L21101_004",
      "sequence": 4,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某電商平台希望建立商品評論情感分析系統,需要處理包含「很好」、「非常好」、「超級好」等不同程度讚美的評論。在文本預處理階段,以下哪種技術組合最適合保留情感強度資訊?",
      "options": {
        "A": "Stemming + 去除停用詞",
        "B": "Lemmatization + 保留程度副詞",
        "C": "分詞 + 去除所有副詞",
        "D": "僅使用Tokenization,不進行其他處理"
      },
      "answer": "B",
      "explanation": "在情感分析任務中,程度副詞(如「很」、「非常」、「超級」)是表達情感強度的重要特徵。Lemmatization能保留詞彙的完整語義(不會過度簡化),同時保留程度副詞可以區分不同情感強度。Stemming會將詞彙簡化為詞根,可能損失語義資訊;去除副詞會直接丟失情感強度特徵;僅Tokenization則無法處理詞形變化。因此B選項最適合此商業場景。",
      "keywords": [
        "情感分析",
        "文本預處理",
        "Lemmatization",
        "程度副詞",
        "商業應用"
      ],
      "reference": "L21101-自然語言處理技術與應用.md - 文本預處理技術選擇"
    },
    {
      "question_id": "L21101_005",
      "sequence": 5,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在Transformer架構中,Self-Attention機制的Query(Q)、Key(K)、Value(V)是如何計算的?",
      "options": {
        "A": "Q、K、V都是輸入向量直接使用,不需要變換",
        "B": "Q、K、V分別由輸入向量與三個不同的權重矩陣相乘得到",
        "C": "Q、K使用相同權重矩陣,V使用不同權重矩陣",
        "D": "Q、K、V使用相同權重矩陣進行變換"
      },
      "answer": "B",
      "explanation": "在Transformer的Self-Attention機制中,Query(Q)、Key(K)、Value(V)分別由輸入向量X與三個獨立的權重矩陣W_Q、W_K、W_V相乘得到:Q=XW_Q, K=XW_K, V=XW_V。這三個權重矩陣是透過訓練學習的參數,使模型能夠學習不同的注意力模式。注意力分數計算為Attention(Q,K,V) = softmax(QK^T/√d_k)V,其中d_k是Key向量的維度。",
      "keywords": ["Transformer", "Self-Attention", "QKV機制", "注意力機制"],
      "reference": "L21101-自然語言處理技術與應用.md - Transformer架構"
    },
    {
      "question_id": "L21101_006",
      "sequence": 6,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某醫療機構要建立病歷摘要生成系統,需要處理包含專業醫學術語的長篇病歷文本。在選擇NLP模型時,以下哪個考量最為關鍵?",
      "options": {
        "A": "模型的訓練速度",
        "B": "模型對長文本的處理能力與領域適應性",
        "C": "模型參數量的大小",
        "D": "模型的開源授權方式"
      },
      "answer": "B",
      "explanation": "醫療病歷摘要生成系統的核心挑戰在於:(1)病歷文本通常很長,需要能處理長序列的模型;(2)包含大量專業醫學術語,需要領域適應能力。因此,模型對長文本的處理能力(如Transformer的位置編碼長度限制)與領域適應性(是否能微調或使用醫學領域預訓練模型)是最關鍵的考量。雖然訓練速度、參數量、授權方式也重要,但不如任務核心需求關鍵。實務上可選擇支援長文本的模型(如Longformer)並進行醫學領域微調。",
      "keywords": ["文本摘要", "長文本處理", "領域適應", "醫療NLP", "模型選擇"],
      "reference": "L21101-自然語言處理技術與應用.md - NLP模型選擇考量"
    },
    {
      "question_id": "L21101_007",
      "sequence": 7,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "BERT與GPT在預訓練任務上的主要差異為何?",
      "options": {
        "A": "BERT使用Masked Language Model雙向訓練,GPT使用自迴歸單向訓練",
        "B": "BERT使用自迴歸單向訓練,GPT使用Masked Language Model雙向訓練",
        "C": "BERT專注於文本生成,GPT專注於文本理解",
        "D": "BERT使用Encoder架構,GPT也使用Encoder架構"
      },
      "answer": "A",
      "explanation": "BERT(Bidirectional Encoder Representations from Transformers)使用Masked Language Model(MLM)進行預訓練,隨機遮蔽15%的token並預測,能同時利用上下文雙向資訊,適合理解型任務。GPT(Generative Pre-trained Transformer)使用自迴歸(autoregressive)方式進行單向訓練,只能看到左側上下文來預測下一個詞,適合生成型任務。BERT使用Transformer Encoder架構,GPT使用Transformer Decoder架構。",
      "keywords": ["BERT", "GPT", "預訓練任務", "MLM", "自迴歸", "雙向vs單向"],
      "reference": "L21101-自然語言處理技術與應用.md - BERT vs GPT對比"
    },
    {
      "question_id": "L21101_008",
      "sequence": 8,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某新聞媒體希望建立自動文章分類系統,將新聞分為政治、經濟、體育、娛樂等類別。現有10萬篇已標註的歷史新聞資料。以下哪種模型策略最具成本效益?",
      "options": {
        "A": "從零訓練一個Transformer模型",
        "B": "使用預訓練BERT模型進行微調(Fine-tuning)",
        "C": "僅使用TF-IDF+傳統機器學習分類器",
        "D": "使用GPT模型進行Few-shot Learning"
      },
      "answer": "B",
      "explanation": "在有10萬篇標註資料的情況下,使用預訓練BERT模型進行微調是最具成本效益的策略。理由:(1)BERT已經學習了豐富的語言表示,微調只需較少的計算資源;(2)10萬篇資料足夠進行有效微調;(3)文本分類是BERT擅長的理解型任務。選項A從零訓練需要大量計算資源;選項C的TF-IDF無法捕捉語義資訊,效果較差;選項D的Few-shot Learning在已有大量標註資料時不如微調效果好且成本較高。",
      "keywords": [
        "文本分類",
        "BERT微調",
        "預訓練模型",
        "成本效益",
        "模型選擇"
      ],
      "reference": "L21101-自然語言處理技術與應用.md - 預訓練模型應用"
    },
    {
      "question_id": "L21101_009",
      "sequence": 9,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在Transformer的Multi-Head Attention機制中,使用多個注意力頭(heads)的主要優勢為何?",
      "options": {
        "A": "減少模型參數量,降低過擬合風險",
        "B": "讓模型能夠關注不同位置的不同表示子空間資訊",
        "C": "加快模型訓練速度",
        "D": "簡化模型架構,便於部署"
      },
      "answer": "B",
      "explanation": "Multi-Head Attention使用多個注意力頭的核心優勢是讓模型能夠同時關注不同位置的不同表示子空間資訊。每個注意力頭學習不同的Q、K、V投影,可以捕捉不同類型的依賴關係(如語法關係、語義關係、長距離依賴等)。例如8個頭可以同時學習8種不同的注意力模式,然後concat後再投影,豐富了模型的表示能力。Multi-Head Attention實際上會增加參數量,也不會顯著加快訓練速度或簡化架構。",
      "keywords": [
        "Multi-Head Attention",
        "多頭注意力",
        "Transformer",
        "表示子空間"
      ],
      "reference": "L21101-自然語言處理技術與應用.md - Transformer Multi-Head機制"
    },
    {
      "question_id": "L21101_010",
      "sequence": 10,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "hard",
      "question_type": "technical_principles",
      "question": "在Self-Attention計算中,為什麼需要將QK^T的結果除以√d_k(Key向量維度的平方根)?",
      "options": {
        "A": "為了加快計算速度",
        "B": "為了防止點積結果過大導致softmax梯度消失",
        "C": "為了確保輸出向量的維度正確",
        "D": "為了實現模型的歸一化"
      },
      "answer": "B",
      "explanation": "在Self-Attention機制中,將QK^T除以√d_k是為了進行scaled dot-product,防止點積結果過大。當d_k較大時,QK^T的點積值會變得很大,導致softmax函數進入飽和區(極大的值會導致softmax輸出接近1,其他接近0),此時梯度會變得極小,造成梯度消失問題,影響訓練效果。除以√d_k可以將點積結果的方差控制在合理範圍,使softmax保持良好的梯度特性。這是數學上的優化技巧,與計算速度、維度轉換、模型歸一化無直接關係。",
      "keywords": [
        "Scaled Dot-Product",
        "Self-Attention",
        "梯度消失",
        "Softmax飽和"
      ],
      "reference": "L21101-自然語言處理技術與應用.md - Attention機制數學原理"
    },
    {
      "question_id": "L21101_011",
      "sequence": 11,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某跨國企業要建立多語言客服聊天機器人,需要支援中、英、日、韓四種語言。系統需要理解客戶問題並生成回應。在設計系統架構時,以下哪種策略最能兼顧效能與維護成本?",
      "options": {
        "A": "為每種語言分別訓練獨立的模型,各自部署",
        "B": "使用多語言預訓練模型(如mBERT或XLM-R)作為統一backbone,加上任務特定的微調",
        "C": "先將所有語言翻譯成英文,再使用英文模型處理",
        "D": "使用規則型系統分別為每種語言建立對話樹"
      },
      "answer": "B",
      "explanation": "使用多語言預訓練模型作為統一backbone是最佳策略,理由:(1)mBERT、XLM-R等模型已在100+語言上預訓練,具備跨語言遷移能力,能共享知識;(2)只需維護一個模型,大幅降低維護成本;(3)可以利用跨語言資料增強,提升低資源語言效果;(4)部署架構統一,便於擴展到新語言。選項A維護成本高,需要4個獨立模型;選項C翻譯會引入額外錯誤和延遲;選項D規則型系統難以處理複雜對話,擴展性差。這是典型的系統整合實務題,需考量技術選型、成本、可維護性。",
      "keywords": [
        "多語言NLP",
        "跨語言模型",
        "mBERT",
        "XLM-R",
        "系統架構",
        "維護成本"
      ],
      "reference": "L21101-自然語言處理技術與應用.md - 多語言NLP系統設計"
    },
    {
      "question_id": "L21101_012",
      "sequence": 12,
      "topic": "L21101-自然語言處理技術與應用",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某金融機構要整合NLP系統到現有核心業務系統,用於自動分析客戶申訴郵件並分派至相關部門。系統需要7×24小時運作,平均每分鐘處理500封郵件。在系統整合時,以下哪個技術考量最為關鍵?",
      "options": {
        "A": "模型準確率必須達到99%以上",
        "B": "建立包含批次推理、非同步處理、負載均衡的分散式架構",
        "C": "使用最新的大型語言模型以確保最佳效果",
        "D": "將所有郵件即時處理,不使用佇列機制"
      },
      "answer": "B",
      "explanation": "在高吞吐量(500封/分鐘)、高可用性(7×24小時)的金融場景下,系統架構設計最為關鍵。應建立:(1)批次推理機制:將郵件打包批次處理,提升GPU利用率;(2)非同步處理:使用訊息佇列(如RabbitMQ、Kafka)解耦接收與處理,避免峰值時系統崩潰;(3)負載均衡:多個推理實例分散負載,確保高可用性;(4)容錯機制:失敗重試、降級策略。選項A過度追求準確率不切實際,金融場景通常需要人工複核;選項C大型模型推理延遲高,無法滿足吞吐量需求;選項D即時處理無法應對流量波動,系統脆弱。這是典型的系統整合實務題,需平衡效能、可靠性、成本。",
      "keywords": [
        "高吞吐量",
        "批次推理",
        "非同步處理",
        "負載均衡",
        "系統架構",
        "金融NLP"
      ],
      "reference": "L21101-自然語言處理技術與應用.md - NLP系統整合與部署"
    },
    {
      "question_id": "L21102_001",
      "sequence": 13,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在電腦視覺的四大核心任務中,以下哪個任務的目標是為圖像中的每個像素分配一個類別標籤?",
      "options": {
        "A": "圖像分類(Image Classification)",
        "B": "物件偵測(Object Detection)",
        "C": "語義分割(Semantic Segmentation)",
        "D": "實例分割(Instance Segmentation)"
      },
      "answer": "C",
      "explanation": "電腦視覺四大核心任務的目標各不相同:(1)圖像分類:為整張圖像分配一個類別標籤;(2)物件偵測:定位並分類圖像中的多個物件,輸出bounding box和類別;(3)語義分割:為每個像素分配類別標籤,實現像素級分類,但不區分同類別的不同實例;(4)實例分割:在語義分割基礎上,進一步區分同類別的不同實例物件。因此語義分割的核心特徵是像素級分類。",
      "keywords": ["電腦視覺四大任務", "語義分割", "像素級分類", "任務識別"],
      "reference": "L21102-電腦視覺技術與應用.md - 四大視覺任務對比"
    },
    {
      "question_id": "L21102_002",
      "sequence": 14,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在物件偵測任務中,IoU(Intersection over Union)指標用於衡量什麼?",
      "options": {
        "A": "模型的分類準確率",
        "B": "預測框與真實框的重疊程度",
        "C": "模型的推理速度",
        "D": "圖像的解析度"
      },
      "answer": "B",
      "explanation": "IoU(Intersection over Union,交併比)是物件偵測中用於衡量預測bounding box與ground truth bounding box重疊程度的指標。計算公式為:IoU = 交集面積 / 聯集面積 = Area(預測框∩真實框) / Area(預測框∪真實框)。IoU值介於0到1之間,值越大表示預測框與真實框越吻合。通常IoU>0.5視為正確偵測,IoU也用於NMS(Non-Maximum Suppression)去除重複檢測框。",
      "keywords": ["IoU", "交併比", "物件偵測", "評估指標", "Bounding Box"],
      "reference": "L21102-電腦視覺技術與應用.md - IoU計算原理"
    },
    {
      "question_id": "L21102_003",
      "sequence": 15,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "simple",
      "question_type": "technical_selection",
      "question": "某零售商店要建立商品自動結帳系統,需要識別購物籃中的商品類別並計算總價。這個應用場景最適合使用電腦視覺的哪個任務?",
      "options": {
        "A": "圖像分類",
        "B": "物件偵測",
        "C": "語義分割",
        "D": "圖像生成"
      },
      "answer": "B",
      "explanation": "商品自動結帳系統需要:(1)定位購物籃中的每個商品位置;(2)識別每個商品的類別;(3)統計商品數量。這是典型的物件偵測任務,因為需要同時處理多個商品物件的定位(bounding box)和分類。圖像分類只能判斷整張圖的類別,無法定位和計數;語義分割雖能做像素級分類但通常不用於此場景且計算成本高;圖像生成不適用於識別任務。物件偵測模型(如YOLO、Faster R-CNN)能輸出每個商品的位置和類別,滿足結帳系統需求。",
      "keywords": ["物件偵測", "商品識別", "零售應用", "任務選擇", "商業場景"],
      "reference": "L21102-電腦視覺技術與應用.md - 視覺任務應用場景"
    },
    {
      "question_id": "L21102_004",
      "sequence": 16,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在CNN(卷積神經網路)中,卷積層的主要作用是什麼?",
      "options": {
        "A": "減少模型參數量,防止過擬合",
        "B": "透過局部連接和權重共享提取圖像的空間特徵",
        "C": "將特徵圖展平為一維向量",
        "D": "對特徵圖進行下採樣"
      },
      "answer": "B",
      "explanation": "CNN卷積層的核心作用是透過局部連接(local connectivity)和權重共享(weight sharing)機制提取圖像的空間特徵。卷積核在圖像上滑動,每個位置進行相同的卷積運算,能夠捕捉局部模式(如邊緣、紋理)。權重共享使得卷積層具有平移不變性(translation invariance),同時大幅減少參數量。淺層卷積提取低級特徵(邊緣、角點),深層卷積提取高級語義特徵(物件部件、完整物件)。選項A是副作用而非主要作用;選項C是全連接層的功能;選項D是池化層的功能。",
      "keywords": [
        "CNN",
        "卷積層",
        "局部連接",
        "權重共享",
        "特徵提取",
        "平移不變性"
      ],
      "reference": "L21102-電腦視覺技術與應用.md - CNN基本原理"
    },
    {
      "question_id": "L21102_005",
      "sequence": 17,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "ResNet(殘差網路)引入的Skip Connection(跳躍連接)解決了深度神經網路的什麼問題?",
      "options": {
        "A": "過擬合問題",
        "B": "梯度消失/爆炸問題,使得訓練超深網路成為可能",
        "C": "模型推理速度慢的問題",
        "D": "記憶體不足的問題"
      },
      "answer": "B",
      "explanation": "ResNet的Skip Connection(殘差連接)透過將輸入直接加到輸出(H(x) = F(x) + x),解決了深度神經網路的梯度消失/爆炸問題。在反向傳播時,梯度可以透過skip connection直接傳遞到前面的層,不會因為多層相乘而消失或爆炸。這使得訓練超深網路(如ResNet-152、ResNet-200)成為可能,突破了傳統CNN的深度限制。ResNet在2015年ImageNet競賽中獲得冠軍,證明了「網路越深,效果越好」在有殘差連接的情況下成立。Skip connection並非為了解決過擬合、速度或記憶體問題。",
      "keywords": [
        "ResNet",
        "Skip Connection",
        "殘差學習",
        "梯度消失",
        "深度網路"
      ],
      "reference": "L21102-電腦視覺技術與應用.md - ResNet殘差網路"
    },
    {
      "question_id": "L21102_006",
      "sequence": 18,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某智慧城市專案需要在路口攝影機上部署車輛偵測系統,要求即時處理(30fps以上)且硬體資源有限(嵌入式裝置)。在YOLO和Faster R-CNN兩種物件偵測模型中,應優先選擇哪一個?",
      "options": {
        "A": "Faster R-CNN,因為準確率較高",
        "B": "YOLO,因為推理速度快且為單階段偵測",
        "C": "兩者效能相同,隨機選擇即可",
        "D": "都不適合,應使用語義分割模型"
      },
      "answer": "B",
      "explanation": "在即時處理(30fps)且硬體資源有限的場景下,應選擇YOLO。YOLO是單階段(one-stage)偵測器,將偵測視為回歸問題,一次性預測bounding box和類別,推理速度快(YOLOv5可達140fps);Faster R-CNN是兩階段(two-stage)偵測器,需先生成候選區域(RPN)再分類,雖然準確率稍高但速度較慢(~5-10fps)。在嵌入式裝置的資源限制下,YOLO更適合實時應用,且近年版本(如YOLOv8)在準確率上已接近Faster R-CNN。這是典型的根據業務需求(實時性、硬體限制)選擇技術方案的題目。",
      "keywords": [
        "YOLO",
        "Faster R-CNN",
        "物件偵測",
        "實時處理",
        "嵌入式部署",
        "模型選擇"
      ],
      "reference": "L21102-電腦視覺技術與應用.md - YOLO vs Faster R-CNN對比"
    },
    {
      "question_id": "L21102_007",
      "sequence": 19,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在語義分割任務中,常用的評估指標mIoU(mean Intersection over Union)是如何計算的?",
      "options": {
        "A": "所有像素的分類準確率",
        "B": "每個類別的IoU平均值",
        "C": "預測框與真實框的重疊面積",
        "D": "模型的F1 Score"
      },
      "answer": "B",
      "explanation": "mIoU(mean Intersection over Union)是語義分割的核心評估指標,計算方式為:(1)對每個類別c,計算其IoU_c = 交集 / 聯集 = TP_c / (TP_c + FP_c + FN_c),其中TP是該類別正確預測的像素數,FP是誤判為該類別的像素數,FN是該類別漏判的像素數;(2)將所有類別的IoU取平均:mIoU = (1/C) * Σ IoU_c,其中C是類別總數。mIoU同時考慮了每個類別的分割品質,比單純的像素準確率更能反映模型對所有類別(包括小物體、稀有類別)的分割能力。",
      "keywords": ["mIoU", "語義分割", "評估指標", "交併比", "像素級評估"],
      "reference": "L21102-電腦視覺技術與應用.md - 語義分割評估指標"
    },
    {
      "question_id": "L21102_008",
      "sequence": 20,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某醫療影像公司要開發肺部CT影像的病灶分割系統,需要精確標記出每個病灶的邊界。以下哪種模型架構最適合此任務?",
      "options": {
        "A": "VGG分類網路",
        "B": "YOLO物件偵測網路",
        "C": "U-Net語義分割網路",
        "D": "ResNet分類網路"
      },
      "answer": "C",
      "explanation": "醫療影像病灶分割需要精確的像素級標記,這是典型的語義分割/實例分割任務。U-Net是專為醫療影像分割設計的架構,具有以下優勢:(1)編碼器-解碼器結構:編碼器提取特徵,解碼器恢復空間解析度;(2)跳躍連接:將編碼器的高解析度特徵concat到解碼器,保留細節資訊,實現精確邊界分割;(3)少量資料即可訓練:適合醫療影像標註資料有限的情況。選項A、D的VGG和ResNet是分類網路,無法輸出分割結果;選項B的YOLO是物件偵測,只能輸出bounding box,無法做像素級精確分割。",
      "keywords": [
        "U-Net",
        "醫療影像",
        "語義分割",
        "病灶分割",
        "編碼器-解碼器",
        "模型選擇"
      ],
      "reference": "L21102-電腦視覺技術與應用.md - 語義分割模型架構"
    },
    {
      "question_id": "L21102_009",
      "sequence": 21,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在實例分割(Instance Segmentation)任務中,相較於語義分割(Semantic Segmentation),主要增加了什麼能力?",
      "options": {
        "A": "像素級分類能力",
        "B": "區分同類別不同實例的能力",
        "C": "物件偵測能力",
        "D": "圖像分類能力"
      },
      "answer": "B",
      "explanation": "實例分割與語義分割的核心差異在於是否區分同類別的不同實例。語義分割只為每個像素分配類別標籤,例如將圖中的所有「人」都標記為同一類別,無法區分是3個人還是5個人;實例分割則在語義分割基礎上,進一步區分同類別的不同實例物件,例如將圖中的5個人分別標記為person_1、person_2...person_5,每個實例有獨立的分割遮罩。代表模型如Mask R-CNN,在Faster R-CNN基礎上增加了mask分支,同時實現物件偵測和實例級分割。",
      "keywords": [
        "實例分割",
        "語義分割",
        "實例區分",
        "Mask R-CNN",
        "任務差異"
      ],
      "reference": "L21102-電腦視覺技術與應用.md - 實例分割vs語義分割"
    },
    {
      "question_id": "L21102_010",
      "sequence": 22,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "hard",
      "question_type": "technical_principles",
      "question": "假設一個卷積層的輸入特徵圖尺寸為32×32,使用3×3的卷積核,stride=1,padding=1,則輸出特徵圖的尺寸為何?",
      "options": {
        "A": "30×30",
        "B": "32×32",
        "C": "34×34",
        "D": "31×31"
      },
      "answer": "B",
      "explanation": "卷積層輸出尺寸計算公式為:Output_size = [(Input_size + 2×Padding - Kernel_size) / Stride] + 1。代入數值:Output_size = [(32 + 2×1 - 3) / 1] + 1 = [(32 + 2 - 3) / 1] + 1 = [31 / 1] + 1 = 31 + 1 = 32。因此輸出特徵圖尺寸為32×32,與輸入相同。這是因為padding=1配合3×3卷積核恰好補償了邊界損失,實現了「same padding」效果,常用於保持特徵圖尺寸不變的場景(如ResNet的殘差塊)。",
      "keywords": [
        "卷積層",
        "輸出維度計算",
        "Padding",
        "Stride",
        "Same Padding"
      ],
      "reference": "L21102-電腦視覺技術與應用.md - 卷積層輸出維度計算公式"
    },
    {
      "question_id": "L21102_011",
      "sequence": 23,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某工廠要部署PCB板缺陷檢測系統,需要在高速產線上(每秒5片PCB)進行即時檢測,並標記出微小缺陷(0.1mm級)的精確位置和類型。系統需整合到現有MES系統。在設計整合架構時,以下哪個方案最為合適?",
      "options": {
        "A": "使用雲端API進行推理,透過REST API與MES整合",
        "B": "部署輕量級YOLO模型在邊緣裝置,透過訊息佇列(MQTT)與MES非同步整合,並設置本地快取降低延遲",
        "C": "使用高精度Mask R-CNN在伺服器推理,透過同步HTTP調用與MES整合",
        "D": "使用傳統圖像處理算法(如邊緣檢測),不使用深度學習"
      },
      "answer": "B",
      "explanation": "PCB缺陷檢測系統整合需考量多個因素:(1)即時性:每秒5片要求低延遲(<200ms),雲端API網路延遲不可控;(2)精度:0.1mm微小缺陷需要高解析度模型,但也要平衡速度;(3)穩定性:產線不能因網路問題中斷;(4)整合性:與MES系統資料交換。方案B最佳:(a)邊緣部署避免網路延遲,確保即時性;(b)輕量級YOLO經過優化可滿足速度要求,必要時可用更高解析度輸入提升小物體檢測;(c)MQTT非同步通訊解耦系統,提升可靠性;(d)本地快取確保MES系統短暫離線時產線仍可運行。選項A延遲高且依賴網路;選項C同步調用會阻塞產線;選項D傳統算法難以應對複雜缺陷模式。",
      "keywords": [
        "工業視覺",
        "缺陷檢測",
        "邊緣部署",
        "MES整合",
        "MQTT",
        "系統架構",
        "即時性"
      ],
      "reference": "L21102-電腦視覺技術與應用.md - 工業視覺系統整合"
    },
    {
      "question_id": "L21102_012",
      "sequence": 24,
      "topic": "L21102-電腦視覺技術與應用",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某零售連鎖店要建立全店商品貨架監控系統,使用200個攝影機監控不同貨架,需要識別缺貨、擺放錯誤等情況。系統需要處理不同光照、視角、遮擋情況,並與庫存管理系統整合。在系統設計時,以下哪個技術組合最能確保系統的穩定性與可擴展性?",
      "options": {
        "A": "所有攝影機串流集中到單一GPU伺服器推理,直接寫入資料庫",
        "B": "採用分散式架構:邊緣裝置初步過濾+雲端精細分析,使用訊息佇列(Kafka)整合,資料湖儲存歷史影像,定期模型再訓練應對新商品和場景變化",
        "C": "每個攝影機獨立部署完整模型,各自連接資料庫",
        "D": "使用傳統模板匹配方法,不使用深度學習"
      },
      "answer": "B",
      "explanation": "大規模零售監控系統需要全面的系統整合設計,方案B最為完善:(1)分散式架構:200個攝影機的串流量巨大(假設720p@30fps約200Mbps/cam),集中處理會造成網路和計算瓶頸,邊緣-雲端協同架構可在邊緣過濾無變化畫面(節省90%+傳輸),只將疑似異常送雲端精細分析;(2)訊息佇列解耦:Kafka可處理高吞吐量事件流,實現檢測系統與庫存系統的非同步整合,避免相互影響;(3)資料湖儲存:保留歷史影像用於模型迭代和審計;(4)持續學習:零售環境動態變化(新商品、促銷陳列、季節性光照),需定期用新資料再訓練模型。選項A單點故障風險高,無法擴展;選項C資源浪費且難以統一管理;選項D模板匹配無法應對複雜場景變化。這是典型的大規模系統整合題,需考量架構、效能、可靠性、維運。",
      "keywords": [
        "大規模部署",
        "邊緣-雲端協同",
        "訊息佇列",
        "Kafka",
        "資料湖",
        "持續學習",
        "零售監控",
        "系統架構"
      ],
      "reference": "L21102-電腦視覺技術與應用.md - 大規模視覺系統整合架構"
    },
    {
      "question_id": "L21103_001",
      "sequence": 25,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在GAN(生成對抗網路)的訓練過程中,生成器(Generator)和判別器(Discriminator)的目標分別是什麼?",
      "options": {
        "A": "生成器希望欺騙判別器,判別器希望區分真假樣本",
        "B": "生成器希望協助判別器,判別器希望生成樣本",
        "C": "兩者目標相同,都是生成逼真樣本",
        "D": "兩者目標相同,都是分類樣本"
      },
      "answer": "A",
      "explanation": "GAN的核心是對抗訓練(adversarial training)機制,生成器G和判別器D進行零和博弈:(1)生成器G的目標是生成逼真的假樣本,欺騙判別器D使其判斷為真樣本(最小化D的判別能力);(2)判別器D的目標是區分真實樣本和生成樣本,正確判斷輸入是真是假(最大化判別準確率)。訓練過程交替更新G和D,最終達到納許均衡:生成器能生成與真實資料分布相同的樣本,判別器無法區分真假(輸出0.5)。這種對抗機制驅動了GAN的強大生成能力。",
      "keywords": [
        "GAN",
        "生成對抗網路",
        "對抗訓練",
        "生成器",
        "判別器",
        "零和博弈"
      ],
      "reference": "L21103-生成式AI技術與應用.md - GAN對抗訓練原理"
    },
    {
      "question_id": "L21103_002",
      "sequence": 26,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "VAE(變分自編碼器)相較於傳統自編碼器(Autoencoder),主要增加了什麼特性?",
      "options": {
        "A": "更快的訓練速度",
        "B": "更少的參數量",
        "C": "潛在空間(latent space)的連續性和可插值性,適合生成新樣本",
        "D": "更高的重建精度"
      },
      "answer": "C",
      "explanation": "VAE的核心創新是將潛在編碼建模為機率分布(通常是高斯分布),而非傳統自編碼器的確定性編碼。VAE編碼器輸出潛在分布的均值μ和方差σ²,再從N(μ,σ²)中採樣得到潛在向量z,解碼器從z重建輸入。這種機率性設計帶來兩個關鍵優勢:(1)潛在空間連續且結構化,相似樣本在潛在空間中接近;(2)可從潛在空間任意採樣生成新樣本,還可進行插值(interpolation)生成中間狀態樣本。VAE透過KL散度約束潛在分布接近標準正態分布,確保潛在空間的規整性。",
      "keywords": [
        "VAE",
        "變分自編碼器",
        "潛在空間",
        "機率建模",
        "KL散度",
        "可插值性"
      ],
      "reference": "L21103-生成式AI技術與應用.md - VAE原理與特性"
    },
    {
      "question_id": "L21103_003",
      "sequence": 27,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "Diffusion Models(擴散模型)的生成過程包含哪兩個主要階段?",
      "options": {
        "A": "編碼階段和解碼階段",
        "B": "前向擴散過程(加噪)和反向去噪過程(生成)",
        "C": "訓練階段和推理階段",
        "D": "特徵提取階段和分類階段"
      },
      "answer": "B",
      "explanation": "Diffusion Models的核心機制包含兩個階段:(1)前向擴散過程(forward diffusion):逐步向資料添加高斯噪聲,經過T步後將資料轉化為純噪聲,這是一個固定的馬可夫鏈過程;(2)反向去噪過程(reverse denoising):訓練神經網路學習逆向過程,從純噪聲開始逐步去噪,最終生成清晰樣本。生成時從標準高斯噪聲採樣,經過T步反向去噪得到生成樣本。Diffusion模型(如DALL-E 2、Stable Diffusion)因其穩定的訓練過程和高品質生成能力而廣受歡迎,但推理需要多步迭代,速度較GAN慢。",
      "keywords": [
        "Diffusion Models",
        "擴散模型",
        "前向擴散",
        "反向去噪",
        "去噪擴散",
        "DDPM"
      ],
      "reference": "L21103-生成式AI技術與應用.md - Diffusion Models原理"
    },
    {
      "question_id": "L21103_004",
      "sequence": 28,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "simple",
      "question_type": "technical_selection",
      "question": "某設計公司想使用生成式AI根據文字描述生成產品概念圖。以下哪種模型最適合此需求?",
      "options": {
        "A": "BERT文本分類模型",
        "B": "YOLO物件偵測模型",
        "C": "Stable Diffusion文生圖模型",
        "D": "ResNet圖像分類模型"
      },
      "answer": "C",
      "explanation": "根據文字描述生成圖像是典型的文生圖(text-to-image)任務,需要使用文本條件生成模型。Stable Diffusion是當前最流行的文生圖模型,結合了Diffusion模型的高品質生成能力和文本編碼器(CLIP)的語義理解能力,能根據文字提示(prompt)生成高解析度、高品質的圖像,非常適合產品概念圖、藝術創作等場景。選項A的BERT是文本理解模型,無法生成圖像;選項B的YOLO是物件偵測,不是生成模型;選項D的ResNet是分類模型,也不具備生成能力。其他文生圖模型如DALL-E 2、Midjourney也可考慮。",
      "keywords": [
        "文生圖",
        "Stable Diffusion",
        "生成式AI",
        "文本條件生成",
        "產品設計",
        "模型選擇"
      ],
      "reference": "L21103-生成式AI技術與應用.md - 文生圖模型應用"
    },
    {
      "question_id": "L21103_005",
      "sequence": 29,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在提示工程(Prompt Engineering)中,CIEC結構代表什麼?",
      "options": {
        "A": "Context, Input, Example, Command",
        "B": "Context, Instruction, Example, Constraint",
        "C": "Create, Implement, Execute, Check",
        "D": "Code, Instruction, Error, Correction"
      },
      "answer": "B",
      "explanation": "CIEC是有效提示工程的結構化框架,代表:(1)Context(上下文):提供背景資訊、角色設定,幫助模型理解任務情境;(2)Instruction(指令):明確說明要完成的任務和期望輸出格式;(3)Example(範例):提供few-shot examples示範期望的輸入輸出,引導模型行為;(4)Constraint(約束):定義限制條件、輸出長度、風格要求等。良好的提示應包含這四個元素,能顯著提升大型語言模型的輸出品質和穩定性。例如:'你是一位專業的產品經理(Context),請根據以下用戶回饋撰寫產品改進建議(Instruction),參考格式如下...(Example),建議控制在300字內並包含優先級(Constraint)'。",
      "keywords": [
        "提示工程",
        "Prompt Engineering",
        "CIEC結構",
        "Few-shot Learning",
        "大型語言模型"
      ],
      "reference": "L21103-生成式AI技術與應用.md - 提示工程CIEC結構"
    },
    {
      "question_id": "L21103_006",
      "sequence": 30,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "模型壓縮技術中,Pruning(剪枝)、Distillation(蒸餾)、Quantization(量化)三種方法的核心原理分別是什麼?",
      "options": {
        "A": "Pruning刪除不重要的權重/神經元,Distillation用小模型學習大模型知識,Quantization降低數值精度",
        "B": "三種方法原理相同,只是名稱不同",
        "C": "Pruning增加模型層數,Distillation合併模型,Quantization增加精度",
        "D": "Pruning用於加速訓練,Distillation用於加速推理,Quantization用於減少記憶體"
      },
      "answer": "A",
      "explanation": "三種模型壓縮技術的核心原理各不相同:(1)Pruning(剪枝):根據重要性指標(如權重絕對值、梯度)刪除不重要的權重連接或整個神經元/通道,減少模型參數量和計算量,分為非結構化剪枝(刪除單個權重)和結構化剪枝(刪除整個通道/層);(2)Distillation(知識蒸餾):訓練小模型(student)模仿大模型(teacher)的輸出分布(soft targets),將大模型的知識遷移到小模型,保持效能同時大幅減小模型尺寸;(3)Quantization(量化):將高精度浮點數(如FP32)轉換為低精度表示(如INT8、FP16),減少記憶體佔用和計算量,幾乎不損失精度。三種技術可組合使用達到更好的壓縮效果。",
      "keywords": [
        "模型壓縮",
        "Pruning",
        "Distillation",
        "Quantization",
        "剪枝",
        "知識蒸餾",
        "量化"
      ],
      "reference": "L21103-生成式AI技術與應用.md - 模型壓縮技術對比"
    },
    {
      "question_id": "L21103_007",
      "sequence": 31,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某遊戲公司要使用生成式AI為遊戲角色生成對話,需要保持角色個性一致且回應符合劇情。現有少量角色對話範例(約50條)。以下哪種方法最合適?",
      "options": {
        "A": "從零訓練一個大型語言模型",
        "B": "使用預訓練GPT模型,透過Few-shot Prompting提供角色範例和劇情上下文",
        "C": "使用BERT模型進行文本分類",
        "D": "使用規則型對話系統"
      },
      "answer": "B",
      "explanation": "在資料量少(僅50條對話)的情況下,使用預訓練GPT模型配合Few-shot Prompting是最合適的策略。具體做法:(1)在提示中提供角色設定(Context)如性格、背景;(2)給出幾個角色對話範例(Example)展示說話風格;(3)提供當前劇情上下文(Context);(4)明確要求保持角色一致性(Constraint)。GPT的few-shot learning能力能從少量範例中學習角色特質,生成符合個性的對話。選項A從零訓練需要大量資料和計算資源,不切實際;選項C的BERT是理解型模型,不適合生成任務;選項D規則型系統難以生成自然且多樣的對話。若預算充足,也可考慮用角色對話對GPT進行LoRA微調。",
      "keywords": [
        "Few-shot Learning",
        "角色對話生成",
        "GPT",
        "提示工程",
        "少量資料",
        "遊戲AI",
        "模型選擇"
      ],
      "reference": "L21103-生成式AI技術與應用.md - Few-shot Learning應用"
    },
    {
      "question_id": "L21103_008",
      "sequence": 32,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某企業要部署內部使用的文件摘要生成系統,處理機密文件。在選擇生成式AI方案時,以下哪個考量最為關鍵?",
      "options": {
        "A": "模型的生成速度",
        "B": "資料隱私與安全性,優先考慮本地部署或私有化部署方案",
        "C": "模型參數量越大越好",
        "D": "使用最新的公開API服務"
      },
      "answer": "B",
      "explanation": "處理機密文件時,資料隱私與安全性是最關鍵考量,必須避免機密資料外洩。應優先選擇:(1)本地部署方案:在企業內部伺服器部署開源模型(如Llama 2、Mistral),資料不出企業網路;(2)私有化部署:使用私有雲或專用實例,確保資料隔離;(3)避免使用公開API:如OpenAI、Claude API會將資料傳輸到第三方伺服器,雖然聲稱不用於訓練,但仍有資料外洩風險,不適合機密文件。即使本地部署的模型效果稍差,但對機密場景而言,安全性優先於效能。選項D使用公開API完全不可接受。這是典型的業務需求(安全合規)優先於技術指標的案例。",
      "keywords": [
        "資料隱私",
        "機密文件",
        "本地部署",
        "私有化部署",
        "安全合規",
        "生成式AI",
        "模型選擇"
      ],
      "reference": "L21103-生成式AI技術與應用.md - 生成式AI安全與隱私考量"
    },
    {
      "question_id": "L21103_009",
      "sequence": 33,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "hard",
      "question_type": "technical_principles",
      "question": "在AI供應鏈安全中,「供應鏈攻擊」(Supply Chain Attack)在生成式AI領域可能以什麼形式出現?",
      "options": {
        "A": "駭客直接攻擊模型訓練伺服器",
        "B": "惡意行為者在開源模型權重、預訓練模型或訓練資料中植入後門或毒化資料,導致下游使用者模型產生有害輸出",
        "C": "使用者輸入惡意提示導致模型輸出不當內容",
        "D": "模型訓練時過擬合"
      },
      "answer": "B",
      "explanation": "生成式AI的供應鏈攻擊是指攻擊者在AI供應鏈的上游環節(模型、資料、程式碼)植入惡意內容,影響下游使用者。具體形式包括:(1)後門植入:在預訓練模型權重中嵌入觸發器,當遇到特定輸入時產生惡意輸出;(2)資料毒化:在訓練資料中混入有害樣本,影響模型行為;(3)惡意套件:在開源模型庫(如Hugging Face)上傳包含惡意程式碼的模型檔案。由於生成式AI高度依賴預訓練模型和開源資源,供應鏈攻擊風險顯著。防禦措施包括:(a)驗證模型來源和完整性(checksum);(b)在隔離環境測試模型;(c)使用可信任的模型倉庫;(d)定期安全審計。選項C是提示注入攻擊,選項D是技術問題,都不屬於供應鏈攻擊。",
      "keywords": [
        "供應鏈攻擊",
        "模型後門",
        "資料毒化",
        "AI安全",
        "預訓練模型風險",
        "安全威脅"
      ],
      "reference": "L21103-生成式AI技術與應用.md - AI供應鏈攻擊與防禦"
    },
    {
      "question_id": "L21103_010",
      "sequence": 34,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某內容平台要整合生成式AI輔助創作者生成文章草稿,系統需要處理每日10萬次請求,確保內容品質並過濾有害內容。在設計整合架構時,以下哪個方案最為完善?",
      "options": {
        "A": "直接調用OpenAI API,不做額外處理",
        "B": "建立包含提示模板管理、輸入過濾、輸出檢測(內容安全)、快取層、降級策略的完整架構,使用API Gateway統一管理",
        "C": "在本地部署單一模型實例處理所有請求",
        "D": "使用開源模型但不做任何安全檢測"
      },
      "answer": "B",
      "explanation": "生產級生成式AI系統整合需要完整的架構設計,方案B最為完善:(1)提示模板管理:預定義高品質提示模板,確保輸出一致性和品質,版本化管理方便迭代;(2)輸入過濾:檢測並拒絕惡意提示(如prompt injection、jailbreak嘗試);(3)輸出檢測:使用內容安全模型(如OpenAI Moderation API)過濾有害、不當、侵權內容,保護平台;(4)快取層:對常見請求使用Redis快取,減少API調用成本和延遲(快取命中率可達30-50%);(5)降級策略:當主模型不可用時切換到備用模型或返回預設內容;(6)API Gateway:統一入口進行限流、認證、監控、日誌記錄。選項A沒有安全保障和成本優化;選項C單實例無法處理10萬次請求;選項D存在重大安全風險。這是典型的系統整合實務題,需考量安全、效能、成本、可靠性。",
      "keywords": [
        "生成式AI整合",
        "內容安全",
        "提示管理",
        "快取策略",
        "API Gateway",
        "系統架構",
        "降級策略"
      ],
      "reference": "L21103-生成式AI技術與應用.md - 生成式AI系統整合最佳實踐"
    },
    {
      "question_id": "L21103_011",
      "sequence": 35,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某教育科技公司要整合GPT模型建立個性化學習助教系統,需要結合學生歷史學習記錄、知識圖譜、課程內容生成個性化學習建議。系統需要支援100萬學生同時使用,並確保回應延遲<3秒。在設計整合架構時,最關鍵的技術挑戰是什麼?",
      "options": {
        "A": "選擇最大參數量的GPT模型",
        "B": "設計高效的上下文構建策略(從知識圖譜、學習記錄中檢索相關資訊)、快取熱門查詢、實現非同步處理與負載均衡",
        "C": "使用最貴的GPU伺服器",
        "D": "完全從零訓練專用模型"
      },
      "answer": "B",
      "explanation": "個性化學習助教系統的整合核心挑戰在於如何高效結合多源資料生成個性化回應,同時滿足大規模並發和低延遲要求。關鍵技術策略:(1)高效上下文構建:從海量學習記錄和知識圖譜中快速檢索相關資訊(使用向量資料庫如Pinecone、Milvus進行語義搜索),構建精簡有效的上下文,避免token浪費;(2)RAG架構(Retrieval-Augmented Generation):結合檢索系統和生成模型,確保回答基於學生實際情況和課程內容;(3)智慧快取:快取常見問題和熱門主題的回應,減少重複計算;(4)非同步處理:使用訊息佇列處理非即時任務(如學習報告生成),即時任務優先;(5)負載均衡:多個模型實例分散請求,確保<3秒延遲。選項A大模型推理慢,無法滿足延遲要求;選項C硬體不能解決架構問題;選項D從零訓練成本極高且不必要。這是複雜的系統整合題,需平衡效能、成本、個性化效果。",
      "keywords": [
        "RAG",
        "個性化學習",
        "上下文構建",
        "向量檢索",
        "知識圖譜",
        "大規模並發",
        "系統整合",
        "GPT應用"
      ],
      "reference": "L21103-生成式AI技術與應用.md - RAG架構與個性化應用整合"
    },
    {
      "question_id": "L21103_012",
      "sequence": 36,
      "topic": "L21103-生成式AI技術與應用",
      "difficulty": "hard",
      "question_type": "technical_principles",
      "question": "在模型壓縮的Quantization(量化)技術中,Post-Training Quantization(PTQ)和Quantization-Aware Training(QAT)的主要差異為何?",
      "options": {
        "A": "兩者完全相同,只是名稱不同",
        "B": "PTQ在訓練後直接量化權重,速度快但可能損失精度;QAT在訓練過程中模擬量化,精度損失更小但需要重新訓練",
        "C": "PTQ用於大模型,QAT用於小模型",
        "D": "PTQ只能量化到FP16,QAT可量化到INT8"
      },
      "answer": "B",
      "explanation": "量化技術的兩種主流方法各有優劣:(1)PTQ(Post-Training Quantization,訓練後量化):在模型訓練完成後直接將權重和激活值從FP32轉換為INT8或其他低精度格式,無需重新訓練,速度快、成本低,但對某些模型可能造成較大精度損失(通常<2%);(2)QAT(Quantization-Aware Training,量化感知訓練):在訓練過程中模擬量化操作(前向傳播使用量化值,反向傳播仍用全精度),讓模型權重適應量化誤差,訓練得到的模型量化後精度損失極小(<0.5%),但需要訓練資料和計算資源,耗時較長。實務上,對精度敏感的應用(如醫療、金融)使用QAT,對速度和成本敏感的應用使用PTQ。兩者都可量化到INT8甚至INT4。",
      "keywords": [
        "量化",
        "PTQ",
        "QAT",
        "訓練後量化",
        "量化感知訓練",
        "模型壓縮",
        "精度vs成本"
      ],
      "reference": "L21103-生成式AI技術與應用.md - 量化技術PTQ vs QAT"
    },
    {
      "question_id": "L21104_001",
      "sequence": 37,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在多模態融合策略中,Early Fusion(早期融合)和Late Fusion(晚期融合)的主要差異為何?",
      "options": {
        "A": "Early Fusion在特徵級融合,Late Fusion在決策級融合",
        "B": "Early Fusion在決策級融合,Late Fusion在特徵級融合",
        "C": "兩者融合時機相同,只是名稱不同",
        "D": "Early Fusion只用於圖像,Late Fusion只用於文本"
      },
      "answer": "A",
      "explanation": "多模態融合的兩種主流策略:(1)Early Fusion(早期融合/特徵級融合):在特徵提取的早期階段就將不同模態的特徵concat或相加,讓模型從頭學習跨模態交互,能捕捉更深層的模態間關聯,但對資料品質要求高,一個模態的噪聲會影響整體效果;(2)Late Fusion(晚期融合/決策級融合):各模態獨立處理到最後,在決策階段(如分類層)才融合各模態的輸出(如加權平均、投票),實現簡單,各模態相對獨立,但無法學習深層的跨模態交互。實務上也常用Hybrid Fusion(混合融合)結合兩者優勢。",
      "keywords": [
        "多模態融合",
        "Early Fusion",
        "Late Fusion",
        "特徵級融合",
        "決策級融合",
        "融合策略"
      ],
      "reference": "L21104-多模態人工智慧應用.md - Early Fusion vs Late Fusion"
    },
    {
      "question_id": "L21104_002",
      "sequence": 38,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "CLIP(Contrastive Language-Image Pre-training)模型的核心訓練目標是什麼?",
      "options": {
        "A": "將圖像分類到預定義的類別",
        "B": "透過對比學習讓匹配的圖文對在嵌入空間中距離接近,不匹配的圖文對距離遠離",
        "C": "從圖像生成文字描述",
        "D": "從文字生成圖像"
      },
      "answer": "B",
      "explanation": "CLIP的核心創新是透過對比學習(contrastive learning)在大規模圖文配對資料上進行預訓練。訓練目標:給定一個批次的N個圖文配對,CLIP同時訓練圖像編碼器和文本編碼器,使得:(1)匹配的圖文對在嵌入空間中的相似度最大化(餘弦相似度接近1);(2)不匹配的圖文對相似度最小化(接近0)。透過這種對比學習,CLIP學習到對齊的視覺-語言表示,實現零樣本圖像分類(給定文字描述即可分類)、圖文檢索等任務。CLIP不是生成模型,不做圖像生成或描述生成。",
      "keywords": [
        "CLIP",
        "對比學習",
        "圖文對齊",
        "零樣本學習",
        "多模態預訓練",
        "視覺-語言模型"
      ],
      "reference": "L21104-多模態人工智慧應用.md - CLIP對比學習原理"
    },
    {
      "question_id": "L21104_003",
      "sequence": 39,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "simple",
      "question_type": "technical_selection",
      "question": "某影音平台要建立影片內容理解系統,需要同時分析影片的視覺內容、語音、字幕來進行影片分類和推薦。這屬於多模態AI的哪種應用場景?",
      "options": {
        "A": "單模態應用",
        "B": "多模態融合應用(視覺+聲音+文本)",
        "C": "僅圖像處理應用",
        "D": "僅語音處理應用"
      },
      "answer": "B",
      "explanation": "影片內容理解涉及三種模態的融合:(1)視覺模態:影片畫面的物件、場景、人物、動作等;(2)聲音模態:背景音樂、音效、語音語調等;(3)文本模態:字幕、旁白的語義資訊。這是典型的多模態融合應用,需要結合三種模態的互補資訊才能全面理解影片內容。例如,恐怖片可能有陰暗的視覺(視覺模態)、緊張的配樂(聲音模態)、驚悚的對白(文本模態)。實務上可使用CNN提取視覺特徵、音訊編碼器提取聲音特徵、BERT提取文本特徵,再透過Transformer或注意力機制進行多模態融合,進行分類或生成推薦。",
      "keywords": [
        "多模態融合",
        "影片理解",
        "視覺+聲音+文本",
        "內容推薦",
        "應用場景"
      ],
      "reference": "L21104-多模態人工智慧應用.md - 多模態應用場景"
    },
    {
      "question_id": "L21104_004",
      "sequence": 40,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在多模態模型中,Cross-Attention(交叉注意力)機制的作用是什麼?",
      "options": {
        "A": "讓模型只關注單一模態內部的資訊",
        "B": "讓一個模態的表示去查詢(attend to)另一個模態的資訊,實現跨模態交互",
        "C": "減少模型參數量",
        "D": "加快模型訓練速度"
      },
      "answer": "B",
      "explanation": "Cross-Attention(交叉注意力)是多模態模型中實現跨模態交互的核心機制。在標準的Self-Attention中,Query、Key、Value都來自同一輸入;而在Cross-Attention中,Query來自一個模態(如文本),Key和Value來自另一個模態(如圖像),讓文本表示能夠「查詢」圖像中的相關資訊。例如,在圖像描述生成任務中,解碼器生成文字時,透過Cross-Attention讓當前要生成的詞(Query)去關注圖像的不同區域(Key、Value),提取相關視覺資訊。Cross-Attention是Vision Transformer、多模態預訓練模型(如LXMERT、VisualBERT)的核心組件,實現了模態間的資訊交互和對齊。",
      "keywords": [
        "Cross-Attention",
        "交叉注意力",
        "跨模態交互",
        "多模態融合",
        "注意力機制",
        "模態對齊"
      ],
      "reference": "L21104-多模態人工智慧應用.md - Cross-Attention機制"
    },
    {
      "question_id": "L21104_005",
      "sequence": 41,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某電商平台要建立以圖搜圖功能,用戶上傳商品圖片即可搜尋相似商品。同時需要支援用文字描述搜尋圖片(如「紅色洋裝」)。以下哪種技術方案最適合?",
      "options": {
        "A": "使用傳統圖像特徵提取(如SIFT)進行圖像檢索",
        "B": "使用CLIP模型建立統一的圖文嵌入空間,支援圖搜圖和文搜圖",
        "C": "分別建立圖像檢索系統和文本檢索系統,兩者獨立運作",
        "D": "使用YOLO物件偵測進行搜尋"
      },
      "answer": "B",
      "explanation": "CLIP模型最適合此多模態檢索場景,理由:(1)統一嵌入空間:CLIP將圖像和文本映射到同一語義空間,圖像向量和文本向量可直接計算相似度;(2)圖搜圖:將用戶上傳的查詢圖片編碼為向量,在商品圖片向量庫中檢索最近鄰(使用向量資料庫如Faiss、Milvus);(3)文搜圖:將文字描述編碼為向量,在同一圖片向量庫中檢索,無需另建系統;(4)零樣本能力:無需針對特定商品類別訓練,能泛化到新商品。實務架構:CLIP編碼器+向量資料庫+相似度檢索。選項A無法處理文字搜尋且語義理解弱;選項C維護兩套系統成本高且無法跨模態;選項D的YOLO是偵測模型,不適合檢索任務。",
      "keywords": [
        "CLIP",
        "圖文檢索",
        "以圖搜圖",
        "跨模態檢索",
        "向量資料庫",
        "電商應用",
        "模型選擇"
      ],
      "reference": "L21104-多模態人工智慧應用.md - CLIP跨模態檢索應用"
    },
    {
      "question_id": "L21104_006",
      "sequence": 42,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在Early Fusion和Late Fusion的選擇中,如果兩個模態的資料品質差異很大(例如圖像清晰但音訊雜訊嚴重),應該優先考慮哪種融合策略?",
      "options": {
        "A": "Early Fusion,因為能更早發現問題",
        "B": "Late Fusion,因為各模態獨立處理,低品質模態的影響可以透過權重調整降低",
        "C": "兩者效果相同",
        "D": "完全不使用音訊模態"
      },
      "answer": "B",
      "explanation": "當模態資料品質差異大時,Late Fusion更為穩健,理由:(1)模態隔離:各模態獨立處理,低品質模態(雜訊音訊)的錯誤不會在早期階段污染高品質模態(清晰圖像)的特徵;(2)權重調整:在決策融合階段可以根據各模態的置信度動態調整權重,降低低品質模態的影響(如圖像0.8權重,音訊0.2權重);(3)容錯性:即使音訊完全失效,系統仍可依靠圖像模態運作。Early Fusion在特徵級融合,低品質模態的噪聲會影響整個融合特徵,難以隔離。選項D完全捨棄音訊過於極端,音訊在某些情況下仍有價值。實務上可採用Hybrid Fusion,結合兩者優勢。",
      "keywords": [
        "Late Fusion",
        "資料品質",
        "模態權重",
        "融合策略選擇",
        "容錯性",
        "多模態魯棒性"
      ],
      "reference": "L21104-多模態人工智慧應用.md - 融合策略選擇考量"
    },
    {
      "question_id": "L21104_007",
      "sequence": 43,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某智慧助理要實現「看圖說話」功能,根據圖像生成自然語言描述。這個任務涉及哪些關鍵技術組件?",
      "options": {
        "A": "僅需要圖像分類模型",
        "B": "需要圖像編碼器(如CNN/ViT)提取視覺特徵,加上文本解碼器(如LSTM/Transformer)生成描述,並透過Cross-Attention實現視覺-語言對齊",
        "C": "僅需要文本生成模型",
        "D": "使用物件偵測即可"
      },
      "answer": "B",
      "explanation": "圖像描述生成(Image Captioning)是典型的視覺-語言生成任務,需要完整的編碼器-解碼器架構:(1)圖像編碼器:使用CNN(如ResNet)或Vision Transformer提取圖像的視覺特徵,得到圖像表示;(2)文本解碼器:使用LSTM或Transformer Decoder逐詞生成描述文字;(3)Cross-Attention:解碼器生成每個詞時,透過Cross-Attention機制關注圖像的相關區域,例如生成「紅色」時關注紅色物體,生成「跑步」時關注人物動作,實現視覺-語言對齊;(4)訓練:使用圖文配對資料,最大化描述文字的條件機率P(描述|圖像)。代表模型如Show and Tell、Show, Attend and Tell、Oscar。選項A只能分類無法生成;選項C無法理解圖像;選項D只能偵測物件無法生成流暢描述。",
      "keywords": [
        "圖像描述生成",
        "Image Captioning",
        "編碼器-解碼器",
        "Cross-Attention",
        "視覺-語言生成",
        "多模態生成"
      ],
      "reference": "L21104-多模態人工智慧應用.md - 圖像描述生成架構"
    },
    {
      "question_id": "L21104_008",
      "sequence": 44,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "多模態預訓練模型(如LXMERT、VisualBERT)相較於單模態預訓練模型(如BERT、ResNet),主要增加了什麼預訓練任務?",
      "options": {
        "A": "僅使用單模態的預訓練任務",
        "B": "增加了跨模態匹配、跨模態對齊等預訓練任務,讓模型學習視覺-語言之間的關聯",
        "C": "完全不使用預訓練",
        "D": "只增加圖像分類任務"
      },
      "answer": "B",
      "explanation": "多模態預訓練模型在單模態預訓練(如BERT的MLM、NSP)基礎上,增加了跨模態預訓練任務來學習視覺-語言關聯:(1)Image-Text Matching(ITM,圖文匹配):判斷給定的圖文對是否匹配,學習跨模態語義對齊;(2)Masked Language Modeling with Vision(視覺輔助的MLM):遮蔽文本中的詞,要求模型根據圖像和上下文預測,學習視覺資訊如何幫助語言理解;(3)Masked Region Modeling(MRM,區域遮蔽):遮蔽圖像的某些區域,根據文本和其他區域預測,學習文本資訊如何幫助視覺理解;(4)Visual Question Answering(VQA):根據圖像回答問題。這些跨模態任務讓模型學習到對齊的視覺-語言表示,可遷移到下游多模態任務(如VQA、圖像檢索、視覺推理)。",
      "keywords": [
        "多模態預訓練",
        "ITM",
        "跨模態對齊",
        "LXMERT",
        "VisualBERT",
        "視覺-語言模型",
        "預訓練任務"
      ],
      "reference": "L21104-多模態人工智慧應用.md - 多模態預訓練模型"
    },
    {
      "question_id": "L21104_009",
      "sequence": 45,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "hard",
      "question_type": "technical_principles",
      "question": "在使用Cross-Attention機制實現視覺-語言融合時,假設文本序列長度為L,圖像特徵有N個區域,則Cross-Attention的計算複雜度為何?",
      "options": {
        "A": "O(L)",
        "B": "O(N)",
        "C": "O(L × N)",
        "D": "O(L²)"
      },
      "answer": "C",
      "explanation": "Cross-Attention的計算複雜度分析:假設文本序列長度為L,圖像有N個區域特徵。在Cross-Attention中,文本的每個位置(L個Query)都要與圖像的所有區域(N個Key)計算注意力分數,因此需要計算L×N個注意力分數,再與N個Value加權求和。總計算複雜度為O(L × N)。例如,文本20個詞(L=20),圖像分為49個區域(7×7的特徵圖,N=49),則需計算20×49=980個注意力分數。相較之下,Self-Attention的複雜度為O(L²)或O(N²)。在多模態模型中,若L和N都很大,Cross-Attention的計算成本會顯著增加,因此需要優化策略如稀疏注意力、低秩近似等。",
      "keywords": [
        "Cross-Attention",
        "計算複雜度",
        "注意力機制",
        "視覺-語言融合",
        "效能優化"
      ],
      "reference": "L21104-多模態人工智慧應用.md - Cross-Attention計算複雜度"
    },
    {
      "question_id": "L21104_010",
      "sequence": 46,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某醫療診斷系統要整合多模態資料(CT影像、病理報告文字、基因檢測資料、病患病歷)進行疾病風險評估。系統需要處理不同來源、不同格式的醫療資料,並符合HIPAA隱私法規。在設計系統整合架構時,以下哪些考量最為關鍵?",
      "options": {
        "A": "僅考慮模型準確率,其他因素不重要",
        "B": "需設計包含資料標準化(FHIR)、多模態對齊、隱私保護(去識別化、聯邦學習)、可解釋性(注意力視覺化)、臨床驗證流程的完整架構",
        "C": "使用最大的多模態模型即可",
        "D": "只處理影像資料,忽略其他模態"
      },
      "answer": "B",
      "explanation": "醫療多模態系統整合是極其複雜的工程,需要全面考量:(1)資料標準化:醫療資料來自不同系統(PACS、EMR、實驗室),需使用FHIR等標準進行資料整合和互操作;(2)多模態對齊:CT影像、病理報告、基因資料的時間戳和病患ID需精確對齊,處理缺失模態的情況(並非每個病患都有完整資料);(3)隱私保護:符合HIPAA/GDPR,對資料去識別化,考慮使用聯邦學習在不共享原始資料的情況下訓練模型;(4)可解釋性:醫療決策需要可解釋,使用注意力視覺化、SHAP等方法解釋模型為何做出某診斷,讓醫師信任和驗證;(5)臨床驗證:與醫療專家合作進行回顧性和前瞻性臨床驗證,評估實際臨床價值;(6)模態缺失處理:設計魯棒的融合策略,即使某些模態缺失仍能運作。選項A忽略合規和可解釋性,醫療場景不可接受;選項C大模型不一定適合醫療特定任務;選項D丟失其他模態的關鍵資訊。這是高難度的系統整合實務題,需平衡技術、法規、臨床需求。",
      "keywords": [
        "醫療多模態",
        "FHIR",
        "HIPAA",
        "隱私保護",
        "聯邦學習",
        "可解釋性",
        "臨床驗證",
        "系統整合",
        "模態對齊"
      ],
      "reference": "L21104-多模態人工智慧應用.md - 醫療多模態系統整合"
    },
    {
      "question_id": "L21104_011",
      "sequence": 47,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某自動駕駛系統整合多個感測器(攝影機、光達LiDAR、毫米波雷達、GPS、IMU)進行環境感知和決策。系統需要即時處理(100ms內)並保證安全。在設計感測器融合架構時,應該優先選擇Early Fusion還是Late Fusion?",
      "options": {
        "A": "純Early Fusion,因為能學習最深層的跨模態關聯",
        "B": "純Late Fusion,因為各感測器獨立處理更簡單",
        "C": "Hybrid Fusion:關鍵任務(如障礙物偵測)使用Early Fusion深度整合攝影機和LiDAR,輔助任務使用Late Fusion,並設計感測器降級策略確保單一感測器失效時系統仍可運作",
        "D": "不使用融合,單獨使用攝影機即可"
      },
      "answer": "C",
      "explanation": "自動駕駛感測器融合是安全關鍵系統,需要精密設計:(1)Hybrid Fusion策略:關鍵感知任務(如前方障礙物偵測、行人偵測)使用Early Fusion深度整合攝影機(提供顏色、紋理、語義)和LiDAR(提供精確深度、3D結構),在特徵級融合能更準確判斷障礙物的位置、速度、類型;輔助任務(如車道保持)可使用Late Fusion減少計算;(2)感測器冗餘與降級:當某個感測器失效(如雨天攝影機視線受阻),系統能自動降級到依賴LiDAR和毫米波雷達,確保基本功能;(3)即時性優化:使用邊緣計算晶片(如NVIDIA Drive)並行處理多感測器資料,在100ms內完成感知-決策-控制循環;(4)時間同步:精確同步各感測器資料(攝影機30fps、LiDAR10fps、雷達100Hz),使用時間戳對齊;(5)不確定性量化:各模態輸出包含置信度,融合時根據環境條件動態調整權重(如霧天降低攝影機權重)。純Early Fusion缺乏容錯性,純Late Fusion無法深度融合,選項D單一感測器完全不符合安全要求。這是極高難度的系統整合題,需考量安全、即時性、冗餘、環境適應性。",
      "keywords": [
        "自動駕駛",
        "感測器融合",
        "Hybrid Fusion",
        "攝影機+LiDAR",
        "安全關鍵系統",
        "降級策略",
        "即時處理",
        "冗餘設計"
      ],
      "reference": "L21104-多模態人工智慧應用.md - 自動駕駛多感測器融合架構"
    },
    {
      "question_id": "L21104_012",
      "sequence": 48,
      "topic": "L21104-多模態人工智慧應用",
      "difficulty": "hard",
      "question_type": "technical_principles",
      "question": "在多模態預訓練模型的Image-Text Matching(ITM)任務中,常使用Hard Negative Mining策略。這個策略的目的是什麼?",
      "options": {
        "A": "隨機選擇負樣本即可",
        "B": "選擇與正樣本語義相似但不匹配的困難負樣本(如同一場景的不同描述),提升模型的細粒度區分能力",
        "C": "只使用正樣本訓練",
        "D": "增加訓練資料量"
      },
      "answer": "B",
      "explanation": "Hard Negative Mining是提升對比學習效果的關鍵策略,在ITM任務中的作用:(1)問題背景:隨機負樣本(如「貓的圖片」配對「汽車的描述」)太容易區分,模型學不到細粒度特徵;(2)Hard Negative定義:選擇與正樣本語義相似但實際不匹配的負樣本,例如正樣本是「一隻黃色拉布拉多在草地上跑」,hard negative可能是「一隻金毛獵犬在公園散步」(同樣是狗、戶外場景,但品種和動作不同);(3)訓練效果:Hard negatives迫使模型學習更細粒度的視覺-語言對齊(區分拉布拉多vs金毛、跑vs散步),而不是粗粒度的類別區分(狗vs汽車);(4)實現方法:在同一批次內選擇與當前圖像最相似但不匹配的文本作為hard negative,或使用批次內其他樣本的描述(in-batch negatives)。Hard Negative Mining顯著提升CLIP、ALIGN等模型的零樣本能力和檢索精度。",
      "keywords": [
        "Hard Negative Mining",
        "對比學習",
        "ITM",
        "細粒度對齊",
        "多模態預訓練",
        "負樣本選擇"
      ],
      "reference": "L21104-多模態人工智慧應用.md - Hard Negative Mining策略"
    },
    {
      "question_id": "L21201_001",
      "sequence": 49,
      "topic": "L21201-AI導入評估",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在AI專案的成本效益分析中,ROI(投資報酬率)的計算公式為何?",
      "options": {
        "A": "ROI = 投資成本 / 投資回報",
        "B": "ROI = (投資回報 - 投資成本) / 投資成本",
        "C": "ROI = 投資回報 + 投資成本",
        "D": "ROI = 投資成本 - 投資回報"
      },
      "answer": "B",
      "explanation": "ROI(Return on Investment,投資報酬率)的標準計算公式為:ROI = (投資回報 - 投資成本) / 投資成本 × 100%。這個公式衡量每投入1元能獲得多少回報。例如,投入100萬,回報150萬,則ROI = (150-100)/100 = 50%。ROI是評估AI專案經濟價值的基礎指標,通常ROI > 50%(1年內)視為高價值專案,ROI > 100%(2年內)為中價值專案。需注意ROI不考慮資金時間價值,長期專案應搭配NPV評估。",
      "keywords": ["ROI", "投資報酬率", "成本效益分析", "財務指標", "專案評估"],
      "reference": "L21201-AI導入評估.md - ROI計算公式"
    },
    {
      "question_id": "L21201_002",
      "sequence": 50,
      "topic": "L21201-AI導入評估",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在風險評估矩陣中,風險分數的計算方式為何?",
      "options": {
        "A": "風險分數 = 機率 + 影響",
        "B": "風險分數 = 機率 × 影響",
        "C": "風險分數 = 機率 - 影響",
        "D": "風險分數 = 機率 / 影響"
      },
      "answer": "B",
      "explanation": "風險評估矩陣的標準計算公式為:風險分數 = 機率(Probability) × 影響(Impact)。機率和影響通常各分為1-5級,風險分數範圍為1-25分。例如,某風險發生機率為4(高,50-70%),影響為5(災難,專案失敗),則風險分數 = 4×5 = 20(極高風險)。風險分級:1-5分為低風險(接受),6-12分為中風險(監控),13-20分為高風險(強化緩解),21-25分為極高風險(考慮終止)。這種乘法關係反映了風險的綜合嚴重程度。",
      "keywords": ["風險評估", "風險矩陣", "機率×影響", "風險分數", "專案管理"],
      "reference": "L21201-AI導入評估.md - 風險評估矩陣公式"
    },
    {
      "question_id": "L21201_003",
      "sequence": 51,
      "topic": "L21201-AI導入評估",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "NPV(淨現值)計算中的折現率(Discount Rate)通常代表什麼?",
      "options": {
        "A": "銀行存款利率",
        "B": "企業加權平均資本成本(WACC)",
        "C": "通貨膨脹率",
        "D": "專案的預期利潤率"
      },
      "answer": "B",
      "explanation": "NPV計算中的折現率通常使用企業加權平均資本成本(WACC, Weighted Average Cost of Capital)。WACC反映企業從債務和股權融資的綜合成本,代表企業的資金機會成本。使用WACC作為折現率,可以將未來現金流折現到現值,評估專案是否創造超過資本成本的價值。NPV計算公式:NPV = Σ[現金流t / (1+r)^t] - 初始投資,其中r為WACC。NPV > 0表示專案創造價值,建議執行;NPV < 0表示專案價值低於資本成本,不建議執行。",
      "keywords": ["NPV", "淨現值", "折現率", "WACC", "資本成本", "財務評估"],
      "reference": "L21201-AI導入評估.md - NPV折現率"
    },
    {
      "question_id": "L21201_004",
      "sequence": 52,
      "topic": "L21201-AI導入評估",
      "difficulty": "simple",
      "question_type": "technical_selection",
      "question": "某零售公司考慮導入AI需求預測系統,預計初期投資300萬元,每年可節省庫存成本120萬元。請問投資回收期為多久?",
      "options": {
        "A": "1年",
        "B": "2年",
        "C": "2.5年",
        "D": "3年"
      },
      "answer": "C",
      "explanation": "回收期(Payback Period)的計算公式為:回收期 = 初期投資 / 年度淨收益。在此案例中:回收期 = 300萬 / 120萬 = 2.5年。這表示需要2年半才能回收初期投資。回收期是評估專案風險的簡單指標,一般標準:<1年為極佳,1-2年為優良,2-3年為可接受,>3年需謹慎評估。回收期2.5年處於可接受範圍,但需進一步評估技術可行性和風險。需注意回收期僅考慮回本時間,不反映回收期後的持續收益,因此應搭配ROI或NPV進行綜合評估。",
      "keywords": [
        "回收期",
        "Payback Period",
        "投資評估",
        "財務分析",
        "零售應用"
      ],
      "reference": "L21201-AI導入評估.md - 回收期計算"
    },
    {
      "question_id": "L21201_005",
      "sequence": 53,
      "topic": "L21201-AI導入評估",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在AI導入評估的五大核心概念中,「組織準備度(Organizational Readiness)」主要評估什麼?",
      "options": {
        "A": "伺服器硬體是否充足",
        "B": "組織文化、人才結構、流程配合度、變革管理能力",
        "C": "AI模型的準確率是否達標",
        "D": "競爭對手是否使用AI"
      },
      "answer": "B",
      "explanation": "組織準備度(Organizational Readiness)評估企業在文化、人才、流程、變革管理等軟實力面向是否ready for AI,包括:(1)組織文化:是否擁抱創新、接受變革、容忍失敗;(2)人才結構:是否具備AI開發、維運、應用人才,或培養能力;(3)流程配合度:現有業務流程是否能配合AI系統調整;(4)變革管理:是否有計畫處理員工抗拒、角色轉變、技能升級。即使技術完美,組織不ready也會導致專案失敗。硬體屬於技術可行性評估,模型準確率屬於執行階段指標,競爭對手分析屬於市場環境評估。",
      "keywords": ["組織準備度", "變革管理", "AI導入", "人才能力", "組織文化"],
      "reference": "L21201-AI導入評估.md - 組織準備度評估"
    },
    {
      "question_id": "L21201_006",
      "sequence": 54,
      "topic": "L21201-AI導入評估",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某製造業要評估導入AI視覺檢測系統,現有10萬張瑕疵影像資料,但缺失值比例達15%,標註不一致的比例約10%。在技術可行性評估中,應優先採取什麼行動?",
      "options": {
        "A": "直接開始訓練模型,資料問題可以後續處理",
        "B": "進行資料品質評估與清理,必要時進行PoC驗證資料是否足以支撐目標準確度",
        "C": "放棄此專案,資料品質不佳無法進行",
        "D": "立即採購更多資料"
      },
      "answer": "B",
      "explanation": "面對資料品質問題,應系統性評估與改善而非極端處理。正確做法:(1)資料品質評估:從完整性(缺失15%)、準確性(標註不一致10%)、一致性、及時性四維度評分,量化資料就緒度;(2)資料清理計畫:處理缺失值(刪除或插補)、重新標註不一致樣本;(3)PoC驗證:用清理後的資料訓練模型,驗證能否達到業務要求的準確度(如99%),評估實際可行性;(4)成本估算:將資料工程成本納入專案預算。選項A會導致模型品質低下;選項C過於保守,15%缺失和10%標註問題可透過資料工程改善;選項D在未評估前盲目採購浪費資源。這是典型的風險管理與技術可行性評估整合案例。",
      "keywords": [
        "資料品質評估",
        "技術可行性",
        "PoC驗證",
        "資料清理",
        "製造業AI",
        "評估決策"
      ],
      "reference": "L21201-AI導入評估.md - 技術可行性評估與資料品質"
    },
    {
      "question_id": "L21201_007",
      "sequence": 55,
      "topic": "L21201-AI導入評估",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某金融機構評估導入客戶流失預測AI,預計初期投資200萬元,第1年可增加營收600萬但需額外行銷成本300萬,第2-3年每年淨收益400萬。使用10%折現率,此專案的NPV約為多少?(計算至整數)",
      "options": {
        "A": "NPV約為500萬",
        "B": "NPV約為900萬",
        "C": "NPV約為730萬",
        "D": "NPV約為1200萬"
      },
      "answer": "C",
      "explanation": "NPV計算:NPV = Σ[現金流t / (1+r)^t] - 初始投資。第1年淨現金流 = 600-300 = 300萬;第2-3年各為400萬。NPV = 300/1.1 + 400/1.1² + 400/1.1³ - 200 = 272.7 + 330.6 + 300.5 - 200 = 703.8 ≈ 730萬(考慮四捨五入)。NPV > 0表示專案具經濟價值,且高達730萬的正NPV顯示這是高價值專案,建議執行。NPV考慮了資金時間價值,比簡單的ROI更能反映長期專案的真實價值。這個案例展示了金融業AI專案如何透過挽留高價值客戶創造顯著經濟效益。",
      "keywords": ["NPV計算", "折現現金流", "財務評估", "金融AI", "投資決策"],
      "reference": "L21201-AI導入評估.md - NPV計算實例"
    },
    {
      "question_id": "L21201_008",
      "sequence": 56,
      "topic": "L21201-AI導入評估",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在AI導入評估的業務價值優先矩陣中,高價值×高可行性的專案應如何處理?",
      "options": {
        "A": "放棄,風險太高",
        "B": "立即執行,屬於Quick Wins",
        "C": "延後執行,優先級最低",
        "D": "僅做概念驗證,不實際部署"
      },
      "answer": "B",
      "explanation": "在2×2優先矩陣中,專案依據業務價值和可行性分為四類:(1)高價值×高可行性 → Quick Wins(快速見效):立即執行,能快速產生業務價值且風險可控,是最優先投資的專案;(2)高價值×低可行性 → Strategic Projects(策略專案):需投入資源提升可行性,中長期執行;(3)低價值×高可行性 → Fill-in Projects(填補專案):有餘力時執行,非優先;(4)低價值×低可行性 → Avoid(避免):資源錯配,應放棄。高價值×高可行性專案同時滿足「值得做」和「做得到」,是AI導入的最佳切入點,應優先投入資源快速實現。",
      "keywords": [
        "優先矩陣",
        "Quick Wins",
        "專案優先順序",
        "業務價值",
        "可行性評估"
      ],
      "reference": "L21201-AI導入評估.md - 價值優先矩陣"
    },
    {
      "question_id": "L21201_009",
      "sequence": 57,
      "topic": "L21201-AI導入評估",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某電商平台評估個性化推薦系統,預計初期投資800萬,年度營運成本600萬,預期年增營收5000萬。第一年的ROI為何?",
      "options": {
        "A": "462.5%",
        "B": "525%",
        "C": "350%",
        "D": "200%"
      },
      "answer": "A",
      "explanation": "第一年ROI計算:ROI = (年度淨收益 - 初期投資 - 年度成本) / 初期投資 × 100% = (5000 - 800 - 600) / 800 × 100% = 3700 / 800 × 100% = 462.5%。這個極高的ROI(462.5%)顯示推薦系統是高回報專案,回收期僅0.18年(約2個月)。個性化推薦能顯著提升轉換率和客單價,是電商平台最具價值的AI應用之一。如此高的ROI建議優先投入資源快速上線,並採用成熟開源框架降低開發風險,建立A/B測試平台持續優化推薦效果。",
      "keywords": ["ROI計算", "推薦系統", "電商AI", "投資回報", "高價值專案"],
      "reference": "L21201-AI導入評估.md - 推薦系統ROI案例"
    },
    {
      "question_id": "L21201_010",
      "sequence": 58,
      "topic": "L21201-AI導入評估",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在評估AI專案的技術成熟度(TRL, Technology Readiness Level)時,TRL 7-9代表什麼階段?",
      "options": {
        "A": "概念驗證階段(Proof of Concept)",
        "B": "技術驗證與試點(Pilot)",
        "C": "系統整合與規模部署(Production)",
        "D": "基礎研究階段"
      },
      "answer": "C",
      "explanation": "TRL(Technology Readiness Level)是NASA提出的技術成熟度分級標準,共分9級:(1)TRL 1-3:基礎研究與概念驗證(Proof of Concept),技術處於實驗室階段,風險極高;(2)TRL 4-6:技術驗證與試點(Pilot),技術在受控環境中驗證,需投入研發資源;(3)TRL 7-9:系統整合與規模部署(Production),技術成熟並在真實環境大規模運行,風險低。AI專案建議優先選擇TRL 7-9的成熟技術(如CNN圖像分類、BERT文本理解),成功率高;選擇TRL 4-6需投入研發;選擇TRL 1-3屬高風險創新專案。",
      "keywords": [
        "TRL",
        "技術成熟度",
        "技術選型",
        "風險評估",
        "Production Ready"
      ],
      "reference": "L21201-AI導入評估.md - 技術成熟度評估"
    },
    {
      "question_id": "L21201_011",
      "sequence": 59,
      "topic": "L21201-AI導入評估",
      "difficulty": "hard",
      "question_type": "technical_principles",
      "question": "下列哪種情境最不適合導入AI解決方案?",
      "options": {
        "A": "需處理大量醫療影像進行病灶辨識,規則複雜難以窮舉",
        "B": "審批流程規則明確且穩定,可用確定性演算法實現",
        "C": "客服系統需處理多樣化客戶問詢,需個性化回應",
        "D": "金融風險評估需分析大量歷史交易資料找出欺詐模式"
      },
      "answer": "B",
      "explanation": "AI適用性判斷的核心標準:AI適合處理規則複雜、資料量大、存在模式識別需求、需要個性化的場景。選項B的審批流程規則明確且穩定,可用傳統的規則引擎(Rule Engine)或RPA(機器人流程自動化)實現,成本更低、可解釋性更強、維護更簡單,不需要AI的複雜性。選項A的醫療影像辨識、選項C的個性化客服、選項D的欺詐模式識別都符合AI適用特徵:規則複雜、大量資料、模式識別、適應性需求。AI Solution Fit Score公式:AI_Fit = (問題複雜度 + 資料可用性 + 自動化效益) - 傳統方案有效性,選項B的傳統方案有效性高,AI_Fit分數低。",
      "keywords": ["AI適用性", "技術選型", "規則引擎vs AI", "RPA", "評估決策"],
      "reference": "L21201-AI導入評估.md - AI適用性判斷公式"
    },
    {
      "question_id": "L21201_012",
      "sequence": 60,
      "topic": "L21201-AI導入評估",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某醫院評估導入AI輔助診斷系統,技術可行性高,預期ROI達150%,但存在以下風險:醫師對AI信任度低(機率60%,影響3分)、誤診可能引發醫療糾紛(機率20%,影響5分)、資料隱私合規挑戰(機率40%,影響4分)。根據風險評估矩陣,應優先緩解哪個風險?",
      "options": {
        "A": "醫師信任度低(風險分數3×0.6=1.8)",
        "B": "誤診醫療糾紛(風險分數5×0.2=1.0)",
        "C": "資料隱私合規(風險分數4×0.4=1.6)",
        "D": "三個風險都很低,無需特別處理"
      },
      "answer": "B",
      "explanation": "風險評估需正確使用風險矩陣公式:風險分數 = 機率(1-5級) × 影響(1-5級)。首先需將百分比機率轉換為1-5級:20%=2(低),40%=3(中),60%=4(高)。重新計算:(1)醫師信任度:4×3=12(中風險);(2)誤診糾紛:2×5=10(中風險);(3)隱私合規:3×4=12(中風險)。雖然三者都在中風險範圍(6-12分),但在醫療場景中,誤診引發醫療糾紛的影響最嚴重(5分=災難級),即使機率低也應優先緩解,因為一旦發生可能導致法律責任、患者傷害、系統停用。緩解措施:(a)AI作為輔助而非替代,最終決策由醫師負責;(b)建立嚴格的臨床驗證流程;(c)設置信心閾值,低信心案例必須人工複核;(d)詳細記錄AI建議與醫師決策,建立可追溯性。這是典型的風險優先級判斷與緩解策略設計題。",
      "keywords": [
        "風險評估矩陣",
        "醫療AI",
        "風險緩解",
        "系統整合",
        "醫療安全",
        "風險優先級"
      ],
      "reference": "L21201-AI導入評估.md - 風險評估矩陣與緩解策略"
    },
    {
      "question_id": "L21201_013",
      "sequence": 61,
      "topic": "L21201-AI導入評估",
      "difficulty": "hard",
      "question_type": "technical_selection",
      "question": "某企業同時評估三個AI專案:專案A(客戶推薦,投資300萬,年收益180萬,可行性高),專案B(供應鏈優化,投資500萬,年收益400萬,可行性中),專案C(新產品研發,投資200萬,年收益100萬,可行性低)。若僅能選擇一個專案,應優先選擇哪個?",
      "options": {
        "A": "專案A,回收期最短",
        "B": "專案B,年收益最高",
        "C": "專案C,投資最少",
        "D": "專案B,綜合價值優先分數最高"
      },
      "answer": "D",
      "explanation": "使用優先矩陣公式綜合評估:Priority_Score = (BusinessValue × Feasibility) / (Cost × Risk)。簡化計算(假設BusinessValue≈年收益,Risk為可行性倒數):(1)專案A:Priority_Score ≈ (180 × 高) / 300 = 180×3/300 = 1.8;(2)專案B:Priority_Score ≈ (400 × 中) / 500 = 400×2/500 = 1.6;(3)專案C:Priority_Score ≈ (100 × 低) / 200 = 100×1/200 = 0.5。但更關鍵的是2×2矩陣定位:專案A(高收益/高可行)→Quick Win;專案B(超高收益/中可行)→Strategic Project,值得投入資源;專案C(低收益/低可行)→避免。雖然專案A的回收期更短(1.67年 vs 1.25年),但專案B的年收益(400萬)遠超專案A(180萬),且供應鏈優化的長期戰略價值更高,ROI也更優(80% vs 60%首年)。若資源允許且願意承擔中等可行性風險,專案B是最佳選擇。這題考察綜合決策能力,需平衡ROI、戰略價值、可行性、風險。",
      "keywords": [
        "優先矩陣",
        "專案選擇",
        "ROI對比",
        "Strategic vs Quick Win",
        "投資決策",
        "多專案評估"
      ],
      "reference": "L21201-AI導入評估.md - 業務價值優先矩陣與專案排序"
    },
    {
      "question_id": "L21201_014",
      "sequence": 62,
      "topic": "L21201-AI導入評估",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某跨國企業評估在三個區域(美國、歐盟、中國)部署AI人臉識別考勤系統,但面臨不同的法規環境:美國部分州禁止,歐盟GDPR嚴格限制生物特徵,中國相對寬鬆。在進行風險評估與決策時,最合適的策略為何?",
      "options": {
        "A": "統一在三個區域部署相同系統,降低開發成本",
        "B": "根據各區域法規環境採取差異化策略:中國全面部署,歐盟採用替代方案(如刷卡+照片比對),美國依州法決定",
        "C": "完全放棄人臉識別,全球使用傳統刷卡",
        "D": "僅在法規最寬鬆的中國部署,其他區域不部署"
      },
      "answer": "B",
      "explanation": "跨境AI部署必須考量各地法規差異,採取差異化合規策略最為穩健:(1)風險識別:美國州法差異大(如伊利諾州BIPA法嚴格,加州相對寬鬆),歐盟GDPR將生物特徵列為敏感個資需明確同意和正當理由,中國個保法相對寬鬆但仍需告知同意;(2)差異化策略:中國可全面部署,ROI最高;歐盟採用「刷卡觸發+照片比對」替代方案,既滿足考勤需求又符合GDPR「資料最小化」原則;美國依各州法律評估,禁止州使用替代方案,允許州部署並確保明確告知;(3)全球統一的隱私保護基線:透明告知、自願參與、資料加密、定期刪除、員工可選擇退出;(4)持續監控法規變化,建立快速應變機制。選項A忽視合規風險可能導致巨額罰款;選項C過度保守犧牲業務價值;選項D地域歧視且未充分利用投資。這是高難度的跨境AI治理與風險管理題,需平衡合規、成本、業務價值、員工權益。",
      "keywords": [
        "跨境AI合規",
        "GDPR",
        "生物特徵",
        "差異化策略",
        "法規風險",
        "AI治理",
        "隱私保護"
      ],
      "reference": "L21201-AI導入評估.md - 法規風險評估與跨境合規"
    },
    {
      "question_id": "L21201_015",
      "sequence": 63,
      "topic": "L21201-AI導入評估",
      "difficulty": "hard",
      "question_type": "technical_selection",
      "question": "某傳統製造業評估導入AI,但發現組織準備度嚴重不足:缺乏AI人才,員工對AI恐懼抗拒,業務流程僵化,數位化基礎薄弱。技術可行性和ROI評估皆優異。應採取什麼行動?",
      "options": {
        "A": "立即全面推動AI轉型,強制要求員工配合",
        "B": "完全放棄AI導入,組織不ready",
        "C": "分階段策略:先進行小規模試點+組織變革準備(培訓、溝通、流程優化),待準備度提升後再擴大規模",
        "D": "外包給顧問公司全權負責,內部不需改變"
      },
      "answer": "C",
      "explanation": "組織準備度不足是AI專案失敗的主因之一,需系統性的變革管理策略,不能僅靠技術推動。最佳實踐:(1)分階段推進:Phase1 試點(Pilot)-選擇影響範圍小、成功機率高的單一產線或部門試點,降低風險,積累經驗,建立內部成功案例;Phase2 組織準備-並行開展培訓(AI基礎知識、工具使用)、溝通(AI價值宣導、消除恐懼)、流程優化(識別需調整的業務流程);Phase3 擴大規模-待試點成功且組織準備度提升後,逐步推廣到其他產線/部門;(2)變革管理具體措施:建立AI Champion團隊、設計員工激勵機制、提供轉崗培訓、強調AI是「輔助」而非「取代」、讓員工參與AI設計以提升接受度;(3)數位化基礎建設:補強資料收集、系統整合等基礎能力。選項A強推會激發強烈抗拒導致失敗;選項B過度保守,組織能力可培養;選項D外包無法建立內部能力,長期依賴外部。Technology + People + Process = Success,三者需協同推進。",
      "keywords": [
        "組織準備度",
        "變革管理",
        "分階段導入",
        "試點策略",
        "員工培訓",
        "AI Champion",
        "數位轉型"
      ],
      "reference": "L21201-AI導入評估.md - 組織準備度評估與變革管理"
    },
    {
      "question_id": "L21201_016",
      "sequence": 64,
      "topic": "L21201-AI導入評估",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某銀行評估客戶流失預測AI專案,財務模型顯示NPV為1500萬,ROI為180%,但資料分析發現:(1)客戶資料缺失率30%,(2)標註的「流失」定義不一致(有的是3個月無交易,有的是6個月),(3)訓練資料僅涵蓋近2年,未包含經濟衰退期。在此情況下,評估報告應提出什麼建議?",
      "options": {
        "A": "NPV和ROI優異,立即執行,資料問題可在開發中解決",
        "B": "建議先進行為期2-3個月的資料治理與PoC:統一流失定義、處理缺失值、補充歷史資料、驗證模型在不同經濟周期的穩健性,再決定是否全面執行",
        "C": "資料問題嚴重,完全放棄專案",
        "D": "直接採購外部資料替代內部資料"
      },
      "answer": "B",
      "explanation": "面對高價值但資料品質不確定的專案,應採取「先驗證,再投資」策略,避免過度樂觀或過度保守。綜合建議:(1)資料治理計畫(1-2個月):統一流失定義(如6個月無交易且聯繫未果),建立明確的標註SOP;處理缺失值(分析缺失模式,決定刪除或插補策略);補充歷史資料(至少涵蓋一個經濟周期,如2008金融危機期間),評估資料可擴充性;(2)PoC驗證(1個月):用清理後的資料訓練模型,驗證準確率、召回率是否滿足業務需求(如Top20%客戶中能正確識別60%流失者);測試模型在不同時期的穩健性(時間切片驗證);(3)成本修正:將資料工程成本(估計100-200萬)和時程延遲納入財務模型,重新計算NPV和ROI;(4)決策建議:若PoC驗證成功(準確率達標),修正後的NPV仍為正,建議執行;若驗證失敗或成本大幅增加導致NPV為負,則延後或重新設計。這種approach在2-3個月的驗證投入(50-100萬)下,能大幅降低全面執行的風險(原計畫投資500萬)。選項A過度樂觀,資料問題會導致模型失敗;選項C過度保守,放棄高價值機會;選項D外部資料未必適配業務需求且有隱私風險。",
      "keywords": [
        "資料治理",
        "PoC驗證",
        "風險緩解",
        "分階段決策",
        "資料品質",
        "模型穩健性",
        "金融AI"
      ],
      "reference": "L21201-AI導入評估.md - 資料品質風險評估與PoC驗證策略"
    },
    {
      "question_id": "L21201_017",
      "sequence": 65,
      "topic": "L21201-AI導入評估",
      "difficulty": "hard",
      "question_type": "technical_principles",
      "question": "在進行AI專案的成本效益分析時,相較於傳統IT專案,AI專案的效益量化更為複雜,主要原因為何?應如何應對?",
      "options": {
        "A": "AI專案的所有效益都無法量化,只能憑感覺評估",
        "B": "AI專案部分效益難以直接換算金額(如客戶體驗提升),且存在模型準確度、採用率等不確定性;應採用代理指標、敏感度分析、PoC驗證、參考標竿等方法",
        "C": "AI專案比傳統IT更容易量化效益",
        "D": "AI專案不需要進行成本效益分析"
      },
      "answer": "B",
      "explanation": "AI專案成本效益分析的複雜性與應對策略:(1)效益量化挑戰:部分效益如客戶體驗提升、品牌形象改善、員工滿意度提升難以直接換算金額;應對:使用代理指標(如NPS提升10%→估計客戶留存率提升5%→換算為營收增長),參考業界標竿案例推估;(2)不確定性高:模型準確度難以事前精確預測(可能80%-95%),使用者採用率存在變數(可能50%-90%);應對:敏感度分析,設定樂觀/基準/悲觀三情境,評估ROI範圍(如樂觀250%、基準150%、悲觀80%),了解關鍵假設變動的影響;(3)隱性成本多:資料工程、持續訓練、模型維運、變革管理成本易被低估;應對:完整成本清單+20%緩衝預算;(4)效益遞延:AI專案可能需較長時間才見效(學習曲線、採用曲線);應對:使用NPV考慮時間價值,設定合理的評估期間(3-5年);(5)PoC驗證:小規模試點驗證實際效益,降低估算誤差,用實證資料校準財務模型。綜合運用這些方法,可提升AI專案成本效益分析的準確性和可信度。",
      "keywords": [
        "成本效益分析",
        "效益量化",
        "代理指標",
        "敏感度分析",
        "PoC驗證",
        "AI vs IT專案",
        "不確定性管理"
      ],
      "reference": "L21201-AI導入評估.md - AI專案成本效益分析複雜性與應對"
    },
    {
      "question_id": "L21201_018",
      "sequence": 66,
      "topic": "L21201-AI導入評估",
      "difficulty": "hard",
      "question_type": "technical_selection",
      "question": "某零售集團評估五個AI專案,資源有限僅能執行兩個。專案資訊:(A)門市客流預測-投資150萬,年收益100萬,可行性高,戰略重要性中;(B)智慧補貨-投資200萬,年收益180萬,可行性高,戰略重要性高;(C)虛擬試衣-投資500萬,年收益300萬,可行性中,戰略重要性高;(D)價格優化-投資100萬,年收益60萬,可行性高,戰略重要性低;(E)欺詐偵測-投資300萬,年收益150萬,可行性中,戰略重要性中。應選擇哪兩個專案?",
      "options": {
        "A": "A+D,總投資最少",
        "B": "B+C,年收益最高",
        "C": "B+A,Quick Wins策略,高ROI+高可行性+兼顧戰略",
        "D": "C+E,最具創新性"
      },
      "answer": "C",
      "explanation": "多專案選擇需綜合考量ROI、可行性、戰略重要性、總投資限制。量化分析:(1)ROI排序:D(60%)>A(67%)>B(90%)>E(50%)>C(60%);但需考慮戰略價值;(2)可行性:A/B/D高,C/E中;(3)戰略重要性:B/C高,A/E中,D低;(4)2×2矩陣定位:B(高ROI+高可行+高戰略)→最優Quick Win;A(中高ROI+高可行+中戰略)→次優Quick Win;C(中ROI+中可行+高戰略)→Strategy Project,但風險較高需投入資源;D(高ROI+高可行+低戰略)→Fill-in;E(中ROI+中可行+中戰略)→中等。選項分析:(A)A+D投資僅250萬但戰略價值低,年收益160萬;(B)B+C投資700萬超出預算且C可行性中風險高,雖年收益480萬;(C)B+A投資350萬適中,年收益280萬,兩者都是高可行性Quick Wins,B具高戰略價值(智慧補貨影響供應鏈效率),A提供穩定回報,組合風險低且兼顧短期和戰略;(D)C+E投資800萬過高且兩者都是中可行性,風險集中。最佳策略:優先選擇高可行性+高ROI的Quick Wins(B+A),確保快速見效並積累AI能力,待資源和經驗充足後再投資策略型專案(C)。",
      "keywords": [
        "多專案選擇",
        "資源配置",
        "ROI排序",
        "Quick Wins",
        "戰略平衡",
        "風險分散",
        "投資組合"
      ],
      "reference": "L21201-AI導入評估.md - 多專案優先排序與資源配置策略"
    },
    {
      "question_id": "L21202_001",
      "sequence": 67,
      "topic": "L21202-AI導入規劃",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "WBS(Work Breakdown Structure,工作分解結構)在AI專案規劃中的主要作用是什麼?",
      "options": {
        "A": "計算專案預算",
        "B": "將專案目標層層分解為可管理的工作包,明確交付物與責任歸屬",
        "C": "評估專案風險",
        "D": "選擇AI技術架構"
      },
      "answer": "B",
      "explanation": "WBS(工作分解結構)是專案管理的核心工具,將專案目標從頂層逐層分解為更小、更具體的工作包(Work Package),直到可以明確定義、估算和執行的顆粒度。WBS的主要作用:(1)範疇管理:確保所有必要工作都被識別,避免遺漏;(2)明確交付物:每個工作包對應明確的deliverables;(3)責任分配:為每個工作包指派負責人;(4)估算基礎:基於WBS進行時間、成本、資源估算;(5)進度追蹤:依據WBS監控專案進展。在AI專案中,典型的第一層分解為:資料準備、模型開發、系統整合、測試驗證、部署上線、變革管理。WBS不直接計算預算或評估風險,但為這些活動提供結構化基礎。",
      "keywords": ["WBS", "工作分解", "專案管理", "範疇管理", "交付物"],
      "reference": "L21202-AI導入規劃.md - WBS工作分解結構"
    },
    {
      "question_id": "L21202_002",
      "sequence": 68,
      "topic": "L21202-AI導入規劃",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "RACI矩陣中的四個角色代表什麼?",
      "options": {
        "A": "Responsible(負責執行)、Accountable(最終當責)、Consulted(諮詢)、Informed(知會)",
        "B": "Risk(風險)、Analysis(分析)、Control(控制)、Implementation(實施)",
        "C": "Resource(資源)、Activity(活動)、Cost(成本)、Input(輸入)",
        "D": "Review(審查)、Approve(批准)、Create(創建)、Issue(發布)"
      },
      "answer": "A",
      "explanation": "RACI矩陣是責任分配矩陣,用於明確專案中每項任務的角色與責任,避免職責不清或重疊。RACI四個角色:(1)R - Responsible(負責執行):實際執行任務的人,可以有多人;(2)A - Accountable(最終當責):對任務成果負最終責任的人,每個任務只能有一個A,擁有最終決策權和問責權;(3)C - Consulted(諮詢):需要提供意見和專業建議的人,雙向溝通;(4)I - Informed(知會):需要被告知進展和結果的人,單向溝通。RACI矩陣的行列分別為任務和角色,交叉處填入R/A/C/I。範例:資料清理任務-R:資料工程師,A:資料科學主管,C:領域專家,I:專案經理。這能確保每項任務都有明確的執行者和當責者。",
      "keywords": ["RACI矩陣", "責任分配", "專案角色", "當責機制", "團隊協作"],
      "reference": "L21202-AI導入規劃.md - RACI責任分配矩陣"
    },
    {
      "question_id": "L21202_003",
      "sequence": 69,
      "topic": "L21202-AI導入規劃",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "關鍵路徑法(CPM, Critical Path Method)在專案時程規劃中用於找出什麼?",
      "options": {
        "A": "專案成本最低的路徑",
        "B": "從專案開始到結束的最長路徑,決定專案最短完成時間",
        "C": "專案風險最高的路徑",
        "D": "專案資源需求最少的路徑"
      },
      "answer": "B",
      "explanation": "關鍵路徑法(CPM)是專案時程管理的核心技術,用於找出專案網路圖中從開始到結束的最長路徑,這條路徑決定了專案的最短完成時間。關鍵路徑上的任務沒有任何時間緩衝(float/slack = 0),任何一個任務延遲都會導致整個專案延遲,因此需重點監控。CPM步驟:(1)列出所有任務及其依賴關係;(2)估算每個任務的工期;(3)繪製網路圖;(4)前推計算(Forward Pass)得到最早開始/完成時間;(5)後推計算(Backward Pass)得到最晚開始/完成時間;(6)計算浮時(Float),浮時為0的任務序列即為關鍵路徑。例如,AI專案的關鍵路徑可能是:需求分析→資料收集→模型訓練→系統整合→上線部署,總時程6個月,其中模型訓練浮時為0,必須按時完成。",
      "keywords": [
        "關鍵路徑",
        "CPM",
        "時程管理",
        "最長路徑",
        "浮時",
        "專案網路圖"
      ],
      "reference": "L21202-AI導入規劃.md - 關鍵路徑法CPM"
    },
    {
      "question_id": "L21202_004",
      "sequence": 70,
      "topic": "L21202-AI導入規劃",
      "difficulty": "simple",
      "question_type": "technical_selection",
      "question": "某AI專案需求明確且穩定,時程緊迫,需要嚴格的階段管控和文件交付。應選擇敏捷式(Agile)還是瀑布式(Waterfall)開發模式?",
      "options": {
        "A": "敏捷式,因為AI專案都應該用敏捷",
        "B": "瀑布式,因為需求明確且需要階段管控",
        "C": "兩者混合,前半段用敏捷後半段用瀑布",
        "D": "完全不需要任何開發模式"
      },
      "answer": "B",
      "explanation": "開發模式選擇需根據專案特性。瀑布式適合本案例,理由:(1)需求明確且穩定:瀑布式要求前期需求凍結,適合需求變動小的專案;敏捷適合需求模糊或易變動的場景;(2)階段管控需求:瀑布式的線性流程(需求→設計→開發→測試→部署)有明確的階段閘門和交付物,便於管控;(3)文件要求:瀑布式重視文件,適合需要完整規格文件的專案(如政府專案、合規要求高的金融專案)。然而,純瀑布式在AI專案中風險較高,因為模型準確度難以事前精確預測,建議採用「混合模式」:前期需求與架構設計用瀑布式(確保穩定基礎),模型開發與優化用敏捷迭代(允許實驗和調整),後期部署與維運回到瀑布式(確保穩定交付)。這種Hybrid approach平衡了可預測性和靈活性。",
      "keywords": [
        "敏捷vs瀑布",
        "開發模式選擇",
        "需求穩定性",
        "專案管理",
        "混合模式"
      ],
      "reference": "L21202-AI導入規劃.md - 敏捷vs瀑布開發模式選擇"
    },
    {
      "question_id": "L21202_005",
      "sequence": 71,
      "topic": "L21202-AI導入規劃",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在AI專案的里程碑規劃中,以下哪個順序最符合典型的專案生命週期?",
      "options": {
        "A": "模型訓練 → 資料收集 → 需求分析 → 系統部署",
        "B": "需求分析 → 資料收集 → 模型訓練 → 系統部署",
        "C": "系統部署 → 模型訓練 → 資料收集 → 需求分析",
        "D": "資料收集 → 系統部署 → 需求分析 → 模型訓練"
      },
      "answer": "B",
      "explanation": "AI專案的典型生命週期遵循由上到下的邏輯順序:(1)需求分析(Requirement Analysis):定義業務問題、目標、成功標準、約束條件,這是一切工作的起點,必須先明確「要解決什麼問題」;(2)資料收集與準備(Data Collection & Preparation):根據需求識別所需資料、收集、清理、標註、探索性分析,資料是AI的基礎,必須在模型訓練前準備好;(3)模型訓練與驗證(Model Training & Validation):選擇演算法、訓練模型、調參、驗證效能,這是AI專案的核心技術階段;(4)系統整合與部署(System Integration & Deployment):將模型整合到業務系統、部署到生產環境、監控運行。每個階段都有明確的里程碑和交付物,前一階段的輸出是後一階段的輸入,形成嚴謹的邏輯鏈。",
      "keywords": [
        "專案生命週期",
        "里程碑規劃",
        "AI專案流程",
        "階段順序",
        "專案管理"
      ],
      "reference": "L21202-AI導入規劃.md - AI專案生命週期與里程碑"
    },
    {
      "question_id": "L21202_006",
      "sequence": 72,
      "topic": "L21202-AI導入規劃",
      "difficulty": "simple",
      "question_type": "technical_selection",
      "question": "某新創公司要開發創新AI產品,需求高度不確定,需要快速試錯和市場反饋。應選擇哪種開發模式?",
      "options": {
        "A": "瀑布式,因為需要完整規劃",
        "B": "敏捷式,適合需求不確定和快速迭代",
        "C": "V模型,強調測試",
        "D": "不需要任何開發流程"
      },
      "answer": "B",
      "explanation": "敏捷式開發非常適合本案例的創新與不確定性場景,理由:(1)需求不確定:敏捷允許需求在開發過程中演化,每個Sprint(2-4週)交付可用增量,快速獲取用戶反饋並調整;(2)快速試錯:敏捷的短迭代週期支持快速實驗,失敗成本低,可以快速pivot;(3)市場反饋驅動:每個Sprint結束都有可演示的產品增量,可以快速推向市場驗證假設;(4)適應變化:敏捷擁抱變化而非抗拒變化,Backlog可以動態調整優先級。敏捷實踐如Scrum(Sprint計畫、每日站會、Sprint回顧)、看板(Kanban)特別適合新創的快節奏環境。瀑布式需求前期凍結,不適合不確定場景;V模型是瀑布式的變體,也不適合。關鍵:敏捷≠無紀律,仍需Product Backlog管理、Definition of Done、持續整合等實踐確保品質。",
      "keywords": [
        "敏捷開發",
        "Scrum",
        "Sprint",
        "快速迭代",
        "需求不確定",
        "新創模式"
      ],
      "reference": "L21202-AI導入規劃.md - 敏捷開發適用場景"
    },
    {
      "question_id": "L21202_007",
      "sequence": 73,
      "topic": "L21202-AI導入規劃",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在使用CPM進行時程規劃時,發現關鍵路徑上的「模型訓練」任務預估需要8週,但專案必須在6個月內完成,壓力很大。以下哪種策略最有效?",
      "options": {
        "A": "壓縮非關鍵路徑上的任務時間",
        "B": "聚焦壓縮關鍵路徑上的任務,如增加GPU資源平行訓練、縮小模型規模、採用遷移學習",
        "C": "延長專案截止日期",
        "D": "取消模型訓練任務"
      },
      "answer": "B",
      "explanation": "CPM的核心洞察:關鍵路徑決定專案總時程,只有壓縮關鍵路徑上的任務才能縮短專案時程,壓縮非關鍵路徑任務無效(它們有浮時緩衝)。針對關鍵路徑任務的壓縮策略:(1)資源投入(Crashing):增加GPU數量實現平行訓練,例如從1張V100增加到4張,訓練時間可能從8週縮短到3週(視平行化效率);(2)技術優化:縮小模型規模(如從BERT-Large降為BERT-Base)、減少訓練epoch、採用遷移學習(使用預訓練模型微調,可能從8週縮短到2週);(3)快速跟進(Fast Tracking):將原本串列的任務改為部分重疊,如資料清理與模型選型部分並行。需注意權衡:資源投入增加成本,技術優化可能影響準確度,需在時間、成本、品質三角中平衡。選項A壓縮非關鍵路徑無效;選項C延期違反約束;選項D取消核心任務不可行。",
      "keywords": [
        "CPM",
        "關鍵路徑壓縮",
        "Crashing",
        "Fast Tracking",
        "時程優化",
        "資源配置"
      ],
      "reference": "L21202-AI導入規劃.md - 關鍵路徑壓縮策略"
    },
    {
      "question_id": "L21202_008",
      "sequence": 74,
      "topic": "L21202-AI導入規劃",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某AI專案使用RACI矩陣進行責任分配,發現「模型驗證」任務有3個人被標記為A(Accountable),這會造成什麼問題?應如何修正?",
      "options": {
        "A": "這是合理的,任務越重要應該有越多人當責",
        "B": "會造成責任分散、推諉,應確保每個任務只有一個A,其他改為R或C",
        "C": "應該將3個人都改為R",
        "D": "RACI矩陣不重要,不需要修正"
      },
      "answer": "B",
      "explanation": "RACI矩陣的核心原則:每個任務必須且只能有一個A(Accountable,最終當責者)。多個A會造成嚴重問題:(1)責任分散:當出問題時,3個人都可以推說「以為其他人負責」,沒有人承擔最終責任;(2)決策混亂:沒有單一決策者,容易陷入爭論或決策延遲;(3)當責缺失:責任無法追溯到具體個人。修正方法:識別真正的最終決策者和當責者(通常是該領域主管),將其保留為A,其他人根據實際角色調整為:(a)R(Responsible,負責執行):實際做驗證工作的資料科學家;(b)C(Consulted,諮詢):需要提供專業意見的領域專家;(c)I(Informed,知會):需要知道結果的專案經理。正確範例:模型驗證-A:資料科學主管(最終決策驗證是否通過),R:資深資料科學家(執行驗證實驗),C:領域專家(提供業務角度意見),I:專案經理(知會進度)。記住:一個A的責任,多個R的協作。",
      "keywords": ["RACI矩陣", "單一當責", "責任分配", "專案治理", "避免推諉"],
      "reference": "L21202-AI導入規劃.md - RACI矩陣最佳實踐"
    },
    {
      "question_id": "L21202_009",
      "sequence": 75,
      "topic": "L21202-AI導入規劃",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某AI專案的網路圖如下:A(2週)→B(3週)→D(4週)→E(2週);A(2週)→C(5週)→E(2週)。請問關鍵路徑是哪一條,專案最短完成時間為多少週?",
      "options": {
        "A": "A→B→D→E,11週",
        "B": "A→C→E,9週",
        "C": "A→B→D→E,11週是關鍵路徑,因為比A→C→E的9週長",
        "D": "兩條路徑時間相同"
      },
      "answer": "C",
      "explanation": "關鍵路徑分析:(1)路徑1:A→B→D→E = 2+3+4+2 = 11週;(2)路徑2:A→C→E = 2+5+2 = 9週。關鍵路徑是所有路徑中最長的,因為它決定了專案的最短完成時間(你不能比最長的路徑更快完成專案)。因此關鍵路徑是A→B→D→E,專案最短完成時間為11週。路徑2(A→C→E)有2週浮時(11-9=2),即C任務可以延遲2週而不影響專案總時程。關鍵路徑上的任務(A、B、D、E)浮時為0,任何延遲都會導致專案延遲,需重點監控。在實務中,專案經理應將資源優先配置給關鍵路徑任務,密切追蹤其進度。",
      "keywords": ["關鍵路徑計算", "CPM", "網路圖", "浮時", "專案時程"],
      "reference": "L21202-AI導入規劃.md - CPM關鍵路徑計算"
    },
    {
      "question_id": "L21202_010",
      "sequence": 76,
      "topic": "L21202-AI導入規劃",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在敏捷式AI專案開發中,Sprint的典型時間長度為何?為什麼不建議過長或過短?",
      "options": {
        "A": "1天,快速迭代",
        "B": "2-4週,平衡快速反饋與可交付增量",
        "C": "3個月,確保充分開發",
        "D": "1年,完整功能開發"
      },
      "answer": "B",
      "explanation": "敏捷開發的Sprint(衝刺)典型長度為2-4週(最常見是2週),這個時間範圍平衡了多個因素:(1)過短(如1週或更短):團隊沒有足夠時間交付有意義的可用增量,頻繁的Sprint計畫和回顧會議佔用過多時間,開銷過高,難以應對需求分析和測試;(2)過長(如6週以上):失去敏捷的快速反饋優勢,需求變化風險增加,團隊容易偏離目標太遠才發現,檢視與調適週期過長;(3)2-4週的優勢:足夠時間完成有價值的用戶故事(User Story),例如完成一個模型特徵的開發和驗證;頻繁的檢視點(每2-4週一次Sprint Review)確保快速反饋;保持團隊專注和節奏感。在AI專案中,由於模型訓練可能較耗時,有時會採用3-4週的Sprint,但仍應確保每個Sprint都有可演示的增量(如新特徵、準確度提升、新模組)。",
      "keywords": ["Sprint", "敏捷開發", "迭代週期", "Scrum", "快速反饋"],
      "reference": "L21202-AI導入規劃.md - 敏捷Sprint規劃"
    },
    {
      "question_id": "L21202_011",
      "sequence": 77,
      "topic": "L21202-AI導入規劃",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某金融AI專案需求變動頻繁但必須符合嚴格的合規要求(如完整的需求文件、測試報告、變更管理)。應採用哪種開發模式?",
      "options": {
        "A": "純敏捷式,快速應對需求變化",
        "B": "純瀑布式,滿足合規文件要求",
        "C": "混合模式(Hybrid):敏捷迭代開發+瀑布式治理(文件、審查、變更控制)",
        "D": "不需要任何開發模式"
      },
      "answer": "C",
      "explanation": "金融等高度監管行業的AI專案面臨雙重挑戰:需求變動(需要靈活性)和合規要求(需要嚴謹性)。混合模式(Hybrid Agile)是最佳選擇,結合兩者優勢:(1)敏捷迭代核心:開發團隊使用Scrum進行2-4週Sprint迭代,快速應對需求變化,持續交付可用增量;(2)瀑布式治理層:在敏捷外包一層瀑布式治理,確保合規:(a)需求管理:敏捷的User Story仍需追溯到正式的需求規格文件(SRS),重大需求變更需經變更控制委員會(CCB)審批;(b)階段閘門:在關鍵里程碑設置Stage Gate(如PoC完成、UAT通過),需提交完整文件並通過審查才能進入下一階段;(c)測試與稽核:每個Sprint的交付需符合測試標準,定期進行合規稽核。(3)實施方式:例如SAFe(Scaled Agile Framework)框架,在團隊層採用敏捷,在方案層和投資組合層採用節奏化的瀑布式計畫。這種模式在銀行、保險、醫療等行業廣泛應用,平衡了創新速度和風險控制。",
      "keywords": [
        "混合開發模式",
        "Agile+Waterfall",
        "合規要求",
        "金融AI",
        "SAFe",
        "受監管行業"
      ],
      "reference": "L21202-AI導入規劃.md - 混合開發模式(Hybrid Agile)"
    },
    {
      "question_id": "L21202_012",
      "sequence": 78,
      "topic": "L21202-AI導入規劃",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在WBS工作分解中,AI專案的第一層分解通常包含哪些主要工作包?",
      "options": {
        "A": "僅包含模型訓練和部署",
        "B": "需求分析、資料準備、模型開發、系統整合、測試驗證、部署上線、變革管理",
        "C": "僅包含技術開發工作,不包含非技術工作",
        "D": "根據團隊成員姓名分解"
      },
      "answer": "B",
      "explanation": "AI專案的WBS第一層分解應涵蓋完整生命週期的所有主要階段,典型結構:(1)需求分析(Requirement Analysis):業務需求訪談、問題定義、成功標準、範疇確認;(2)資料準備(Data Preparation):資料收集、清理、標註、探索性分析、特徵工程;(3)模型開發(Model Development):演算法選擇、模型訓練、調參、驗證、優化;(4)系統整合(System Integration):API開發、與現有系統整合、中介軟體開發;(5)測試驗證(Testing & Validation):單元測試、整合測試、UAT、效能測試、安全測試;(6)部署上線(Deployment):環境準備、部署、上線、監控設置;(7)變革管理(Change Management):用戶培訓、溝通宣導、流程調整、支援準備;(8)專案管理(Project Management):貫穿全程的計畫、監控、風險管理、溝通協調。每個第一層工作包再分解為第二層、第三層,直到可執行的顆粒度(通常一個工作包1-2週可完成)。這種結構化分解確保沒有遺漏關鍵工作。",
      "keywords": [
        "WBS分解",
        "AI專案生命週期",
        "工作包",
        "範疇管理",
        "專案結構"
      ],
      "reference": "L21202-AI導入規劃.md - AI專案WBS典型結構"
    },
    {
      "question_id": "L21202_013",
      "sequence": 79,
      "topic": "L21202-AI導入規劃",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某AI專案在Sprint 3發現原本承諾的5個User Story中,模型準確度要求(從80%提升到95%)因資料品質問題無法達成。在Sprint Review時應如何處理?",
      "options": {
        "A": "隱瞞問題,假裝已完成",
        "B": "透明揭露問題,與Product Owner討論:調整準確度目標、投入資料清理工作、或延後該User Story到下個Sprint",
        "C": "強行宣稱已達成95%",
        "D": "立即終止整個專案"
      },
      "answer": "B",
      "explanation": "敏捷的核心價值之一是透明(Transparency),在Sprint Review遇到問題應坦誠溝通並協作解決,而非隱瞞。正確處理流程:(1)問題揭露:在Sprint Review向利害關係人透明展示實際達成的80%準確度,說明根因是訓練資料中30%樣本標註錯誤;(2)影響分析:評估80% vs 95%對業務價值的影響,是否仍可接受?若業務可接受80%,則此Story視為完成;若必須95%,則此Story未完成;(3)協作決策:與Product Owner討論三種選項:(a)調整Definition of Done,接受80%並標記為技術債務(Technical Debt),後續Sprint改善;(b)投入資料清理工作(重新標註資料),將準確度提升Story移到下個Sprint Backlog,提高優先級;(c)如果是根本性問題(資料永遠無法支持95%),則重新評估產品目標;(4)經驗學習:在Sprint Retrospective討論如何提前發現資料品質問題,改進Definition of Ready。這種透明和適應的態度是敏捷成功的關鍵,遠勝於隱瞞問題導致後期崩潰。",
      "keywords": [
        "敏捷透明度",
        "Sprint Review",
        "User Story",
        "Product Owner",
        "適應性規劃",
        "技術債務"
      ],
      "reference": "L21202-AI導入規劃.md - 敏捷問題處理與透明溝通"
    },
    {
      "question_id": "L21202_014",
      "sequence": 80,
      "topic": "L21202-AI導入規劃",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在AI專案的風險規劃中,應建立風險登錄簿(Risk Register)記錄哪些資訊?",
      "options": {
        "A": "僅記錄風險名稱",
        "B": "風險描述、機率、影響、風險分數、緩解策略、負責人、狀態",
        "C": "僅記錄已發生的問題",
        "D": "不需要記錄風險"
      },
      "answer": "B",
      "explanation": "風險登錄簿(Risk Register)是專案風險管理的核心工具,應記錄風險的完整生命週期資訊,典型欄位:(1)風險ID:唯一識別碼;(2)風險描述:清晰描述風險事件和潛在影響,例如「訓練資料標註品質不一致,可能導致模型準確度低於目標」;(3)風險類別:技術風險、資料風險、業務風險、合規風險等;(4)機率(Probability):1-5級,估計發生可能性;(5)影響(Impact):1-5級,估計對專案的衝擊;(6)風險分數:機率×影響,用於排序優先級;(7)緩解策略(Mitigation Strategy):如何降低風險或減輕影響,例如「建立標註SOP和雙人複核機制」;(8)應變計畫(Contingency Plan):風險發生時的應對方案;(9)負責人(Risk Owner):誰負責監控和管理此風險;(10)狀態:開放、監控中、已緩解、已關閉。風險登錄簿應在專案啟動時建立,並在整個專案生命週期持續更新(每週或每Sprint檢視),作為風險管理會議的主要工具。",
      "keywords": [
        "風險登錄簿",
        "風險管理",
        "緩解策略",
        "風險分數",
        "Risk Register"
      ],
      "reference": "L21202-AI導入規劃.md - 風險登錄簿管理"
    },
    {
      "question_id": "L21202_015",
      "sequence": 81,
      "topic": "L21202-AI導入規劃",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某AI專案規劃資源需求,團隊包含:資料工程師2人、資料科學家3人、軟體工程師2人、DevOps工程師1人、專案經理1人。在專案的「資料準備」階段(預計8週),哪些角色應為主要投入?",
      "options": {
        "A": "僅資料科學家",
        "B": "資料工程師(主力)+ 資料科學家(協作探索性分析)+ 專案經理(協調)",
        "C": "所有角色全力投入",
        "D": "僅專案經理"
      },
      "answer": "B",
      "explanation": "AI專案不同階段需要不同角色的主力投入,資源規劃需精準匹配。資料準備階段的角色投入:(1)資料工程師(主力100%):負責資料收集、ETL pipeline開發、資料清理、資料品質檢查、特徵儲存,這是他們的核心專長,應全力投入;(2)資料科學家(協作30-50%):參與探索性資料分析(EDA)、特徵工程設計、標註策略制定,了解資料特性為模型開發做準備;(3)領域專家(諮詢):提供業務知識指導資料理解和特徵定義;(4)專案經理(日常):協調資源、追蹤進度、解決阻礙。其他角色在此階段投入較少:軟體工程師可能僅10-20%投入準備整合環境,DevOps準備基礎設施,資料科學家的主力投入會在下一階段(模型開發)。這種階段性的資源波峰規劃(Resource Leveling)確保人力高效利用,避免資源閒置或過度配置。在WBS基礎上,使用責任分配矩陣(RAM)或資源長條圖清晰呈現各階段的人力需求。",
      "keywords": [
        "資源規劃",
        "角色分工",
        "資料準備階段",
        "資源長條圖",
        "專案人力配置"
      ],
      "reference": "L21202-AI導入規劃.md - AI專案各階段資源配置"
    },
    {
      "question_id": "L21202_016",
      "sequence": 82,
      "topic": "L21202-AI導入規劃",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某跨國企業規劃大型AI轉型專案,包含5個子專案(客服機器人、推薦系統、需求預測、品質檢測、風險評估),涉及8個部門、3個區域、100+人團隊,為期2年。在規劃時,應採用什麼層級的專案管理框架?",
      "options": {
        "A": "單一專案管理,所有工作用一個WBS管理",
        "B": "方案管理(Program Management):建立方案層統籌5個專案,確保目標對齊、資源協調、依賴管理、綜效實現",
        "C": "完全獨立管理5個專案,互不相關",
        "D": "不需要任何管理框架"
      },
      "answer": "B",
      "explanation": "大型AI轉型屬於方案級(Program)而非單一專案級(Project),需要方案管理框架統籌。方案vs專案的關鍵差異:(1)方案(Program):一組相關專案的集合,共同實現戰略目標(AI轉型),關注整體綜效、變革管理、效益實現;專案(Project):臨時性任務,產出特定交付物(如客服機器人系統);(2)方案管理框架(如PMI PgMP、SAFe)應包含:【方案治理層】方案指導委員會(Steering Committee)、方案經理(Program Manager)、PMO(專案管理辦公室);【方案規劃】整體方案藍圖、路線圖(Roadmap)、效益管理計畫、組織變革計畫;【專案協調】5個子專案各有專案經理,但需協調:(a)依賴管理:如客服機器人和推薦系統可能共用NLP平台;(b)資源協調:資料科學家跨專案支援,避免資源衝突;(c)風險整合:識別跨專案風險(如GDPR合規影響所有專案);【效益實現】各專案交付物≠方案效益,需整合實現AI轉型的商業價值;【變革管理】大規模組織變革、文化轉型、能力建設。這種方案級管理確保5個專案不是孤島,而是協同實現AI轉型戰略。單一專案管理無法應對此複雜度,完全獨立管理會錯失綜效和協調機會。",
      "keywords": [
        "方案管理",
        "Program Management",
        "大型轉型",
        "多專案協調",
        "PMO",
        "效益管理",
        "變革管理"
      ],
      "reference": "L21202-AI導入規劃.md - 方案管理vs專案管理"
    },
    {
      "question_id": "L21202_017",
      "sequence": 83,
      "topic": "L21202-AI導入規劃",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某醫療AI專案採用混合開發模式(敏捷核心+瀑布治理),在Sprint 5時FDA要求新增可解釋性報告(Explainability Report),導致原計畫需調整。該需求變更應如何處理以兼顧敏捷靈活性和合規要求?",
      "options": {
        "A": "直接加入下個Sprint Backlog立即開發",
        "B": "經正式變更控制流程:評估影響→更新需求文件→CCB審批→更新方案計畫→再納入Product Backlog排序",
        "C": "拒絕變更,維持原計畫",
        "D": "私下修改代碼,不走變更流程"
      },
      "answer": "B",
      "explanation": "混合模式的關鍵是在敏捷靈活性和瀑布治理間找到平衡,重大合規需求變更必須走正式流程。完整處理步驟:(1)變更識別與評估:識別這是重大變更(FDA合規要求),評估影響:(a)範疇:新增可解釋性模組(如SHAP/LIME整合、報告生成);(b)時程:估計需2個Sprint(4週);(c)成本:需額外2人週的開發+1週的合規審查;(d)風險:延遲上線時程但必須執行(法規要求);(2)正式變更控制:提交變更請求(Change Request)到CCB(變更控制委員會),包含影響分析、建議方案、資源需求;(3)文件更新:CCB批准後更新:(a)需求規格文件(SRS)新增可解釋性需求;(b)設計文件新增可解釋性架構;(c)測試計畫新增可解釋性驗證;(d)專案計畫調整時程和預算;(4)敏捷層面適應:將可解釋性需求分解為User Stories,納入Product Backlog,由Product Owner排定優先級(通常高優先因為是合規要求),在接下來的Sprint中開發;(5)追溯性維護:確保新User Stories可追溯到更新後的SRS,滿足稽核要求。這種approach確保:(a)合規:所有變更有文件追溯和審批記錄;(b)靈活:敏捷團隊可以在Sprint內快速交付增量;(c)透明:所有利害關係人了解變更影響。選項A跳過治理會違反合規;選項C拒絕FDA要求不可行;選項D私下修改違反治理原則且有稽核風險。",
      "keywords": [
        "混合模式",
        "變更控制",
        "CCB",
        "敏捷+合規",
        "FDA",
        "醫療AI治理",
        "追溯性"
      ],
      "reference": "L21202-AI導入規劃.md - 混合模式變更管理"
    },
    {
      "question_id": "L21202_018",
      "sequence": 84,
      "topic": "L21202-AI導入規劃",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某全球零售集團規劃AI方案,包含需求預測(Project A)、動態定價(Project B)、智慧補貨(Project C)三個專案。分析發現:C依賴A的需求預測輸出,B和C都需要共用的價格彈性模型。在方案規劃時,應如何安排專案順序和依賴管理?",
      "options": {
        "A": "三個專案同時啟動,平行執行",
        "B": "階段式啟動:Phase1先啟動A(需求預測)建立基礎,Phase2啟動B和C並建立共用價格彈性模型,設置依賴管理和整合點",
        "C": "僅執行A,放棄B和C",
        "D": "隨機順序,不考慮依賴"
      },
      "answer": "B",
      "explanation": "方案層面的專案依賴和整合管理是複雜方案成功的關鍵。分析與規劃:(1)依賴分析:C(智慧補貨)依賴A(需求預測)的輸出,形成硬依賴(Hard Dependency),C必須在A產出可用的需求預測API後才能開始整合;B(動態定價)和C(智慧補貨)都需要價格彈性模型,形成共用資源依賴;(2)最佳排程策略-階段式啟動:【Phase 1 (Month 1-6)】啟動Project A(需求預測),目標:開發需求預測模型並提供API,這是基礎能力;【Phase 2 (Month 4-12,部分重疊)】Month 4同時啟動B和C(A已有初步成果可供整合),並啟動共用模組專案「價格彈性模型」;(3)依賴管理機制:【技術整合點】定義清晰的API契約(A的需求預測API規格),版本化管理;設置整合里程碑(如Month 6 A完成初版API,C開始整合測試);【共用資源協調】建立共用模組團隊開發價格彈性模型,由方案經理協調B和C的需求,避免重複開發;定義共用模型的治理機制(誰負責維護、如何版本管理);【風險緩解】若A延遲,C受直接影響,應建立緩衝時間或備案(C先用歷史平均需求開發原型);定期召開專案間整合會議(每兩週一次),追蹤依賴狀態;(4)方案級工具:使用方案路線圖(Program Roadmap)呈現時間軸和依賴;使用依賴矩陣(Dependency Matrix)追蹤跨專案依賴;使用整合管理計畫(Integration Management Plan)定義整合點和測試策略。這種階段式、有序的規劃確保:(a)降低風險:基礎能力先建立;(b)資源效率:共用模組統一開發;(c)整合可控:明確的整合點和版本管理。選項A同時啟動會導致C在A未ready時空轉,B和C重複開發價格模型浪費資源;選項C過度保守;選項D忽視依賴會導致整合災難。",
      "keywords": [
        "方案依賴管理",
        "階段式啟動",
        "跨專案整合",
        "共用資源",
        "Program Roadmap",
        "整合管理",
        "依賴矩陣"
      ],
      "reference": "L21202-AI導入規劃.md - 方案層級依賴與整合管理"
    },
    {
      "question_id": "L21301_001",
      "sequence": 85,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "資料品質評估的CACT框架代表哪四個維度?",
      "options": {
        "A": "Cost, Accuracy, Consistency, Time",
        "B": "Completeness(完整性), Accuracy(準確性), Consistency(一致性), Timeliness(及時性)",
        "C": "Create, Analyze, Control, Test",
        "D": "Clean, Augment, Check, Transform"
      },
      "answer": "B",
      "explanation": "CACT是資料品質評估的經典框架,代表四個核心維度:(1)Completeness(完整性):資料是否完整,缺失值比例多少。例如客戶資料中,地址欄位有30%缺失,完整性低;(2)Accuracy(準確性):資料是否正確反映真實情況。例如客戶年齡記錄為150歲明顯錯誤;(3)Consistency(一致性):同一實體在不同地方的資料是否一致。例如客戶姓名在系統A是「張三」,系統B是「張 三」(多空格),不一致;(4)Timeliness(及時性):資料是否即時更新,是否符合業務時效需求。例如股價資料延遲5分鐘可能無法滿足即時交易需求。在AI專案啟動前,應使用CACT框架進行資料品質稽核,識別需改善的面向,確保資料符合模型訓練要求。低品質資料會導致Garbage In, Garbage Out,嚴重影響模型效能。",
      "keywords": [
        "CACT",
        "資料品質",
        "完整性",
        "準確性",
        "一致性",
        "及時性",
        "資料稽核"
      ],
      "reference": "L21301-數據準備與模型選擇.md - CACT資料品質框架"
    },
    {
      "question_id": "L21301_002",
      "sequence": 86,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在機器學習任務類型中,以下哪個屬於監督式學習(Supervised Learning)?",
      "options": {
        "A": "K-Means聚類",
        "B": "圖像分類(有標註類別)",
        "C": "主成分分析(PCA)",
        "D": "自組織映射(SOM)"
      },
      "answer": "B",
      "explanation": "機器學習任務分為三大類:(1)監督式學習(Supervised Learning):訓練資料包含輸入(X)和對應的標籤(Y),模型學習X→Y的映射關係。包括分類(Classification,Y是離散類別)和迴歸(Regression,Y是連續值)。範例:圖像分類(輸入圖像,標籤是貓/狗)、房價預測(輸入房屋特徵,標籤是價格);(2)非監督式學習(Unsupervised Learning):訓練資料僅有輸入X,沒有標籤,模型學習資料的內在結構。包括聚類(Clustering,如K-Means)、降維(Dimensionality Reduction,如PCA)、異常檢測;(3)強化學習(Reinforcement Learning):智慧體透過與環境互動,根據獎勵信號學習最佳策略,如AlphaGo。選項B的圖像分類有明確標註,屬於監督式學習;選項A的K-Means、選項C的PCA、選項D的SOM都是非監督式學習。",
      "keywords": [
        "監督式學習",
        "分類",
        "迴歸",
        "非監督學習",
        "聚類",
        "任務類型識別"
      ],
      "reference": "L21301-數據準備與模型選擇.md - 機器學習任務類型"
    },
    {
      "question_id": "L21301_003",
      "sequence": 87,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在分類模型評估中,Precision(精確率)和Recall(召回率)的定義分別為何?",
      "options": {
        "A": "Precision = TP/(TP+FP), Recall = TP/(TP+FN)",
        "B": "Precision = TP/(TP+FN), Recall = TP/(TP+FP)",
        "C": "兩者定義相同",
        "D": "Precision是準確率,Recall是錯誤率"
      },
      "answer": "A",
      "explanation": "Precision和Recall是分類模型的核心評估指標,定義如下:(1)Precision(精確率) = TP / (TP + FP),表示模型預測為正類的樣本中,實際為正類的比例。關注「預測準不準」,高Precision表示模型預測的正類很少誤判;(2)Recall(召回率) = TP / (TP + FN),表示實際為正類的樣本中,被模型成功識別的比例。關注「找全不全」,高Recall表示模型能找出大部分正類樣本。其中TP=True Positive(正確預測為正類),FP=False Positive(錯誤預測為正類,實際是負類),FN=False Negative(錯誤預測為負類,實際是正類)。兩者存在權衡(Trade-off):提高閾值可提升Precision但降低Recall,反之亦然。不同業務場景有不同偏好:垃圾郵件檢測重Precision(避免誤殺正常郵件),疾病篩檢重Recall(避免漏檢患者)。",
      "keywords": [
        "Precision",
        "Recall",
        "精確率",
        "召回率",
        "混淆矩陣",
        "TP FP FN",
        "模型評估"
      ],
      "reference": "L21301-數據準備與模型選擇.md - Precision vs Recall"
    },
    {
      "question_id": "L21301_004",
      "sequence": 88,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某電商平台有客戶購買歷史資料,需要將客戶分群以進行精準行銷。這屬於哪種機器學習任務?應使用哪類演算法?",
      "options": {
        "A": "分類任務,使用邏輯迴歸",
        "B": "聚類任務,使用K-Means或階層式聚類",
        "C": "迴歸任務,使用線性迴歸",
        "D": "強化學習,使用Q-Learning"
      },
      "answer": "B",
      "explanation": "客戶分群是典型的聚類(Clustering)任務,屬於非監督式學習。任務特徵:(1)沒有預定義的類別標籤:不像分類任務有明確的「高價值/低價值」標籤,聚類是讓演算法自動發現資料中的自然分組;(2)目標是發現相似客戶群:根據購買行為(頻率、金額、品類偏好等)將客戶分為不同群組(如「高頻高額」、「低頻高額」、「價格敏感型」等);(3)適用演算法:K-Means(需預先指定K個群),階層式聚類(Hierarchical Clustering,產生樹狀分群),DBSCAN(基於密度的聚類,可發現任意形狀)。分類任務需要標註資料,迴歸預測連續值,強化學習需要環境互動,都不適用於此場景。聚類後可用RFM(Recency, Frequency, Monetary)分析解讀每個群組特徵,制定差異化行銷策略。",
      "keywords": [
        "聚類",
        "客戶分群",
        "K-Means",
        "非監督學習",
        "任務識別",
        "RFM分析"
      ],
      "reference": "L21301-數據準備與模型選擇.md - 任務類型識別與演算法選擇"
    },
    {
      "question_id": "L21301_005",
      "sequence": 89,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "面對資料缺失值,以下哪種處理方式最不適當?",
      "options": {
        "A": "若缺失率<5%且隨機缺失(MCAR),可刪除缺失樣本",
        "B": "對數值型特徵,使用中位數或均值插補",
        "C": "對所有缺失值都用0填補,不考慮特徵意義",
        "D": "使用模型預測缺失值(如KNN插補)"
      },
      "answer": "C",
      "explanation": "缺失值處理需根據缺失機制、比例、特徵類型選擇合適策略,選項C的做法最不適當。缺失值處理決策樹:(1)分析缺失機制:MCAR(完全隨機缺失)、MAR(隨機缺失)、MNAR(非隨機缺失);(2)根據缺失率決策:缺失率<5%且MCAR→刪除樣本(Listwise Deletion);5-20%→插補;>20%→考慮刪除特徵或收集更多資料;(3)插補策略選擇:數值型特徵→均值/中位數/回歸插補;類別型特徵→眾數/新增類別「missing」;時間序列→前向填充/插值;(4)進階方法:KNN插補(用最近鄰樣本),多重插補(MICE),深度學習生成模型。選項C的問題:(a)忽視特徵意義:年齡缺失填0不合理(0歲嬰兒?),應用均值/中位數;(b)引入偏差:對某些特徵,0可能是有意義的值(如購買次數=0表示未購買),缺失填0會混淆真實的0和缺失的0;(c)影響模型:0可能偏離特徵分布中心,導致模型學習錯誤模式。正確做法是針對不同特徵選擇合適的插補值(如年齡用中位數,類別用眾數或「Unknown」類別)。",
      "keywords": [
        "缺失值處理",
        "資料插補",
        "MCAR MAR MNAR",
        "KNN插補",
        "資料清理"
      ],
      "reference": "L21301-數據準備與模型選擇.md - 缺失值處理決策樹"
    },
    {
      "question_id": "L21301_006",
      "sequence": 90,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某醫療AI專案要預測患者30天內再入院風險,資料中僅5%患者實際再入院(正類),95%未再入院(負類)。這種類別不平衡問題應如何處理?",
      "options": {
        "A": "忽略不平衡,直接訓練模型",
        "B": "使用過採樣(SMOTE)增加正類樣本,或欠採樣減少負類樣本,並調整類別權重(Class Weight)",
        "C": "刪除所有負類樣本",
        "D": "改變問題定義,不處理不平衡"
      },
      "answer": "B",
      "explanation": "類別不平衡(Class Imbalance)是實務中常見問題,5:95的極端不平衡會導致模型偏向預測多數類(負類),召回率極低。處理策略:(1)重採樣技術:【過採樣(Over-sampling)】增加少數類樣本:SMOTE(Synthetic Minority Over-sampling Technique)合成新的少數類樣本,在特徵空間中插值生成;ADASYN(自適應合成)在難分類區域生成更多樣本;【欠採樣(Under-sampling)】減少多數類樣本:隨機欠採樣或Tomek Links去除邊界樣本;風險是丟失資訊。建議:先過採樣到1:10,再欠採樣到平衡;(2)演算法層面:調整類別權重(Class Weight):給少數類更高權重(如正類權重=19),懲罰模型誤分類少數類;使用對不平衡魯棒的演算法:XGBoost的scale_pos_weight參數;(3)評估指標:不用Accuracy(95%都預測負類,準確率也有95%但沒意義),使用Precision/Recall/F1/AUC-ROC;(4)異常檢測視角:若不平衡極端(1:1000+),視為異常檢測問題,使用One-Class SVM、Isolation Forest。選項A會導致模型無法識別正類;選項C丟失95%資料不可行;選項D逃避問題。",
      "keywords": [
        "類別不平衡",
        "SMOTE",
        "過採樣",
        "欠採樣",
        "Class Weight",
        "AUC-ROC",
        "醫療AI"
      ],
      "reference": "L21301-數據準備與模型選擇.md - 類別不平衡處理策略"
    },
    {
      "question_id": "L21301_007",
      "sequence": 91,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在模型選擇時,訓練集、驗證集、測試集的典型分割比例和各自用途為何?",
      "options": {
        "A": "訓練集100%,不需要其他集合",
        "B": "訓練集70%、驗證集15%、測試集15%;訓練用於學習參數,驗證用於調參和模型選擇,測試用於最終評估",
        "C": "訓練集、驗證集、測試集用途相同",
        "D": "隨機分配,沒有固定比例"
      },
      "answer": "B",
      "explanation": "資料集分割是機器學習的基礎實踐,確保模型評估的可靠性。三集合用途與分割:(1)訓練集(Training Set,通常70-80%):用於訓練模型,學習參數(如神經網路的權重),模型在此資料上學習模式;(2)驗證集(Validation Set,通常10-15%):用於超參數調整(如學習率、正則化係數)和模型選擇(如比較不同架構),防止在訓練集上過擬合,但不用於最終評估(因為調參過程會間接學習驗證集);(3)測試集(Test Set,通常10-15%):模型在整個開發過程中完全沒見過,僅在最終階段用於無偏評估泛化能力,模擬真實世界表現。典型比例:70:15:15或60:20:20,資料量大時可調整(如百萬級資料可用98:1:1)。關鍵原則:(a)三個集合必須完全獨立,無資料洩漏;(b)分層抽樣保持類別分布一致;(c)時間序列資料需按時間順序分割,避免未來資訊洩漏。如資料量小,可用K折交叉驗證(K-Fold CV)替代單一驗證集,更充分利用資料。",
      "keywords": [
        "資料集分割",
        "訓練集",
        "驗證集",
        "測試集",
        "超參數調整",
        "模型評估",
        "資料洩漏"
      ],
      "reference": "L21301-數據準備與模型選擇.md - 資料集分割與用途"
    },
    {
      "question_id": "L21301_008",
      "sequence": 92,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某線上廣告系統要預測使用者點擊率(CTR),特徵包含:用戶年齡、性別、地區、瀏覽歷史、廣告類別等。在特徵工程階段,以下哪種處理最合適?",
      "options": {
        "A": "直接使用原始特徵,不做任何處理",
        "B": "對數值特徵(年齡)進行標準化,對類別特徵(性別、地區、廣告類別)進行One-Hot編碼或Embedding,並構建交叉特徵(如用戶地區×廣告類別)",
        "C": "刪除所有類別特徵,僅保留數值特徵",
        "D": "將所有特徵轉為文字描述"
      },
      "answer": "B",
      "explanation": "CTR預測是典型的特徵工程密集型任務,需要精心處理各類特徵。最佳實踐:(1)數值特徵處理:年齡進行標準化或歸一化(Min-Max Scaling),讓不同量綱的特徵在同一尺度,避免大數值特徵主導;也可考慮分桶(Binning),如年齡分為18-25、26-35等區間,捕捉非線性關係;(2)類別特徵處理:【低基數類別】(如性別2個值):One-Hot編碼,轉為二進位向量[0,1]或[1,0];【高基數類別】(如地區可能有數百個城市):Embedding技術,將每個類別映射為低維稠密向量(如100維),在訓練中學習,能捕捉類別間相似性(如「北京」和「上海」的embedding向量接近);或Target Encoding(用該類別的平均CTR編碼,但需防止過擬合);(3)交叉特徵(Feature Crossing):構建高階特徵捕捉交互效應,如「用戶地區×廣告類別」能捕捉「北京用戶偏好科技類廣告」這種區域性偏好;常用二階交叉,必要時三階;可手動構建或使用深度學習自動學習(如DeepFM);(4)時間特徵:從時間戳提取小時、星期幾、是否週末等,捕捉時間模式。選項A忽視特徵工程會大幅降低效能;選項C丟失重要的類別資訊;選項D不符合ML輸入要求。",
      "keywords": [
        "特徵工程",
        "One-Hot編碼",
        "Embedding",
        "特徵交叉",
        "CTR預測",
        "類別特徵處理",
        "標準化"
      ],
      "reference": "L21301-數據準備與模型選擇.md - 特徵工程最佳實踐"
    },
    {
      "question_id": "L21301_009",
      "sequence": 93,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "交叉驗證(Cross-Validation)相較於單次訓練/測試分割的優勢為何?",
      "options": {
        "A": "訓練速度更快",
        "B": "更充分利用資料,減少評估的隨機性,得到更可靠的效能估計",
        "C": "模型準確率一定更高",
        "D": "不需要測試集"
      },
      "answer": "B",
      "explanation": "交叉驗證(Cross-Validation,CV)是更魯棒的模型評估方法,相較於單次分割的優勢:(1)充分利用資料:K折CV將資料分為K份,每份輪流作為驗證集,其餘作為訓練集,重複K次,每個樣本都被驗證一次,沒有資料浪費;單次分割的測試集(如15%)永遠不參與訓練,在資料量小時浪費;(2)減少隨機性:單次分割的效能受分割方式影響(運氣好分到簡單測試集,分數虛高;運氣差分到難樣本,分數虛低);K折CV取K次結果的平均和標準差,更穩定可靠,例如5折CV得到「準確率=85%±2%」比單次「87%」更有參考價值;(3)超參數調優:在網格搜索(Grid Search)中使用CV,避免在單一驗證集上過擬合超參數;(4)小資料集友好:當資料僅數百筆時,單次分割測試集太小不可靠,CV能最大化利用有限資料。常見變體:K折CV(K=5或10)、留一法(LOOCV,K=樣本數,計算量大)、分層K折(Stratified K-Fold,保持類別比例)、時間序列CV(Time Series CV,按時間順序)。缺點:計算成本高(K倍訓練時間),但用於模型選擇和評估非常值得。仍需獨立測試集做最終評估。",
      "keywords": [
        "交叉驗證",
        "K-Fold CV",
        "模型評估",
        "資料利用",
        "魯棒性",
        "超參數調優"
      ],
      "reference": "L21301-數據準備與模型選擇.md - 交叉驗證原理與優勢"
    },
    {
      "question_id": "L21301_010",
      "sequence": 94,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "hard",
      "question_type": "technical_principles",
      "question": "在資料洩漏(Data Leakage)問題中,以下哪個場景會造成洩漏,導致模型在訓練時表現優異但上線後崩潰?",
      "options": {
        "A": "在分割訓練/測試集之前,對整個資料集進行標準化(fit_transform on whole dataset)",
        "B": "在分割訓練/測試集之後,對訓練集fit標準化參數,再transform訓練集和測試集",
        "C": "使用時間序列資料時,按時間順序分割,訓練集用過去資料,測試集用未來資料",
        "D": "使用分層抽樣確保訓練/測試集的類別分布一致"
      },
      "answer": "A",
      "explanation": "資料洩漏是指測試集的資訊洩漏到訓練過程,導致模型評估過度樂觀,上線後表現遠低於預期。選項A是典型的洩漏案例:(1)錯誤做法:在分割前對全資料集fit_transform標準化,計算的均值和標準差包含了測試集資訊;訓練時模型間接學習到測試集的統計特性;例如測試集某特徵均值特別高,全資料集標準化會被這個高均值影響,訓練集的標準化參數因此「知道」了測試集資訊;(2)正確做法:先分割,再在訓練集上fit標準化器(計算均值、標準差),然後transform訓練集和測試集,測試集不參與統計參數計算;sklearn範例:scaler.fit(X_train)然後scaler.transform(X_train)和scaler.transform(X_test);(3)其他洩漏案例:用未來資訊預測過去(如用T+1天的股價預測T天);特徵包含目標變數的變形(如用「是否申請退款」預測「客戶流失」,但退款發生在流失之後);重複樣本出現在訓練和測試集(如同一用戶的多筆記錄);(4)時間序列特殊性:必須按時間順序分割,不能隨機分割,否則用未來預測過去。選項B是正確做法;選項C正確處理時間序列;選項D的分層抽樣不會造成洩漏。資料洩漏是實務中的隱形殺手,需格外警惕。",
      "keywords": [
        "資料洩漏",
        "Data Leakage",
        "標準化陷阱",
        "時間序列分割",
        "訓練測試隔離",
        "模型評估陷阱"
      ],
      "reference": "L21301-數據準備與模型選擇.md - 資料洩漏識別與防範"
    },
    {
      "question_id": "L21301_011",
      "sequence": 95,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某金融風控系統要整合多個模型(欺詐偵測、信用評分、異常交易)進行綜合風險評估,但發現三個模型使用不同的特徵工程pipeline和資料前處理邏輯,維護困難且存在資料不一致風險。應如何設計資料準備架構?",
      "options": {
        "A": "每個模型各自維護獨立的資料準備邏輯",
        "B": "建立統一的Feature Store:集中管理特徵定義、計算、儲存、版本控制,各模型從Feature Store取用標準化特徵",
        "C": "完全不做特徵工程,使用原始資料",
        "D": "隨機選擇一個模型的pipeline給其他模型使用"
      },
      "answer": "B",
      "explanation": "多模型場景下,Feature Store是解決特徵工程混亂的最佳架構實踐。Feature Store設計與優勢:(1)核心概念:Feature Store是集中式的特徵管理平台,統一定義、計算、儲存、服務特徵,類似資料的「超市」,模型按需取用;(2)架構組件:【特徵定義層】用宣告式語法定義特徵(如YAML/Python),例如「最近30天交易金額總和」,包含計算邏輯、資料來源、更新頻率;【特徵計算層】離線計算引擎(如Spark)批次計算歷史特徵,即時計算引擎(如Flink)計算實時特徵;【特徵儲存層】離線特徵存於資料倉庫(如BigQuery、Snowflake)供訓練使用,線上特徵存於低延遲資料庫(如Redis、Cassandra)供推理使用;【特徵服務層】提供API讓模型訓練和推理獲取特徵,確保訓練/服務一致性(Training-Serving Skew);【特徵監控層】追蹤特徵分布變化、資料品質、血緣關係(Lineage);(3)解決的問題:【特徵重用】「最近30天交易金額」可被欺詐偵測、信用評分、異常交易三個模型共用,定義一次、多處使用,避免重複開發;【一致性】確保訓練和推理使用完全相同的特徵邏輯,消除Training-Serving Skew(訓練時準確率90%,上線後70%的常見原因);【版本控制】特徵定義變更時自動版本化,模型可追溯使用的特徵版本,支援A/B測試;【監控與治理】集中監控特徵品質,發現資料漂移及時告警;(4)實現工具:開源Feast、Tecton,雲端AWS SageMaker Feature Store、GCP Vertex AI Feature Store。選項A導致重複開發和維護噩夢;選項C丟失領域知識;選項D強行統一會犧牲各模型的特殊需求。Feature Store是MLOps成熟度的重要標誌。",
      "keywords": [
        "Feature Store",
        "特徵工程架構",
        "Training-Serving Skew",
        "特徵重用",
        "多模型系統",
        "MLOps",
        "Feast"
      ],
      "reference": "L21301-數據準備與模型選擇.md - Feature Store架構與實踐"
    },
    {
      "question_id": "L21301_012",
      "sequence": 96,
      "topic": "L21301-數據準備與模型選擇",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某醫療AI系統使用多個資料來源(醫院EMR、實驗室系統、影像PACS),發現相同患者在不同系統的ID不一致,同一檢驗項目在不同醫院命名不同(如「白血球」vs「WBC」vs「White Blood Cell Count」)。在資料準備階段應如何處理這種資料整合挑戰?",
      "options": {
        "A": "忽略不一致,直接合併資料",
        "B": "建立資料治理框架:實施主資料管理(MDM)統一患者ID,建立醫學本體(Ontology)映射術語,使用ETL pipeline標準化資料格式,建立資料品質監控",
        "C": "僅使用單一資料來源",
        "D": "手動逐筆修改資料"
      },
      "answer": "B",
      "explanation": "醫療資料整合是極具挑戰的工程問題,需要系統性的資料治理方案。完整架構:(1)主資料管理(Master Data Management, MDM):【患者統一識別】建立患者主索引(Patient Master Index),將不同系統的患者ID映射到唯一的全局ID;使用決定性匹配(姓名+身份證號+生日完全匹配)和機率性匹配(模糊匹配,處理拼寫錯誤、缺失);建立黃金記錄(Golden Record)作為患者資料的權威來源;(2)醫學術語標準化:【本體映射】使用醫學標準本體如SNOMED CT、LOINC、ICD-10,將不同醫院的術語映射到標準編碼;例如「白血球」、「WBC」、「White Blood Cell Count」都映射到LOINC code「6690-2」;建立術語映射表(Terminology Mapping Table),定期維護更新;【單位標準化】確保檢驗結果單位一致(如血糖mmol/L vs mg/dL需換算);(3)ETL Pipeline:【Extract】從EMR、PACS、LIS等系統抽取資料;【Transform】清理、標準化、去識別化、術語映射、單位轉換、格式統一;【Load】載入到統一的資料湖或資料倉庫,符合FHIR標準;(4)資料品質管理:建立資料品質規則(如年齡0-120歲、體溫35-42°C),自動檢測異常;定期稽核資料完整性、準確性、一致性、及時性;【血緣追蹤】記錄每筆資料的來源系統、轉換歷程,確保可追溯性;(5)隱私合規:去識別化處理(移除姓名、ID、地址等18種HIPAA識別符),使用加密和存取控制;【法規遵循】符合HIPAA、GDPR等法規要求。這種架構確保:(a)資料品質:統一標準、可信資料源;(b)可擴展性:新增資料來源時使用標準化流程;(c)合規性:隱私保護、稽核追蹤。選項A會導致模型訓練在混亂資料上失敗;選項C丟失多來源資訊的價值;選項D不可擴展。這是醫療AI成功的基礎工程。",
      "keywords": [
        "資料治理",
        "MDM",
        "主資料管理",
        "醫學本體",
        "SNOMED",
        "LOINC",
        "FHIR",
        "ETL",
        "醫療資料整合",
        "去識別化"
      ],
      "reference": "L21301-數據準備與模型選擇.md - 醫療資料治理與整合架構"
    },
    {
      "question_id": "L21302_001",
      "sequence": 97,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "容器化技術(如Docker)在AI模型部署中的主要優勢為何?",
      "options": {
        "A": "提高模型準確率",
        "B": "封裝應用及其依賴環境,確保跨環境一致性,簡化部署",
        "C": "加快模型訓練速度",
        "D": "自動標註訓練資料"
      },
      "answer": "B",
      "explanation": "容器化(Containerization)是現代AI部署的核心技術,Docker是最流行的容器平台。主要優勢:(1)環境一致性:將模型、程式碼、依賴(Python版本、套件、系統函式庫)打包成容器映像檔,確保在開發、測試、生產環境執行結果完全一致,解決「在我電腦上可以跑」問題;(2)簡化部署:一個docker run命令即可啟動服務,不需在目標機器手動安裝Python、TensorFlow等依賴;(3)隔離性:每個容器獨立運行,互不干擾,可在同一主機運行多個模型服務不衝突;(4)可移植性:容器可在任何支援Docker的平台運行(本地、雲端、Kubernetes),不綁定特定基礎設施;(5)版本控制:容器映像檔可版本化(如model:v1.2.3),方便回滾和A/B測試。Docker不影響模型準確率或訓練速度,也不涉及資料標註。典型流程:Dockerfile定義環境→build映像檔→push到Registry→pull並run部署。",
      "keywords": [
        "Docker",
        "容器化",
        "環境一致性",
        "模型部署",
        "隔離性",
        "可移植性"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - Docker容器化優勢"
    },
    {
      "question_id": "L21302_002",
      "sequence": 98,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "藍綠部署(Blue-Green Deployment)的核心概念是什麼?",
      "options": {
        "A": "同時運行兩個完全相同的生產環境(藍和綠),新版本部署到閒置環境,測試通過後切換流量",
        "B": "將伺服器塗成藍色和綠色",
        "C": "只在夜間部署新版本",
        "D": "隨機選擇伺服器進行部署"
      },
      "answer": "A",
      "explanation": "藍綠部署是零停機部署(Zero-Downtime Deployment)的經典策略,特別適合需要高可用性的AI服務。核心機制:(1)雙環境設置:維護兩套完全相同的生產環境,假設藍環境(Blue)當前服務用戶流量,綠環境(Green)閒置;(2)部署流程:將新版本模型部署到綠環境,在綠環境進行完整測試(功能測試、效能測試、A/B測試),確認新版本穩定後,將負載均衡器的流量從藍切換到綠(通常是瞬間切換或逐步切換);(3)快速回滾:若新版本出現問題,立即將流量切回藍環境,實現秒級回滾,最小化影響;(4)優勢:零停機時間,用戶無感知;降低部署風險,新版本經過充分測試;快速回滾能力,錯誤影響可控;(5)成本:需要雙倍基礎設施資源(但切換後舊環境可用於下次部署)。變體:可與金絲雀部署結合,先導5%流量到綠環境,確認無誤後再全量切換。藍綠部署是MLOps成熟度的重要指標。",
      "keywords": [
        "藍綠部署",
        "Blue-Green Deployment",
        "零停機部署",
        "快速回滾",
        "高可用性"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - 藍綠部署策略"
    },
    {
      "question_id": "L21302_003",
      "sequence": 99,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "金絲雀部署(Canary Deployment)相較於藍綠部署的主要差異為何?",
      "options": {
        "A": "金絲雀部署是逐步將小比例流量導向新版本,監控指標,確認無誤後逐步擴大;藍綠部署是瞬間切換全部流量",
        "B": "兩者完全相同",
        "C": "金絲雀部署只能在白天執行",
        "D": "金絲雀部署不需要監控"
      },
      "answer": "A",
      "explanation": "金絲雀部署(Canary Deployment)是更保守、更漸進的部署策略,名稱源自礦工用金絲雀偵測瓦斯的做法。核心差異:(1)流量分配:【金絲雀】逐步灰度:5% → 10% → 25% → 50% → 100%,每個階段監控一段時間(如30分鐘到數小時);【藍綠】直接切換:0% → 100%(或先切5%快速驗證後立即切100%);(2)風險控制:【金絲雀】錯誤影響範圍小,即使新版本有bug也只影響5%用戶,可快速偵測並回滾;【藍綠】若新版本有隱藏bug,切換後立即影響100%用戶;(3)監控要求:【金絲雀】需要精細監控指標(錯誤率、延遲、業務KPI),對比新舊版本,設定自動回滾閾值;【藍綠】也需監控但時間窗口較短;(4)部署時間:【金絲雀】較長(數小時到數天),逐步驗證;【藍綠】較短(數分鐘),快速切換;(5)基礎設施:【金絲雀】可與舊版本共用資源,節省成本;【藍綠】需要雙倍資源。選擇建議:高風險變更(如演算法大改)用金絲雀,低風險變更或緊急修復用藍綠。實務常結合:先藍綠切5%,再金絲雀逐步擴大。",
      "keywords": [
        "金絲雀部署",
        "Canary Deployment",
        "灰度發布",
        "漸進式部署",
        "風險控制",
        "A/B測試"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - 金絲雀部署策略"
    },
    {
      "question_id": "L21302_004",
      "sequence": 100,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "simple",
      "question_type": "technical_selection",
      "question": "某AI推薦系統需要部署到生產環境,預期每秒1000次推理請求(QPS=1000)。在系統整合測試的優先順序排序中,以下哪個最關鍵?",
      "options": {
        "A": "UI介面美觀度測試",
        "B": "效能測試(壓力測試、延遲測試)確保系統能承受QPS=1000並滿足延遲要求",
        "C": "程式碼註釋完整性檢查",
        "D": "開發團隊技能培訓"
      },
      "answer": "B",
      "explanation": "系統整合測試優先順序應以業務關鍵需求和風險為導向,高QPS場景下效能測試最關鍵。測試優先級:(1)【最高優先】效能測試:【壓力測試(Load Testing)】模擬QPS=1000甚至更高(如1500,留30%餘量),驗證系統吞吐量是否達標,識別瓶頸(CPU、記憶體、GPU、網路、資料庫);【延遲測試(Latency Testing)】測試P50、P95、P99延遲,確保滿足SLA(如P95<100ms);【持久性測試(Soak Testing)】長時間運行(如24小時)確保無記憶體洩漏或效能衰減;效能不達標會直接導致用戶體驗差或系統崩潰,必須優先;(2)【高優先】功能正確性測試:整合測試確保模型推理結果正確,API輸入輸出符合規格;端到端測試模擬真實用戶流程;(3)【高優先】可靠性測試:故障注入(Chaos Engineering)測試系統容錯能力;災難恢復測試驗證備份恢復流程;(4)【中優先】安全測試:API認證授權、SQL注入、XSS等安全漏洞掃描;(5)【低優先】UI美觀、程式碼品質(這些重要但不影響系統能否上線)。測試金字塔:大量單元測試(快速、低成本)→適量整合測試→少量端到端測試。選項B的效能測試直接關係系統能否承載業務量,是上線前的必要條件。",
      "keywords": [
        "系統整合測試",
        "效能測試",
        "壓力測試",
        "延遲測試",
        "QPS",
        "測試優先級",
        "SLA"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - 系統整合測試優先級"
    },
    {
      "question_id": "L21302_005",
      "sequence": 101,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "MLOps CI/CD pipeline中,CI(Continuous Integration)和CD(Continuous Deployment)分別指什麼?",
      "options": {
        "A": "CI是持續集成程式碼並自動測試,CD是持續部署到生產環境",
        "B": "CI是人工審查程式碼,CD是手動部署",
        "C": "CI和CD是相同的概念",
        "D": "CI是資料清理,CD是模型訓練"
      },
      "answer": "A",
      "explanation": "CI/CD是DevOps的核心實踐,在MLOps中有特殊擴展。定義與流程:(1)CI(Continuous Integration,持續集成):【傳統軟體】開發者頻繁(每天多次)將程式碼合併到主分支,每次合併觸發自動化構建和測試,快速發現整合問題;【MLOps擴展】不僅集成程式碼,還包括資料驗證(schema檢查、分布驗證)、模型訓練pipeline、模型驗證(準確率、公平性、可解釋性測試);工具:Jenkins、GitLab CI、GitHub Actions;(2)CD(Continuous Deployment,持續部署):【Continuous Delivery】自動化部署到預生產環境,但需人工批准才部署到生產;【Continuous Deployment】更進一步,自動化部署到生產,無需人工干預;【MLOps擴展】包括模型打包(容器化)、模型註冊(Model Registry)、A/B測試配置、監控設置、自動回滾機制;(3)MLOps Pipeline範例:git push觸發→CI階段(lint、單元測試、資料驗證、模型訓練、模型評估)→若通過→CD階段(打包Docker、部署到Staging、整合測試)→人工批准或自動判斷→部署到Production→監控;(4)優勢:加速發布週期(從數週縮短到數天甚至數小時),降低人為錯誤,提高品質(自動測試),快速反饋。選項A正確概括了CI/CD核心,選項B的人工流程違背自動化精神,選項C錯誤,選項D混淆了概念。",
      "keywords": [
        "MLOps",
        "CI/CD",
        "持續集成",
        "持續部署",
        "自動化",
        "DevOps",
        "Pipeline"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - MLOps CI/CD Pipeline"
    },
    {
      "question_id": "L21302_006",
      "sequence": 102,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某AI服務部署後發現推理延遲過高(P95延遲=500ms,目標<100ms)。經分析,模型本身推理僅需20ms,瓶頸在模型載入和預處理。應採取哪種優化策略?",
      "options": {
        "A": "重新訓練模型",
        "B": "實施模型預載入(服務啟動時載入模型到記憶體)、批次推理(Batching)、預處理快取,並考慮模型量化減小模型尺寸",
        "C": "增加資料量",
        "D": "放棄部署"
      },
      "answer": "B",
      "explanation": "推理延遲優化需要系統性分析瓶頸並採取多層次策略。本案例的優化方案:(1)模型預載入(Preloading):【問題】每次請求都載入模型會耗時數百ms;【方案】服務啟動時一次性載入模型到記憶體(GPU或CPU),請求來時直接推理;【實現】使用全域變數或單例模式持有模型實例;(2)批次推理(Batching):【問題】逐個處理請求無法充分利用GPU平行能力;【方案】收集一小批請求(如10-50個,等待時間<10ms),批次送入模型推理,GPU吞吐量可提升5-10倍;【實現】使用TensorFlow Serving的batch配置或NVIDIA Triton Inference Server;(3)預處理優化:【問題】每次請求重複計算預處理(如圖像resize、標準化);【方案】快取常見輸入的預處理結果(如用Redis快取),對預處理pipeline進行編譯優化(如用TorchScript、ONNX);(4)模型量化(Quantization):【問題】大模型載入慢、推理慢;【方案】將模型從FP32量化到INT8或FP16,模型尺寸減小4倍,推理速度提升2-4倍,延遲降低;【工具】TensorRT、ONNX Runtime、PyTorch Quantization;(5)模型壓縮:剪枝(Pruning)移除不重要權重,知識蒸餾(Distillation)用小模型模仿大模型;(6)硬體加速:使用GPU、TPU或專用AI晶片(如AWS Inferentia)。綜合這些策略,可將P95延遲從500ms降至<50ms。選項A重訓模型無法解決系統瓶頸;選項C增加資料與推理延遲無關;選項D放棄不可接受。這是典型的系統整合優化題,需全面考量。",
      "keywords": [
        "推理延遲優化",
        "批次推理",
        "模型預載入",
        "量化",
        "模型壓縮",
        "效能調優",
        "TensorRT"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - 推理效能優化策略"
    },
    {
      "question_id": "L21302_007",
      "sequence": 103,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某公司要在Kubernetes(K8s)上部署多個AI模型服務,需要根據流量自動擴縮容(Auto-scaling)。應配置什麼機制?",
      "options": {
        "A": "手動調整Pod數量",
        "B": "配置Horizontal Pod Autoscaler(HPA)基於CPU/記憶體使用率或自定義指標(如QPS)自動調整Pod副本數",
        "C": "固定Pod數量不變",
        "D": "隨機增減Pod"
      },
      "answer": "B",
      "explanation": "Kubernetes的自動擴縮容是雲原生AI部署的關鍵能力,確保資源效率和服務可用性。HPA機制與配置:(1)Horizontal Pod Autoscaler(HPA):【原理】根據監控指標動態調整Pod副本數(水平擴縮),流量高時增加Pod,流量低時減少Pod,保持資源利用率在目標範圍;【核心指標】CPU使用率(如目標70%,低於50%縮容,高於80%擴容),記憶體使用率,自定義指標(如QPS、推理延遲、GPU使用率);【配置範例】最小副本數=2(保證高可用),最大副本數=20(避免成本失控),目標CPU=70%;【擴縮容策略】擴容快速(檢測到高負載後30秒內擴容),縮容保守(持續低負載5分鐘後才縮容,避免抖動);(2)垂直擴縮(Vertical Pod Autoscaler, VPA):調整單個Pod的CPU/記憶體配額,適合無法水平擴展的場景;(3)Cluster Autoscaler:當Pod資源不足時,自動增加K8s節點(VM),實現集群層級擴縮;(4)AI場景特殊考量:【GPU資源】配置GPU節點池,HPA需考慮GPU可用性;【冷啟動】模型載入可能需要數十秒,需預留足夠warmup時間或使用Model Warm Pool;【有狀態服務】若服務需保持連接狀態(如WebSocket),需配置會話親和性(Session Affinity)。實務配置:結合HPA(應對流量波動)和Cluster Autoscaler(應對大規模增長),設置合理的擴縮容閾值和速率,監控擴縮容行為並調優。選項A手動不可行,選項C浪費資源或無法應對流量,選項D隨機會導致服務不穩定。",
      "keywords": [
        "Kubernetes",
        "HPA",
        "自動擴縮容",
        "Auto-scaling",
        "雲原生",
        "資源管理",
        "GPU調度"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - Kubernetes自動擴縮容"
    },
    {
      "question_id": "L21302_008",
      "sequence": 104,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "微服務架構(Microservices)相較於單體架構(Monolithic)在AI系統中的主要優勢和挑戰為何?",
      "options": {
        "A": "微服務沒有任何優勢,僅增加複雜度",
        "B": "微服務優勢:獨立部署、技術異構、可擴展性;挑戰:服務間通訊開銷、分散式追蹤複雜、資料一致性",
        "C": "微服務和單體架構完全相同",
        "D": "微服務只適合小型專案"
      },
      "answer": "B",
      "explanation": "微服務架構是大型AI系統的主流選擇,但需要權衡優劣。優勢與挑戰分析:(1)優勢:【獨立部署】每個服務(如資料預處理服務、模型推理服務、後處理服務)可獨立開發、測試、部署,不影響其他服務;模型更新時只需重新部署推理服務,前後端服務不受影響;【技術異構】不同服務可用不同技術棧,如推理服務用Python+TensorFlow,資料處理用Java+Spark,前端用Node.js,選擇最適合的工具;【可擴展性】高負載服務可獨立擴展,如推理服務擴展到10個實例,其他服務保持2個實例,資源利用效率高;【故障隔離】一個服務故障不會導致整個系統崩潰,如特徵工程服務當機,可降級為使用快取特徵;【團隊自主】不同團隊負責不同服務,減少協調成本,加快開發速度;(2)挑戰:【服務間通訊】微服務需透過網路調用(REST API、gRPC),增加延遲(數ms到數十ms)和複雜度;需處理網路故障、超時、重試;【分散式追蹤】一個請求可能經過10個服務,問題排查困難,需要分散式追蹤系統(如Jaeger、Zipkin)記錄請求鏈路;【資料一致性】服務間共用資料時,維護一致性困難,需使用最終一致性或分散式事務(Saga);【運維複雜度】管理數十個服務比單一應用複雜,需要容器編排(K8s)、服務網格(Istio)、集中式日誌(ELK);【測試複雜】整合測試需要啟動多個服務,契約測試(Contract Testing)確保服務介面相容。選擇建議:小型專案(<5人團隊)用單體架構簡單快速;大型專案(10+服務、多團隊)用微服務提升靈活性;中型專案可採用模組化單體(Modular Monolith)作為過渡。AI系統常見微服務劃分:API Gateway→特徵服務→模型推理服務→後處理服務→監控服務。",
      "keywords": [
        "微服務架構",
        "Microservices",
        "單體架構",
        "獨立部署",
        "可擴展性",
        "分散式系統",
        "服務網格"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - 微服務架構優勢與挑戰"
    },
    {
      "question_id": "L21302_009",
      "sequence": 105,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某AI服務需要在邊緣裝置(如Raspberry Pi、手機)上部署模型進行即時推理,但原模型尺寸500MB,無法裝入裝置記憶體。應採取什麼策略?",
      "options": {
        "A": "放棄邊緣部署,僅使用雲端推理",
        "B": "結合模型壓縮(量化、剪枝、蒸餾)、使用輕量級模型(MobileNet、EfficientNet)、轉換為邊緣優化格式(TensorFlow Lite、ONNX)",
        "C": "強制將大模型塞入裝置",
        "D": "購買更大記憶體的裝置"
      },
      "answer": "B",
      "explanation": "邊緣部署(Edge Deployment)面臨嚴格的資源約束,需要模型優化和格式轉換。綜合策略:(1)模型壓縮技術:【量化(Quantization)】從FP32降為INT8甚至INT4,模型尺寸減小4-8倍(500MB→62-125MB),推理速度提升2-4倍,準確率損失<1-2%;工具:TensorFlow Lite、PyTorch Mobile、ONNX Runtime;【剪枝(Pruning)】移除不重要的權重和神經元,減小模型尺寸30-50%,需重新訓練恢復準確率;結構化剪枝可移除整個通道或層;【知識蒸餾(Distillation)】訓練小模型(student)模仿大模型(teacher),500MB模型蒸餾為50MB,保持90-95%準確率;(2)輕量級模型架構:直接使用專為邊緣設計的模型:MobileNet(圖像分類,4MB),EfficientNet(精度和效率平衡),TinyBERT(NLP,僅14MB);使用Neural Architecture Search(NAS)為目標裝置定制模型;(3)邊緣優化格式:【TensorFlow Lite】Google邊緣推理框架,支援量化和硬體加速(GPU、DSP、NPU);【ONNX】跨框架格式,可在ONNX Runtime上高效推理;【Core ML】蘋果生態系統優化格式;(4)混合部署:輕量級模型在邊緣做初步推理(如人臉偵測),複雜任務傳雲端處理(如人臉辨識),平衡延遲、準確率、成本;(5)硬體加速:利用裝置的AI加速器(如Google Coral TPU、Qualcomm Hexagon DSP),推理速度提升10-100倍。綜合應用,可將500MB模型壓縮至20-50MB,滿足邊緣部署需求。選項A放棄邊緣失去離線、低延遲、隱私優勢;選項C技術上不可行;選項D成本高且不可擴展。",
      "keywords": [
        "邊緣部署",
        "模型壓縮",
        "TensorFlow Lite",
        "MobileNet",
        "量化",
        "知識蒸餾",
        "Edge AI"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - 邊緣部署模型優化"
    },
    {
      "question_id": "L21302_010",
      "sequence": 106,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在模型版本管理中,Model Registry的主要功能為何?",
      "options": {
        "A": "僅儲存模型檔案",
        "B": "集中管理模型的版本、元資料、血緣、階段(Staging/Production),支援模型發現、審批、部署、回滾",
        "C": "訓練模型",
        "D": "標註資料"
      },
      "answer": "B",
      "explanation": "Model Registry是MLOps的核心組件,類似程式碼的Git,但針對模型的特殊需求設計。核心功能:(1)版本管理:每次訓練產生新模型版本(如v1.0.0、v1.0.1),自動遞增版本號;記錄每個版本的建立時間、訓練者、commit hash;支援語義化版本(Semantic Versioning):主版本.次版本.修訂版本;(2)元資料管理:記錄模型超參數(學習率、批次大小)、訓練指標(準確率、F1)、訓練資料集版本、框架版本(TensorFlow 2.10);儲存模型評估報告、混淆矩陣、特徵重要性;(3)血緣追蹤(Lineage):追蹤模型的完整譜系:訓練資料→特徵工程→訓練pipeline→模型;實現端到端可追溯性,符合監管要求(如GDPR的「解釋權」);(4)階段管理:模型生命週期階段:None(實驗中)→Staging(準備部署,正在測試)→Production(生產環境)→Archived(已退役);階段轉換需要審批流程,確保品質閘門;(5)模型發現與搜索:團隊成員可搜索「準確率>90%的客戶流失預測模型」,避免重複訓練;標籤和描述幫助模型重用;(6)部署整合:一鍵部署Production階段模型到Kubernetes;自動生成部署配置(Docker image、serving config);(7)回滾支援:Production模型出問題時,快速回滾到前一版本;A/B測試比較不同版本效能。工具:MLflow Model Registry、AWS SageMaker Model Registry、Google Vertex AI Model Registry。Model Registry將模型視為一等公民,是MLOps成熟度的標誌。",
      "keywords": [
        "Model Registry",
        "模型版本管理",
        "MLOps",
        "血緣追蹤",
        "模型階段",
        "MLflow"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - Model Registry功能"
    },
    {
      "question_id": "L21302_011",
      "sequence": 107,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某全球電商平台要部署AI推薦系統到多個區域(美國、歐洲、亞洲),需要符合各地法規(如GDPR、CCPA)、處理跨區域延遲、確保資料本地化。應設計什麼部署架構?",
      "options": {
        "A": "單一全球部署在美國,所有區域共用",
        "B": "多區域部署(Multi-Region Deployment):各區域獨立部署模型服務和資料儲存,實現資料本地化;全球統一的Model Registry和CI/CD;區域間災難恢復",
        "C": "完全不考慮法規要求",
        "D": "隨機部署"
      },
      "answer": "B",
      "explanation": "跨區域AI系統部署是複雜的系統工程,需要平衡法規、效能、成本。完整架構設計:(1)多區域部署架構:【資料本地化】每個區域(US、EU、APAC)獨立部署:(a)推理服務叢集(Kubernetes);(b)特徵儲存(Feature Store本地副本);(c)使用者資料儲存(符合GDPR要求,EU資料不出境);【路由策略】全球負載均衡器(如AWS Route53、Cloudflare)根據使用者地理位置路由到最近區域,降低延遲(跨區延遲200ms→同區域20ms);(2)全球統一治理:【Model Registry】全球統一的模型倉庫,但模型製品(artifact)複製到各區域;新模型v2.0發布到全球Registry,各區域Pull部署;【CI/CD Pipeline】統一的訓練和部署pipeline,確保各區域模型版本一致;但允許區域特定配置(如EU區域使用更嚴格的隱私保護模型);【監控與日誌】集中式監控dashboard(如Grafana)聚合各區域指標,但原始日誌本地儲存符合法規;(3)法規遵循:【GDPR(歐盟)】資料最小化,明確同意,提供資料下載和刪除,影響評估(DPIA);模型不使用敏感個資(如種族、健康),或使用聯邦學習;【CCPA(加州)】使用者可選擇退出資料銷售,提供資料透明度;【資料殘留(Data Residency)】確保EU使用者資料僅存於EU區域資料中心,不跨境傳輸;(4)災難恢復:各區域互為備援,EU區域故障時暫時由US區域服務(但僅限非個資功能);定期演練跨區域故障切換(Failover);(5)模型訓練策略:【集中訓練】在單一區域(如US)用全球去識別化資料訓練全球模型,分發到各區域;【聯邦學習】若無法集中資料,各區域本地訓練,聚合模型參數,保護隱私;【區域微調】全球模型作為base,各區域用本地資料微調適應當地偏好(如歐洲偏好環保產品)。這種架構確保:(a)合規:滿足各地法規;(b)低延遲:本地服務;(c)高可用:區域冗餘;(d)一致性:全球統一模型版本。選項A違反GDPR資料本地化;選項C法律風險;選項D不可行。",
      "keywords": [
        "多區域部署",
        "GDPR",
        "資料本地化",
        "跨境合規",
        "全球架構",
        "災難恢復",
        "聯邦學習"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - 多區域部署架構與合規"
    },
    {
      "question_id": "L21302_012",
      "sequence": 108,
      "topic": "L21302-AI技術系統集成與部署",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某金融AI信用評分系統需要整合到核心銀行系統(遺留系統,Mainframe COBOL),同時提供REST API給行動App。系統要求99.99%可用性、<50ms延遲、符合金融監管(可追溯性、可解釋性)。應設計什麼整合架構?",
      "options": {
        "A": "直接在Mainframe上運行AI模型",
        "B": "設計混合整合架構:AI推理服務獨立部署(Kubernetes)、透過Enterprise Service Bus(ESB)與Mainframe整合、提供REST API給App、實施全鏈路監控與審計日誌、可解釋性模組",
        "C": "完全重寫核心銀行系統",
        "D": "不整合,獨立運作"
      },
      "answer": "B",
      "explanation": "金融遺留系統整合AI是極具挑戰的工程,需要平衡新舊技術、滿足嚴格的金融監管。完整架構設計:(1)整合架構層:【AI推理服務】獨立部署在雲端/混合雲Kubernetes:高可用配置(多副本、跨可用區);模型服務(TensorFlow Serving或自建FastAPI);快取層(Redis)儲存常見請求結果,降低延遲;【Enterprise Service Bus(ESB)】作為Mainframe和現代服務的橋樑:協議轉換(Mainframe的MQ Series→REST/gRPC);訊息路由與編排;錯誤處理與重試;【API Gateway】統一入口給行動App:認證授權(OAuth 2.0、JWT);限流(Rate Limiting)保護後端;請求聚合(Aggregation)減少往返;【資料同步】Mainframe客戶主資料異步同步到推理服務資料庫(PostgreSQL);使用Change Data Capture(CDC)或定時批次同步;(2)高可用性設計(99.99%):【多副本部署】推理服務至少3個副本,跨可用區;【負載均衡】L7負載均衡器(如Nginx、Envoy)分散請求;【健康檢查】每5秒檢查服務健康,不健康實例自動下線;【熔斷器(Circuit Breaker)】Mainframe回應慢時啟動熔斷,使用降級策略(如返回快取結果或預設分數);【災難恢復】主備資料中心,RTO<5分鐘;(3)低延遲優化(<50ms):【模型優化】量化、快取預處理、批次推理;【資料快取】Redis快取特徵和預測結果,TTL=5分鐘;【非同步處理】非即時需求使用非同步調用,提升吞吐量;【就近部署】API Gateway和推理服務部署在同一VPC,減少網路延遲;(4)金融監管合規:【可追溯性】全鏈路追蹤(Jaeger)記錄每個請求的完整路徑;審計日誌記錄所有信用評分請求(who, when, what, why),保留7年;【可解釋性】整合SHAP/LIME模組,每次評分生成解釋報告(如「拒絕原因:收入過低佔60%、負債比過高佔30%」);【模型治理】Model Registry記錄使用的模型版本,定期審查模型公平性和歧視性;【資料保護】加密傳輸(TLS 1.3)、加密儲存、資料遮罩、最小權限存取;(5)整合流程範例:行動App請求→API Gateway認證→推理服務查詢Redis快取→未命中則調用模型推理→透過ESB查詢Mainframe補充資料→綜合評分→記錄審計日誌→返回結果+解釋→全鏈路追蹤記錄。這種架構確保:(a)遺留系統保護:不修改Mainframe核心邏輯;(b)現代化能力:AI、API、監控;(c)合規:可追溯、可解釋、安全;(d)高可用低延遲:滿足SLA。選項A技術上不可行(Mainframe不支援TensorFlow);選項C重寫成本極高風險大;選項D無法實現業務價值。",
      "keywords": [
        "遺留系統整合",
        "ESB",
        "高可用性",
        "金融監管",
        "可追溯性",
        "可解釋性",
        "API Gateway",
        "混合雲"
      ],
      "reference": "L21302-AI技術系統集成與部署.md - 遺留系統AI整合架構"
    },
    {
      "question_id": "L21303_001",
      "sequence": 109,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在AI模型上線後的監控中,「模型漂移(Model Drift)」指的是什麼現象?",
      "options": {
        "A": "模型檔案在硬碟中的位置改變",
        "B": "模型效能隨時間衰退,因為輸入資料分布或目標變數關係發生變化",
        "C": "模型訓練速度變慢",
        "D": "模型檔案大小增加"
      },
      "answer": "B",
      "explanation": "模型漂移(Model Drift)是生產環境AI系統的核心挑戰,影響模型長期效能。定義與類型:(1)定義:模型在訓練時的假設與生產環境的實際情況產生偏離,導致預測品質下降;(2)兩種主要漂移:【資料漂移(Data Drift)】輸入資料的分布發生變化,例如訓練時客戶平均年齡40歲,上線後實際使用者平均25歲;特徵統計特性改變(均值、標準差、分位數);檢測方法:KL散度、KS檢定、Population Stability Index(PSI);【概念漂移(Concept Drift)】輸入與輸出的關係發生變化,例如經濟衰退導致原本「收入高→信用好」的關係弱化;目標變數分布改變;檢測:監控模型準確率、AUC等指標下降;(3)漂移原因:環境變化(疫情改變消費習慣)、季節性(聖誕節購物模式)、對手策略(欺詐者適應檢測系統)、資料收集變化(新增資料來源);(4)影響:模型準確率從90%降至70%,業務價值大幅下降;可能產生錯誤決策(拒絕優質客戶、批准高風險貸款)。模型漂移是不可避免的,需要持續監控和定期再訓練。",
      "keywords": [
        "模型漂移",
        "Model Drift",
        "資料漂移",
        "概念漂移",
        "模型監控",
        "PSI"
      ],
      "reference": "AI系統維運最佳實踐 - 模型漂移監控"
    },
    {
      "question_id": "L21303_002",
      "sequence": 110,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在MLOps實踐中,模型監控應包含哪些關鍵指標?",
      "options": {
        "A": "僅監控模型準確率",
        "B": "模型效能指標(準確率、AUC、F1)、資料品質指標(缺失率、異常值)、系統效能指標(延遲、吞吐量)、業務指標(轉換率、收益)",
        "C": "僅監控伺服器CPU使用率",
        "D": "不需要任何監控"
      },
      "answer": "B",
      "explanation": "AI系統監控需要多維度指標體系,全面掌握系統健康狀況。四大監控維度:(1)模型效能指標(Model Performance):【線上指標】準確率、Precision/Recall、AUC-ROC、F1 Score;【漂移檢測】PSI(Population Stability Index)、KS統計量、分布距離;【信心分數】模型預測的信心度分布(高信心預測比例下降可能表示漂移);【錯誤分析】Top錯誤類型、混淆矩陣變化;(2)資料品質指標(Data Quality):【完整性】缺失值比例、NULL值數量;【準確性】異常值檢測(如年齡>150歲)、範圍檢查;【一致性】特徵分布變化(與訓練集對比);【及時性】資料新鮮度、延遲;(3)系統效能指標(System Performance):【延遲】P50/P95/P99推理延遲、端到端延遲;【吞吐量】QPS(Queries Per Second)、成功率;【資源使用】CPU、記憶體、GPU使用率;【可用性】Uptime、錯誤率、SLA達成率;(4)業務指標(Business Metrics):【業務KPI】推薦系統的點擊率(CTR)、轉換率、收益;【使用者體驗】回應時間、使用者滿意度;【成本】推理成本、基礎設施成本。監控策略:設定告警閾值(如準確率<85%告警)、建立儀表板(Grafana)即時呈現、定期生成報告、異常自動通知。僅監控單一維度會遺漏問題,例如準確率正常但延遲飆高會影響用戶體驗,業務指標下降可能是模型漂移的早期信號。",
      "keywords": [
        "模型監控",
        "監控指標",
        "MLOps",
        "資料品質",
        "系統效能",
        "業務指標",
        "告警"
      ],
      "reference": "MLOps監控最佳實踐 - 多維度指標體系"
    },
    {
      "question_id": "L21303_003",
      "sequence": 111,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "simple",
      "question_type": "technical_selection",
      "question": "某推薦系統監控發現模型準確率從85%降至75%,經分析是資料漂移導致。應採取什麼行動?",
      "options": {
        "A": "忽略問題,繼續使用舊模型",
        "B": "使用最新資料重新訓練模型(Retraining),驗證效能恢復後部署新版本",
        "C": "關閉整個系統",
        "D": "增加伺服器數量"
      },
      "answer": "B",
      "explanation": "模型效能衰退時,模型再訓練(Retraining)是標準應對措施,恢復模型與當前資料分布的對齊。再訓練流程:(1)觸發條件:準確率下降超過閾值(如從85%降至75%,下降>10%);資料漂移檢測指標超標(如PSI>0.25);業務指標惡化(如推薦點擊率下降20%);定期再訓練(如每月一次,即使沒漂移);(2)再訓練流程:【資料收集】收集最新生產資料(如最近3個月),包含真實標籤(ground truth);【資料準備】清理、標註、特徵工程,確保與原pipeline一致;【模型訓練】使用原架構或優化架構,訓練新模型;【離線驗證】在保留集上評估新模型效能,確認準確率恢復到目標(如>83%);【A/B測試】將5-10%流量導向新模型,對比舊模型效能;【全量部署】確認新模型效能優於舊模型後,逐步擴大到100%;【監控】密切監控新模型上線後表現;(3)自動化再訓練:建立自動化pipeline:監控系統偵測漂移→自動觸發訓練→自動驗證→通知人工審批→自動部署;頻率設定:高動態場景(如欺詐檢測)每週再訓練,穩定場景(如圖像分類)每季再訓練;(4)持續學習(Continual Learning):進階做法是線上學習,模型持續從新資料增量學習,但需防止災難性遺忘(Catastrophic Forgetting)。選項A忽略會持續惡化;選項C過度反應損失業務;選項D增加伺服器無法解決模型品質問題。再訓練是維運的核心能力。",
      "keywords": [
        "模型再訓練",
        "Retraining",
        "模型維運",
        "漂移應對",
        "持續學習",
        "自動化MLOps"
      ],
      "reference": "AI模型維運 - 再訓練策略與自動化"
    },
    {
      "question_id": "L21303_004",
      "sequence": 112,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "simple",
      "question_type": "technical_principles",
      "question": "在AI系統的日誌管理中,集中式日誌(Centralized Logging)相較於分散式日誌的主要優勢為何?",
      "options": {
        "A": "日誌檔案更小",
        "B": "統一收集、儲存、查詢所有服務的日誌,便於問題排查、審計、分析",
        "C": "不需要儲存日誌",
        "D": "日誌自動刪除"
      },
      "answer": "B",
      "explanation": "集中式日誌是微服務和分散式AI系統的運維基礎,解決日誌分散難以管理的問題。集中式日誌架構與優勢:(1)架構:【日誌收集】每個服務(API、模型服務、資料庫)產生日誌,由Agent(如Fluentd、Filebeat)收集;【日誌傳輸】透過訊息佇列(Kafka)或直接傳送到日誌伺服器;【日誌儲存】集中儲存到Elasticsearch、Splunk等,支援大規模、長期儲存;【日誌查詢】透過Kibana、Grafana提供統一查詢介面,支援全文搜索、過濾、聚合;(2)優勢:【統一視圖】一個介面查詢所有服務日誌,例如追蹤一個請求經過API Gateway→模型服務→資料庫的完整路徑;【問題排查】分散式系統錯誤可能跨多個服務,集中式日誌可快速定位根因;例如搜尋「request_id=abc123」找出該請求在所有服務的日誌;【審計與合規】金融、醫療系統需要保留完整審計日誌,集中儲存便於管理和合規檢查;【安全分析】集中分析日誌可偵測異常模式(如突然的大量錯誤、疑似攻擊);【效能分析】聚合分析所有服務的效能指標,識別瓶頸;(3)日誌標準化:結構化日誌(JSON格式)包含timestamp、service_name、log_level、message、trace_id、user_id等欄位;統一日誌級別(DEBUG、INFO、WARN、ERROR);(4)常見工具:ELK Stack(Elasticsearch、Logstash、Kibana)、EFK Stack(用Fluentd替換Logstash)、Splunk、Graylog。集中式日誌是可觀測性(Observability)三支柱之一(日誌、指標、追蹤)。",
      "keywords": [
        "集中式日誌",
        "ELK Stack",
        "日誌管理",
        "可觀測性",
        "問題排查",
        "Elasticsearch",
        "Kibana"
      ],
      "reference": "AI系統維運 - 集中式日誌架構"
    },
    {
      "question_id": "L21303_005",
      "sequence": 113,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某欺詐偵測AI系統上線後,發現欺詐者快速適應檢測規則,模型召回率從90%降至60%。這屬於哪種問題,應如何應對?",
      "options": {
        "A": "系統故障,重啟伺服器即可",
        "B": "對抗性漂移(Adversarial Drift),需要更頻繁的模型再訓練(如每週)、引入對抗樣本訓練、實施行為分析檢測新型欺詐模式",
        "C": "硬體問題,更換伺服器",
        "D": "不需要任何處理"
      },
      "answer": "B",
      "explanation": "欺詐檢測面臨特殊的對抗性環境,是概念漂移的極端形式。對抗性漂移應對策略:(1)問題識別:【對抗性漂移】欺詐者主動調整策略避開檢測,是有意識的對抗,不同於自然的資料漂移;【表現】召回率快速下降(漏檢增加),而精確率可能保持(檢測到的仍是欺詐);【常見場景】欺詐檢測、垃圾郵件過濾、惡意軟體檢測、推薦系統對抗(刷榜);(2)短期應對:【加速再訓練】從每月縮短到每週甚至每天,快速納入新型欺詐案例;【人工審查閉環】將可疑但未檢出的案例(如用戶舉報)加入訓練資料,形成快速學習循環;【規則補丁】在模型外層加入針對新型欺詐的啟發式規則(如「一天內多次更換IP地址」),作為臨時防禦;(3)中長期策略:【對抗訓練(Adversarial Training)】在訓練時加入對抗樣本,提升模型魯棒性;模擬欺詐者可能的攻擊方式,主動生成對抗樣本訓練;【集成模型(Ensemble)】使用多個不同模型(如規則、統計、深度學習)投票,攻擊者難以同時繞過所有模型;【行為分析】引入序列模型(LSTM、Transformer)分析用戶行為軌跡,檢測異常模式;【無監督異常檢測】使用Isolation Forest、One-Class SVM檢測未見過的新型欺詐;【人機協作】高風險案例交由人工審查,建立專家反饋循環;(4)系統設計:【多層防禦】規則層(快速攔截已知模式)→模型層(檢測複雜模式)→行為分析層(識別異常軌跡)→人工審查層;【快速更新機制】支援熱更新規則和模型,無需停機;【對抗者成本提升】增加攻擊成本(如多因素驗證),降低攻擊收益。欺詐檢測是AI維運的最高難度場景,需要持續創新和快速迭代。",
      "keywords": [
        "對抗性漂移",
        "欺詐檢測",
        "對抗訓練",
        "快速再訓練",
        "集成模型",
        "人機協作",
        "行為分析"
      ],
      "reference": "AI對抗性維運 - 欺詐檢測系統"
    },
    {
      "question_id": "L21303_006",
      "sequence": 114,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在AI系統的A/B測試中,以下哪個做法最為適當?",
      "options": {
        "A": "隨機將50%流量分配給新模型,立即觀察1小時結果",
        "B": "先將5-10%流量分配給新模型,運行足夠時間(如數天到一週)收集統計顯著樣本,對比核心指標,確認新模型顯著優於舊模型後再擴大",
        "C": "100%流量直接切換到新模型",
        "D": "不做測試,憑感覺決定"
      },
      "answer": "B",
      "explanation": "A/B測試是驗證模型改進的黃金標準,需要嚴謹的實驗設計。A/B測試最佳實踐:(1)流量分配策略:【初始比例】保守起步,5-10%流量給新模型(Treatment),90-95%給舊模型(Control);【漸進擴大】若新模型表現良好,逐步擴大:5%→10%→25%→50%→100%;【風險控制】新模型若有bug,影響範圍可控,可快速回滾;(2)實驗時長:【統計顯著性】需足夠樣本量達到統計顯著,通常數千到數萬樣本;【業務週期】覆蓋完整業務週期(如一週,包含工作日和週末)避免週期性偏差;【外部因素】避開促銷、假期等特殊時期,減少混淆因素;【最小時長】至少運行數天,1小時太短,結果不穩定;(3)指標選擇:【核心指標(Primary Metrics)】直接業務目標,如推薦系統的點擊率、轉換率、收益;【護欄指標(Guardrail Metrics)】確保不傷害其他面向,如延遲、錯誤率、用戶滿意度;【模型指標】準確率、AUC等技術指標;(4)統計分析:【顯著性檢驗】使用t-test或卡方檢驗,確認差異不是隨機波動(p-value < 0.05);【效應量】不僅看是否顯著,還看提升幅度是否有商業價值(如CTR提升0.1%可能統計顯著但商業價值小);【多重檢驗修正】測試多個指標時使用Bonferroni或FDR修正,避免假陽性;(5)決策:新模型在核心指標顯著優於舊模型,且護欄指標無惡化→全量部署;新模型無顯著差異或劣於舊模型→保留舊模型,分析原因;(6)常見陷阱:【辛普森悖論】總體提升但某子群體惡化,需分層分析;【新奇效應】用戶對新模型暫時興趣高,長期效果需追蹤;【污染】Treatment和Control用戶互動(如社交網路),需cluster級別隨機化。A/B測試平台:自建或使用Google Optimize、Optimizely、GrowthBook。",
      "keywords": [
        "A/B測試",
        "實驗設計",
        "統計顯著性",
        "流量分配",
        "護欄指標",
        "模型驗證",
        "因果推斷"
      ],
      "reference": "AI系統A/B測試最佳實踐"
    },
    {
      "question_id": "L21303_007",
      "sequence": 115,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某AI服務監控告警頻繁誤報(False Alarm),例如每天收到50條告警但僅5條是真實問題,導致團隊告警疲勞。應如何優化告警策略?",
      "options": {
        "A": "關閉所有告警",
        "B": "調整告警閾值(基於歷史數據設定合理範圍)、使用複合條件(多個指標同時異常才告警)、實施告警降噪(相似告警聚合)、分級告警(P0-P3)",
        "C": "增加更多告警",
        "D": "忽略所有告警"
      },
      "answer": "B",
      "explanation": "告警疲勞是運維的大敵,需要精心設計告警策略,確保高信噪比。告警優化策略:(1)閾值優化:【基於歷史基線】分析過去30天的指標分布,設定閾值為均值±3標準差(99.7%置信區間);例如平均QPS=1000,標準差=100,閾值設為700-1300,而非固定值;【動態閾值】根據時間模式(工作日vs週末、白天vs夜間)調整閾值,避免正常波動觸發告警;【百分位數】使用P95或P99而非均值,更能反映尾部異常;(2)複合條件:【多指標聯合】「錯誤率>5% AND 延遲>200ms AND 持續5分鐘」才告警,單一指標短暫異常不告警;【變化率】「QPS下降>50%」比絕對值更能反映異常;【趨勢判斷】連續3個監控週期遞增才告警,避免單點抖動;(3)告警降噪:【聚合相似告警】「服務A的10個實例都超時」聚合為一條告警,而非10條;【抑制規則】已知上游服務故障時,抑制下游服務的級聯告警;【靜默期】某告警觸發後30分鐘內不重複發送,避免轟炸;(4)告警分級:【P0-Critical】影響核心業務,立即處理(如模型服務完全down),電話+簡訊+郵件;【P1-High】部分影響,1小時內處理(如準確率下降20%),簡訊+郵件;【P2-Medium】需關注,4小時內處理(如延遲P95上升30%),郵件;【P3-Low】資訊性,工作時間處理(如磁碟使用率70%),儀表板呈現;【On-call輪值】P0/P1觸發值班人員處理,P2/P3由負責團隊自行處理;(5)告警可操作性:【明確Runbook】每個告警附帶處理手冊(如「準確率下降→檢查資料漂移→觸發再訓練」);【上下文資訊】告警包含相關圖表、日誌連結,方便快速診斷;【自動修復】部分問題自動修復(如重啟故障Pod),成功則不告警,失敗才升級;(6)持續優化:【告警覆盤】每週檢視誤報告警,調整閾值或刪除;【告警效率指標】追蹤告警精確率(真實問題/總告警數),目標>50%;【反饋循環】處理告警後標記是否有用,持續改進。目標是「每個告警都有意義,每次響應都有價值」。",
      "keywords": [
        "告警優化",
        "告警疲勞",
        "動態閾值",
        "告警分級",
        "降噪策略",
        "On-call",
        "運維自動化"
      ],
      "reference": "AI系統告警策略最佳實踐"
    },
    {
      "question_id": "L21303_008",
      "sequence": 116,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在模型版本回滾(Rollback)時,以下哪個做法最安全?",
      "options": {
        "A": "直接刪除新版本模型,強制使用舊版本",
        "B": "使用藍綠部署或金絲雀部署架構,透過流量切換快速回滾到前一版本,同時保留新版本環境以供分析問題",
        "C": "重新訓練一個全新模型",
        "D": "關閉整個服務"
      },
      "answer": "B",
      "explanation": "模型回滾是生產事故的重要恢復手段,需要快速、安全、可追溯。回滾最佳實踐:(1)架構支援:【藍綠部署】維持兩套環境,新版本(綠)出問題時,立即將流量切回舊版本(藍),回滾時間<1分鐘;【金絲雀部署】若新版本僅部署在5%流量,發現問題立即停止擴大,將5%流量切回舊版本,影響範圍可控;【版本標籤】使用語義化版本(v1.2.3),清晰標記生產版本;(2)回滾流程:【異常檢測】監控發現新版本(v2.0.0)錯誤率飆升、準確率下降;【決策】評估影響範圍和嚴重程度,決定回滾;【執行回滾】修改負載均衡器配置,將流量從v2.0.0切換到v1.9.5(前一穩定版本);或在K8s中修改Deployment標籤,rollout到前一版本;【驗證】確認錯誤率恢復、服務穩定;【保留新版本環境】不立即刪除v2.0.0環境,用於問題分析、日誌查看、根因診斷;(3)回滾保障:【快速回滾能力】回滾應<5分鐘完成,需要預演和自動化;【模型版本管理】Model Registry保留所有歷史版本,可快速取用;【配置即程式碼】部署配置版本化(Git),回滾配置等同回滾程式碼;【資料相容性】確保舊模型可以處理新資料格式(向後相容),或維護資料轉換層;(4)根因分析:回滾後進行事後分析(Post-mortem):新版本為何失敗?測試遺漏什麼?如何預防?記錄教訓,改進流程;(5)回滾vs前進修復:【回滾】快速恢復服務,適合緊急情況;【前進修復(Fix Forward)】快速修復bug並部署修復版本v2.0.1,適合問題明確且修復簡單;【選擇】緊急且影響大→回滾;問題已知且修復快→前進修復。選項A刪除新版本會丟失分析證據;選項C重訓不及時;選項D過度反應。回滾是止血,根因分析是治病。",
      "keywords": [
        "模型回滾",
        "Rollback",
        "藍綠部署",
        "事故恢復",
        "版本管理",
        "Post-mortem",
        "生產事故處理"
      ],
      "reference": "AI模型回滾策略與事故處理"
    },
    {
      "question_id": "L21303_009",
      "sequence": 117,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "medium",
      "question_type": "technical_selection",
      "question": "某推薦系統發現特定用戶群體(如老年用戶)的推薦效果明顯低於整體,但整體指標正常。這可能是什麼問題,應如何監控和改善?",
      "options": {
        "A": "整體指標正常就不需要處理",
        "B": "模型公平性(Fairness)問題,應實施分層監控(按年齡、性別等切片),評估各子群體指標,使用公平性約束訓練或後處理調整",
        "C": "這是正常現象,無法改善",
        "D": "刪除老年用戶資料"
      },
      "answer": "B",
      "explanation": "AI公平性和偏見問題是倫理AI的核心挑戰,需要主動監控和緩解。公平性問題診斷與改善:(1)問題識別:【辛普森悖論】整體指標掩蓋子群體問題,如整體準確率90%但老年用戶僅60%;【保護屬性】年齡、性別、種族、地域等敏感屬性上的差異;【公平性定義】統計平等(各群體正例率相同)、機會平等(各群體真陽性率相同)、預測平等(各群體精確率相同);(2)分層監控:【切片分析(Slicing)】將整體資料按保護屬性切片(如年齡18-25、26-35、36-50、51+),計算每個切片的指標(準確率、CTR、滿意度);【差異檢測】識別指標顯著低於整體的切片,如老年用戶CTR=2%,整體=5%;【儀表板呈現】Fairness Dashboard實時呈現各群體指標,告警異常差異;(3)根因分析:【訓練資料偏差】老年用戶樣本少(僅佔5%),模型學習不足;【特徵偏差】模型過度依賴「瀏覽速度快」等特徵,不利於老年用戶;【標籤偏差】歷史推薦偏向年輕用戶,形成反饋循環;(4)改善策略:【資料增強】過採樣老年用戶樣本,確保訓練資料平衡;【公平性約束訓練】在loss function加入公平性懲罰項,如最小化各群體錯誤率差異;【後處理調整】訓練後調整決策閾值,確保各群體機會平等(如老年用戶閾值降低,增加推薦機會);【多目標優化】同時優化整體指標和公平性指標;【群體特定模型】為不同群體訓練專門模型,個性化推薦策略;(5)持續監控:【公平性指標】Demographic Parity(統計平等)、Equal Opportunity(機會平等)、Calibration(校準);【定期審計】季度審查各群體指標,確保無歧視;【透明度】向用戶說明推薦邏輯,提供控制選項。公平性與準確率可能存在權衡(Fairness-Accuracy Trade-off),需在業務目標、社會責任、法規要求間平衡。選項A忽視社會責任和法規風險;選項C逃避問題;選項D違反倫理且可能違法。",
      "keywords": [
        "模型公平性",
        "Fairness",
        "偏見檢測",
        "分層監控",
        "切片分析",
        "公平性約束",
        "AI倫理",
        "辛普森悖論"
      ],
      "reference": "AI公平性監控與偏見緩解"
    },
    {
      "question_id": "L21303_010",
      "sequence": 118,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "medium",
      "question_type": "technical_principles",
      "question": "在成本優化方面,AI系統運營成本的主要組成為何?應如何優化?",
      "options": {
        "A": "僅考慮伺服器成本",
        "B": "運算成本(GPU/CPU)、儲存成本、網路成本、人力成本;優化策略包括自動擴縮容、使用Spot實例、模型壓縮、快取、冷熱資料分層",
        "C": "成本無法優化",
        "D": "僅削減人力"
      },
      "answer": "B",
      "explanation": "AI系統成本管理是可持續運營的關鍵,需要全面考量並持續優化。成本結構與優化策略:(1)運算成本(通常佔50-70%):【GPU成本】訓練大模型的主要成本(A100 $2-3/小時);【優化】使用Spot/Preemptible實例(便宜70%但可能中斷,適合容錯訓練);混合精度訓練(FP16)減少記憶體和時間;模型並行和資料並行提升GPU利用率;【推理成本】持續產生,需重點優化;【優化】模型量化(INT8)、批次推理、模型快取、自動擴縮容(低峰縮容節省成本);(2)儲存成本(通常佔10-20%):【訓練資料】原始資料、處理後資料、增強資料;【模型版本】Model Registry保留所有版本;【日誌】大量日誌長期儲存;【優化】冷熱資料分層(熱資料SSD、冷資料S3 Glacier,成本差10倍);壓縮歷史資料;定期清理無用模型版本和日誌;使用物件儲存(S3)取代塊儲存(EBS),便宜5倍;(3)網路成本(通常佔5-15%):【跨區域傳輸】資料在不同雲端區域間傳輸;【優化】資料本地化,減少跨區域傳輸;使用CDN快取推理結果;壓縮API回應;(4)人力成本(通常佔30-50%,但常被忽略):【開發】資料科學家、ML工程師;【運維】DevOps、On-call;【優化】自動化MLOps pipeline減少人工介入;提升工具和平台降低運維複雜度;知識共享減少重複開發;(5)成本監控與優化:【成本可觀測性】按服務、團隊、專案標籤資源,追蹤成本歸屬;設定預算告警,超支自動通知;【成本優化建議】雲端提供商的Cost Explorer分析閒置資源、過度配置;【FinOps實踐】財務、工程、業務協作,建立成本意識文化;定期成本審查會議,設定優化目標(如降低20%);【ROI導向】評估成本vs業務價值,低價值高成本的服務考慮下線。實務案例:某公司透過模型量化+Spot實例+自動擴縮容,將推理成本從$10000/月降至$3000/月(降低70%)。成本優化是持續過程,需要技術和管理雙重手段。",
      "keywords": [
        "成本優化",
        "GPU成本",
        "Spot實例",
        "冷熱資料",
        "自動擴縮容",
        "FinOps",
        "資源利用率",
        "雲端成本管理"
      ],
      "reference": "AI系統成本優化最佳實踐"
    },
    {
      "question_id": "L21303_011",
      "sequence": 119,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某全球AI平台需要實現「模型即服務」(Model-as-a-Service),讓內部數十個業務團隊自助部署和管理模型,同時確保資源隔離、成本可控、合規安全。應設計什麼平台架構?",
      "options": {
        "A": "每個團隊各自建立獨立基礎設施",
        "B": "建立統一的ML Platform:多租戶Kubernetes、Model Registry、自助服務Portal、資源配額管理、統一監控告警、成本追蹤、合規審計",
        "C": "禁止團隊部署模型",
        "D": "完全無管控的自由部署"
      },
      "answer": "B",
      "explanation": "企業級ML Platform是MLOps成熟度的頂峰,實現規模化AI。完整平台架構設計:(1)多租戶基礎設施:【Namespace隔離】每個業務團隊獨立K8s namespace,網路和資源隔離;【資源配額】設定CPU/GPU/記憶體配額,防止資源壟斷(如team-A最多10個GPU);【優先級】關鍵業務高優先級,保證資源;【成本標籤】所有資源標註team_id,追蹤各團隊成本,月底Chargeback;(2)自助服務Portal:【模型上傳】團隊透過Web介面或CLI上傳模型到Model Registry;【一鍵部署】選擇模型版本、配置(副本數、資源需求、AutoScaling規則)、點擊部署;【Deployment Template】預定義模板(如「推薦系統-標準配置」),降低配置門檻;【權限管理】RBAC控制,team-A僅能管理自己的模型;(3)Model Registry:【集中管理】所有團隊的模型統一在Registry,便於發現和重用;【版本控制】語義化版本,階段管理(Staging/Production);【元資料】記錄訓練者、準確率、資料集版本、依賴項;(4)統一監控告警:【多租戶監控】每個團隊獨立dashboard,查看自己模型的指標;【平台級監控】Platform團隊監控整體資源使用、成本、SLA;【告警路由】team-A模型告警發給team-A,不幹擾其他團隊;【SLO管理】各團隊設定自己的SLO(如P99延遲<100ms),平台自動監控;(5)成本追蹤與優化:【成本透明】每個團隊看到自己的月度成本明細(GPU小時、儲存、網路);【預算管理】設定預算上限,接近告警,超過自動縮容或禁止新部署;【成本優化建議】平台分析各團隊資源使用,提供優化建議(如「team-B的模型A閒置資源50%,建議縮容」);(6)合規與安全:【模型掃描】部署前自動掃描模型是否包含惡意程式碼、隱私資料;【存取控制】API Gateway強制認證,記錄所有調用審計日誌;【資料隱私】enforece資料去識別化,禁止使用生產個資訓練;【合規報告】季度生成合規報告,列出所有生產模型、資料來源、風險評估;(7)CI/CD整合:【GitOps】團隊在Git定義模型部署配置,推送觸發自動部署;【Pipeline Template】提供標準化訓練和部署pipeline,團隊可複用;【測試閘門】部署前自動運行整合測試,失敗自動阻止;(8)知識共享:【模型Marketplace】優秀模型可分享給其他團隊,加速創新;【最佳實踐】平台team整理MLOps最佳實踐文件、範例程式碼;【社群】內部論壇、定期分享會,團隊間交流經驗。這種平台架構實現:(a)規模化:支援數十到數百個模型;(b)自助服務:團隊自主創新,減少依賴;(c)治理:統一監控、成本、合規;(d)效率:共用基礎設施和知識,降低重複。代表平台:AWS SageMaker、Google Vertex AI、內部自建(Kubeflow+MLflow+自研Portal)。平台建設是長期投資,但ROI顯著。",
      "keywords": [
        "ML Platform",
        "多租戶",
        "Model-as-a-Service",
        "自助服務",
        "資源配額",
        "成本管理",
        "Kubeflow",
        "MLflow",
        "企業MLOps"
      ],
      "reference": "企業級ML Platform架構設計"
    },
    {
      "question_id": "L21303_012",
      "sequence": 120,
      "topic": "L21303-AI技術系統維運與優化",
      "difficulty": "hard",
      "question_type": "system_integration",
      "question": "某醫療AI系統上線2年後,需要進行模型效能衰退的根因分析和長期維運優化。發現準確率從92%降至85%,但無明顯資料漂移。應如何系統性診斷和改善?",
      "options": {
        "A": "直接重新訓練模型",
        "B": "進行全面診斷:分析錯誤案例(Error Analysis)、檢查資料品質演變、評估標註漂移、檢視特徵重要性變化、對比子群體效能、實施持續學習或定期校準",
        "C": "放棄該模型",
        "D": "忽略效能下降"
      },
      "answer": "B",
      "explanation": "長期維運的模型效能衰退需要深度診斷,不能簡單重訓了事。系統性診斷與改善流程:(1)錯誤分析(Error Analysis):【收集錯誤案例】找出當前模型預測錯誤的案例(如誤診病例);【模式識別】分析錯誤案例的共同特徵,如「新型疾病變體」、「罕見併發症」、「特定年齡層」;【量化影響】計算各類錯誤的佔比,優先解決高頻錯誤;【根因假設】提出假設(如「訓練資料缺乏X疾病樣本」);(2)資料品質演變:【分布變化】雖然整體無明顯漂移,但細查發現:(a)新病例的嚴重程度分布變化(輕症增多);(b)檢測設備更新,影像品質提升但模型未適應;【標註漂移(Label Drift)】醫學診斷標準更新,導致歷史標註與當前標準不一致;例如2年前的「陽性」定義與現在不同;【資料收集偏差】病患來源醫院變化,引入新的地域性特徵;(3)特徵重要性分析:【SHAP分析】對比訓練時和當前的特徵重要性排序,發現關鍵特徵的貢獻度變化;【特徵失效】某些原本重要的特徵(如血液檢測指標A)因檢測方法改變而失效;【新特徵需求】識別可能改善效能的新特徵(如新型生物標誌物);(4)子群體分析:【切片評估】將資料按年齡、性別、疾病類型、嚴重程度切片,發現:(a)整體準確率85%,但老年患者僅75%;(b)罕見疾病召回率僅60%;【定向優化】針對低效能子群體過採樣或專門訓練;(5)標註品質檢查:【重新標註】抽樣當前資料請專家重新標註,對比模型預測和新標註,發現模型可能是對的,標註標準變了;【共識標註】多位專家標註同一案例,計算Inter-Annotator Agreement,低共識表示標註不穩定;(6)改善策略:【持續學習】建立incremental learning pipeline,定期(如每月)用新資料增量訓練,適應分布變化;【主動學習】模型識別不確定案例,優先請專家標註,高效改善;【模型校準(Calibration)】若模型信心分數不準(如預測90%信心但實際僅70%準確),進行Platt Scaling或Temperature Scaling校準;【集成更新】加入新訓練的模型到集成(Ensemble),與舊模型投票,漸進提升;【定期審計】季度review模型效能,與臨床專家討論,確保符合最新醫學標準;(7)長期維運機制:【模型生命週期管理】定義模型退役標準(如準確率<80%或使用>3年),強制review;【反饋閉環】醫師使用模型時可標註「預測錯誤」,自動加入再訓練資料;【A/B測試新舊模型】持續評估是否需要更新;【監管合規】向FDA/TFDA報告模型變更,確保符合醫療器材法規。這種深度診斷能發現重訓無法解決的系統性問題(如標註標準變化、新疾病變體),實現持續改善而非一次性修復。選項A簡單重訓可能無效;選項C放棄浪費投資;選項D忽略會惡化到不可用。醫療AI維運是持續的醫工協作。",
      "keywords": [
        "錯誤分析",
        "根因診斷",
        "標註漂移",
        "持續學習",
        "模型校準",
        "主動學習",
        "子群體分析",
        "醫療AI維運",
        "長期優化"
      ],
      "reference": "AI模型長期維運診斷與優化"
    }
  ]
}
